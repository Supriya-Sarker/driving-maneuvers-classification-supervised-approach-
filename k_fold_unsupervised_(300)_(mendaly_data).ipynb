{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd \n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential, save_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Input, RepeatVector, TimeDistributed\n",
    "from keras.regularizers import l1\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('D:/data/Mendeley Data/raw.csv')\n",
    "#rename ground truth\n",
    "del dataset['AccZ']\n",
    "del dataset['GyroX']\n",
    "del dataset['GyroY']\n",
    "dataset.columns = ['AccX', ' AccY', ' GyroZ', 'Target']\n",
    "dataset = dataset.rename(columns = \\\n",
    "                                    {'AccX':'acc_x',' AccY':'acc_y',' GyroZ':'gyro_z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['category'] = dataset['Target'].map({ 1: 'aggressive_acceleration', 2:'aggressive_right_turn', 3:'aggressive_left_turn',\\\n",
    "                                            4: 'aggressive_braking', })\n",
    "del dataset['Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>category</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.162598</td>\n",
       "      <td>-0.086670</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.322754</td>\n",
       "      <td>-0.140381</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480225</td>\n",
       "      <td>-0.226807</td>\n",
       "      <td>-0.251908</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426025</td>\n",
       "      <td>-0.253906</td>\n",
       "      <td>-0.106870</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>0.472900</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>554.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>0.459961</td>\n",
       "      <td>-0.227051</td>\n",
       "      <td>1.282443</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>0.419189</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>1.183206</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>555.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.308838</td>\n",
       "      <td>-0.090088</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>0.098145</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>556.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc_x     acc_y    gyro_z                 category  second\n",
       "0     0.162598 -0.086670  0.824427  aggressive_acceleration     0.0\n",
       "1     0.175781 -0.100586  0.832061  aggressive_acceleration     0.5\n",
       "2     0.322754 -0.140381  0.587786  aggressive_acceleration     1.0\n",
       "3     0.480225 -0.226807 -0.251908  aggressive_acceleration     1.5\n",
       "4     0.426025 -0.253906 -0.106870  aggressive_acceleration     2.0\n",
       "...        ...       ...       ...                      ...     ...\n",
       "1109  0.472900 -0.431152  8.893130       aggressive_braking   554.5\n",
       "1110  0.459961 -0.227051  1.282443       aggressive_braking   555.0\n",
       "1111  0.419189 -0.192871  1.183206       aggressive_braking   555.5\n",
       "1112  0.308838 -0.090088  0.656489       aggressive_braking   556.0\n",
       "1113  0.098145 -0.015869  0.045802       aggressive_braking   556.5\n",
       "\n",
       "[1114 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['second'] = (dataset.index)*0.5\n",
    "dataset.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>category</th>\n",
       "      <th>eng_acc_x</th>\n",
       "      <th>eng_acc_y</th>\n",
       "      <th>eng_gyro_z</th>\n",
       "      <th>slope_acc_x</th>\n",
       "      <th>slope_acc_y</th>\n",
       "      <th>slope_gyro_z</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.162598</td>\n",
       "      <td>-0.086670</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.679681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.030899</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.692326</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.322754</td>\n",
       "      <td>-0.140381</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>0.019707</td>\n",
       "      <td>0.345493</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>-0.079590</td>\n",
       "      <td>0.146542</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.480225</td>\n",
       "      <td>-0.226807</td>\n",
       "      <td>-0.251908</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.230616</td>\n",
       "      <td>0.051441</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.314941</td>\n",
       "      <td>-0.172852</td>\n",
       "      <td>0.252891</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.426025</td>\n",
       "      <td>-0.253906</td>\n",
       "      <td>-0.106870</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.181498</td>\n",
       "      <td>0.064468</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>-0.054199</td>\n",
       "      <td>-0.098236</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554.5</th>\n",
       "      <td>0.472900</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>0.223635</td>\n",
       "      <td>0.185892</td>\n",
       "      <td>79.087757</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.379856</td>\n",
       "      <td>554.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.0</th>\n",
       "      <td>0.459961</td>\n",
       "      <td>-0.227051</td>\n",
       "      <td>1.282443</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>0.211564</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>1.644659</td>\n",
       "      <td>-0.025879</td>\n",
       "      <td>0.408203</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.5</th>\n",
       "      <td>0.419189</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>1.183206</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>0.175720</td>\n",
       "      <td>0.037199</td>\n",
       "      <td>1.399977</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>-0.071689</td>\n",
       "      <td>555.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.0</th>\n",
       "      <td>0.308838</td>\n",
       "      <td>-0.090088</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>0.095381</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.430977</td>\n",
       "      <td>-0.220703</td>\n",
       "      <td>0.205566</td>\n",
       "      <td>-0.160678</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.5</th>\n",
       "      <td>0.098145</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>-0.421387</td>\n",
       "      <td>0.148437</td>\n",
       "      <td>-0.171497</td>\n",
       "      <td>556.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_x     acc_y    gyro_z                 category  eng_acc_x  \\\n",
       "second                                                                     \n",
       "0.0     0.162598 -0.086670  0.824427  aggressive_acceleration   0.026438   \n",
       "0.5     0.175781 -0.100586  0.832061  aggressive_acceleration   0.030899   \n",
       "1.0     0.322754 -0.140381  0.587786  aggressive_acceleration   0.104170   \n",
       "1.5     0.480225 -0.226807 -0.251908  aggressive_acceleration   0.230616   \n",
       "2.0     0.426025 -0.253906 -0.106870  aggressive_acceleration   0.181498   \n",
       "...          ...       ...       ...                      ...        ...   \n",
       "554.5   0.472900 -0.431152  8.893130       aggressive_braking   0.223635   \n",
       "555.0   0.459961 -0.227051  1.282443       aggressive_braking   0.211564   \n",
       "555.5   0.419189 -0.192871  1.183206       aggressive_braking   0.175720   \n",
       "556.0   0.308838 -0.090088  0.656489       aggressive_braking   0.095381   \n",
       "556.5   0.098145 -0.015869  0.045802       aggressive_braking   0.009632   \n",
       "\n",
       "        eng_acc_y  eng_gyro_z  slope_acc_x  slope_acc_y  slope_gyro_z   time  \n",
       "second                                                                        \n",
       "0.0      0.007512    0.679681          NaN          NaN           NaN    0.0  \n",
       "0.5      0.010118    0.692326     0.026367    -0.027832      0.008922    0.5  \n",
       "1.0      0.019707    0.345493     0.293945    -0.079590      0.146542    1.0  \n",
       "1.5      0.051441    0.063458     0.314941    -0.172852      0.252891    1.5  \n",
       "2.0      0.064468    0.011421    -0.108398    -0.054199     -0.098236    2.0  \n",
       "...           ...         ...          ...          ...           ...    ...  \n",
       "554.5    0.185892   79.087757     0.578613    -0.781250      0.379856  554.5  \n",
       "555.0    0.051552    1.644659    -0.025879     0.408203     -0.024141  555.0  \n",
       "555.5    0.037199    1.399977    -0.081543     0.068359     -0.071689  555.5  \n",
       "556.0    0.008116    0.430977    -0.220703     0.205566     -0.160678  556.0  \n",
       "556.5    0.000252    0.002098    -0.421387     0.148437     -0.171497  556.5  \n",
       "\n",
       "[1114 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['eng_acc_x'] = (dataset['acc_x'].pow(2))\n",
    "dataset['eng_acc_y'] = (dataset['acc_y'].pow(2))\n",
    "dataset['eng_gyro_z'] = (dataset['gyro_z'].pow(2))\n",
    "\n",
    "dataset['slope_acc_x'] = dataset.iloc[:, 0].diff().div(dataset.second.diff(), axis=0)\n",
    "dataset['slope_acc_y'] = dataset.iloc[:, 1].diff().div(dataset.second.diff(), axis=0)\n",
    "dataset['slope_gyro_z'] = dataset.iloc[:, 5].diff().div(dataset.second.diff(), axis=0)\n",
    "\n",
    "dataset['time'] = dataset['second']\n",
    "dataset.set_index('second', inplace=True)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window feature seclection for acc_x\n",
    "acc_x = dataset['acc_x']\n",
    "shifted_acc_x = acc_x.shift(1)\n",
    "window_shifted_acc_x = shifted_acc_x.rolling(window=20)\n",
    "mean_window_acc_x = window_shifted_acc_x.mean().fillna(value =0, inplace=False)\n",
    "#mean_window_acc_x = window_shifted_acc_x.mad()\n",
    "min_window_acc_x = window_shifted_acc_x.min().fillna(value =0, inplace=False)\n",
    "max_window_acc_x = window_shifted_acc_x.max().fillna(value =0, inplace=False)\n",
    "var_window_acc_x = window_shifted_acc_x.var().fillna(value =0, inplace=False)\n",
    "std_window_acc_x = window_shifted_acc_x.std().fillna(value =0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_acc_x = dataset['eng_acc_x']\n",
    "shifted_eng_acc_x = eng_acc_x.shift(1)\n",
    "window_shifted_eng_acc_x = shifted_eng_acc_x.rolling(window=20)\n",
    "engy_window_acc_x = window_shifted_eng_acc_x.mean().fillna(value =0, inplace=False)\n",
    "\n",
    "slope_acc_x = dataset['slope_acc_x']\n",
    "shifted_slope_acc_x = slope_acc_x.shift(1)\n",
    "window_shifted_slope_acc_x = shifted_slope_acc_x.rolling(window=20)\n",
    "slope_window_acc_x = window_shifted_slope_acc_x.mean().fillna(value =0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window feature seclection for acc_y\n",
    "acc_y = dataset['acc_y']\n",
    "shifted_acc_y = acc_y.shift(1)\n",
    "window_shifted_acc_y = shifted_acc_y.rolling(window=20)\n",
    "mean_window_acc_y = window_shifted_acc_y.mean().fillna(value =0, inplace=False)\n",
    "min_window_acc_y = window_shifted_acc_y.min().fillna(value =0, inplace=False)\n",
    "max_window_acc_y = window_shifted_acc_y.max().fillna(value =0, inplace=False)\n",
    "var_window_acc_y = window_shifted_acc_y.var().fillna(value =0, inplace=False)\n",
    "std_window_acc_y = window_shifted_acc_y.std().fillna(value =0, inplace=False)\n",
    "eng_acc_y = dataset['eng_acc_y']\n",
    "shifted_eng_acc_y = eng_acc_y.shift(1)\n",
    "window_shifted_eng_acc_y = shifted_eng_acc_y.rolling(window=20)\n",
    "engy_window_acc_y = window_shifted_eng_acc_y.mean().fillna(value =0, inplace=False)\n",
    "\n",
    "slope_acc_y = dataset['slope_acc_y']\n",
    "shifted_slope_acc_y = slope_acc_y.shift(1)\n",
    "window_shifted_slope_acc_y = shifted_slope_acc_y.rolling(window=20)\n",
    "slope_window_acc_y = window_shifted_slope_acc_y.mean().fillna(value =0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window feature seclection for gyro_z\n",
    "gyro_z = dataset['gyro_z']\n",
    "shifted_gyro_z = gyro_z.shift(1)\n",
    "window_shifted_gyro_z = shifted_gyro_z.rolling(window=20)\n",
    "mean_window_gyro_z = window_shifted_gyro_z.mean().fillna(value =0, inplace=False)\n",
    "min_window_gyro_z = window_shifted_gyro_z.min().fillna(value =0, inplace=False)\n",
    "max_window_gyro_z = window_shifted_gyro_z.max().fillna(value =0, inplace=False)\n",
    "var_window_gyro_z = window_shifted_gyro_z.var().fillna(value =0, inplace=False)\n",
    "std_window_gyro_z = window_shifted_gyro_z.std().fillna(value =0, inplace=False)\n",
    "eng_gyro_z = dataset['eng_gyro_z']\n",
    "shifted_eng_gyro_z = eng_gyro_z.shift(1)\n",
    "window_shifted_eng_gyro_z = shifted_eng_gyro_z.rolling(window=20)\n",
    "engy_window_gyro_z = window_shifted_eng_gyro_z.mean().fillna(value =0, inplace=False)\n",
    "\n",
    "slope_gyro_z = dataset['slope_gyro_z']\n",
    "shifted_slope_gyro_z = slope_gyro_z.shift(1)\n",
    "window_shifted_slope_gyro_z = shifted_slope_gyro_z.rolling(window=20)\n",
    "slope_window_gyro_z = window_shifted_slope_gyro_z.mean().fillna(value =0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>min_acc_x</th>\n",
       "      <th>max_acc_x</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>eng_acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>min_acc_y</th>\n",
       "      <th>...</th>\n",
       "      <th>min_gyro_z</th>\n",
       "      <th>max_gyro_z</th>\n",
       "      <th>var_gyro_z</th>\n",
       "      <th>std_gyro_z</th>\n",
       "      <th>eng_gyro_z</th>\n",
       "      <th>slope_acc_x</th>\n",
       "      <th>slope_acc_y</th>\n",
       "      <th>slope_gyro_z</th>\n",
       "      <th>category</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.162598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.086670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.322754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.480225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.226807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.426025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.253906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554.5</th>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.277698</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>0.242419</td>\n",
       "      <td>0.132945</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>-0.076709</td>\n",
       "      <td>-0.352295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>3.763359</td>\n",
       "      <td>0.733041</td>\n",
       "      <td>0.856178</td>\n",
       "      <td>2.285721</td>\n",
       "      <td>-0.038208</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>-0.028628</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>554.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.0</th>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.272546</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>0.127542</td>\n",
       "      <td>-0.227051</td>\n",
       "      <td>-0.090149</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>3.646008</td>\n",
       "      <td>1.909452</td>\n",
       "      <td>6.159822</td>\n",
       "      <td>-0.010303</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.010806</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.5</th>\n",
       "      <td>0.419189</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.234750</td>\n",
       "      <td>0.125461</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>-0.088672</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>3.552899</td>\n",
       "      <td>1.884913</td>\n",
       "      <td>6.238066</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>555.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.0</th>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.274780</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.056057</td>\n",
       "      <td>0.236764</td>\n",
       "      <td>0.128759</td>\n",
       "      <td>-0.090088</td>\n",
       "      <td>-0.093872</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>3.519133</td>\n",
       "      <td>1.875935</td>\n",
       "      <td>6.280083</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>-0.010400</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.5</th>\n",
       "      <td>0.098145</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.234750</td>\n",
       "      <td>0.132529</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>-0.100293</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>8.893130</td>\n",
       "      <td>3.522480</td>\n",
       "      <td>1.876827</td>\n",
       "      <td>6.278032</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>aggressive_braking</td>\n",
       "      <td>556.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_x  mean_acc_x  min_acc_x  max_acc_x  var_acc_x  std_acc_x  \\\n",
       "second                                                                     \n",
       "0.0     0.162598    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "0.5     0.175781    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "1.0     0.322754    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "1.5     0.480225    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "2.0     0.426025    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "554.5   0.472900    0.277698   -0.04541   0.631592   0.058767   0.242419   \n",
       "555.0   0.459961    0.272546   -0.04541   0.631592   0.056063   0.236777   \n",
       "555.5   0.419189    0.270386   -0.04541   0.631592   0.055108   0.234750   \n",
       "556.0   0.308838    0.274780   -0.04541   0.631592   0.056057   0.236764   \n",
       "556.5   0.098145    0.283154   -0.04541   0.631592   0.055108   0.234750   \n",
       "\n",
       "        eng_acc_x     acc_y  mean_acc_y  min_acc_y  ...  min_gyro_z  \\\n",
       "second                                              ...               \n",
       "0.0      0.000000 -0.086670    0.000000   0.000000  ...    0.000000   \n",
       "0.5      0.000000 -0.100586    0.000000   0.000000  ...    0.000000   \n",
       "1.0      0.000000 -0.140381    0.000000   0.000000  ...    0.000000   \n",
       "1.5      0.000000 -0.226807    0.000000   0.000000  ...    0.000000   \n",
       "2.0      0.000000 -0.253906    0.000000   0.000000  ...    0.000000   \n",
       "...           ...       ...         ...        ...  ...         ...   \n",
       "554.5    0.132945 -0.431152   -0.076709  -0.352295  ...    0.137405   \n",
       "555.0    0.127542 -0.227051   -0.090149  -0.431152  ...    0.137405   \n",
       "555.5    0.125461 -0.192871   -0.088672  -0.431152  ...    0.137405   \n",
       "556.0    0.128759 -0.090088   -0.093872  -0.431152  ...    0.137405   \n",
       "556.5    0.132529 -0.015869   -0.100293  -0.431152  ...    0.137405   \n",
       "\n",
       "        max_gyro_z  var_gyro_z  std_gyro_z  eng_gyro_z  slope_acc_x  \\\n",
       "second                                                                \n",
       "0.0       0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "0.5       0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "1.0       0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "1.5       0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "2.0       0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "...            ...         ...         ...         ...          ...   \n",
       "554.5     3.763359    0.733041    0.856178    2.285721    -0.038208   \n",
       "555.0     8.893130    3.646008    1.909452    6.159822    -0.010303   \n",
       "555.5     8.893130    3.552899    1.884913    6.238066    -0.004321   \n",
       "556.0     8.893130    3.519133    1.875935    6.280083     0.008789   \n",
       "556.5     8.893130    3.522480    1.876827    6.278032     0.016748   \n",
       "\n",
       "        slope_acc_y  slope_gyro_z                 category   time  \n",
       "second                                                             \n",
       "0.0        0.000000      0.000000  aggressive_acceleration    0.0  \n",
       "0.5        0.000000      0.000000  aggressive_acceleration    0.5  \n",
       "1.0        0.000000      0.000000  aggressive_acceleration    1.0  \n",
       "1.5        0.000000      0.000000  aggressive_acceleration    1.5  \n",
       "2.0        0.000000      0.000000  aggressive_acceleration    2.0  \n",
       "...             ...           ...                      ...    ...  \n",
       "554.5      0.032104     -0.028628       aggressive_braking  554.5  \n",
       "555.0     -0.026880     -0.010806       aggressive_braking  555.0  \n",
       "555.5      0.002954     -0.004162       aggressive_braking  555.5  \n",
       "556.0     -0.010400      0.006596       aggressive_braking  556.0  \n",
       "556.5     -0.012842      0.007540       aggressive_braking  556.5  \n",
       "\n",
       "[1114 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_acc_gyro_xyz = concat([acc_x, mean_window_acc_x, min_window_acc_x, max_window_acc_x,\\\n",
    "                               var_window_acc_x, std_window_acc_x, engy_window_acc_x, \\\n",
    "                               acc_y, mean_window_acc_y, min_window_acc_y, max_window_acc_y,\\\n",
    "                               var_window_acc_y, std_window_acc_y, engy_window_acc_y, \\\n",
    "                               gyro_z, mean_window_gyro_z, min_window_gyro_z, max_window_gyro_z,\\\n",
    "                               var_window_gyro_z, std_window_gyro_z, engy_window_gyro_z], axis=1)\n",
    "dataset_acc_gyro_xyz.columns = ['acc_x', 'mean_acc_x', 'min_acc_x', 'max_acc_x', 'var_acc_x', \\\n",
    "                                'std_acc_x', 'eng_acc_x', \\\n",
    "                                'acc_y', 'mean_acc_y', 'min_acc_y', 'max_acc_y', 'var_acc_y', \\\n",
    "                                'std_acc_y', 'eng_acc_y', \\\n",
    "                                'gyro_z', 'mean_gyro_z', 'min_gyro_z', 'max_gyro_z', 'var_gyro_z', \\\n",
    "                                'std_gyro_z', 'eng_gyro_z']\n",
    "dataset_acc_gyro_xyz['slope_acc_x'] = slope_window_acc_x\n",
    "dataset_acc_gyro_xyz['slope_acc_y'] = slope_window_acc_y\n",
    "dataset_acc_gyro_xyz['slope_gyro_z'] = slope_window_gyro_z\n",
    "dataset_acc_gyro_xyz['category']= dataset['category'] \n",
    "dataset_acc_gyro_xyz['time']= dataset['time'] \n",
    "\n",
    "dataset_acc_gyro_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 1114 entries, 0.0 to 556.5\n",
      "Data columns (total 26 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   acc_x         1114 non-null   float64\n",
      " 1   mean_acc_x    1114 non-null   float64\n",
      " 2   min_acc_x     1114 non-null   float64\n",
      " 3   max_acc_x     1114 non-null   float64\n",
      " 4   var_acc_x     1114 non-null   float64\n",
      " 5   std_acc_x     1114 non-null   float64\n",
      " 6   eng_acc_x     1114 non-null   float64\n",
      " 7   acc_y         1114 non-null   float64\n",
      " 8   mean_acc_y    1114 non-null   float64\n",
      " 9   min_acc_y     1114 non-null   float64\n",
      " 10  max_acc_y     1114 non-null   float64\n",
      " 11  var_acc_y     1114 non-null   float64\n",
      " 12  std_acc_y     1114 non-null   float64\n",
      " 13  eng_acc_y     1114 non-null   float64\n",
      " 14  gyro_z        1114 non-null   float64\n",
      " 15  mean_gyro_z   1114 non-null   float64\n",
      " 16  min_gyro_z    1114 non-null   float64\n",
      " 17  max_gyro_z    1114 non-null   float64\n",
      " 18  var_gyro_z    1114 non-null   float64\n",
      " 19  std_gyro_z    1114 non-null   float64\n",
      " 20  eng_gyro_z    1114 non-null   float64\n",
      " 21  slope_acc_x   1114 non-null   float64\n",
      " 22  slope_acc_y   1114 non-null   float64\n",
      " 23  slope_gyro_z  1114 non-null   float64\n",
      " 24  category      1114 non-null   object \n",
      " 25  time          1114 non-null   float64\n",
      "dtypes: float64(25), object(1)\n",
      "memory usage: 235.0+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_acc_gyro_xyz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_acc_gyro_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['agg_LLC'] =  np.where(((data['acc_y']>2)|(data['slope_acc_y']>5))|\\\n",
    "                            ((data['gyro_z']<-0.6)|(data['slope_gyro_z']<-0.6)),1,0)\n",
    "\n",
    "data['agg_RLC'] =  np.where(((data['acc_y']<-2)|(data['slope_acc_y']<-5))|\\\n",
    "                           ((data['gyro_z']>0.6)|(data['slope_gyro_z']>0.6)),1,0)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['agg_LT'] =  np.where(((data['acc_y']>2)|(data['slope_acc_y']>5))|\\\n",
    "                            (data['eng_acc_y']>0.3)&((data['gyro_z']>0.6)|(data['slope_gyro_z']>0.6)),1,0)\n",
    "\n",
    "data['agg_RT'] =  np.where(((data['acc_y']<-2)|(data['slope_acc_y']<-5))|\\\n",
    "                         (data['eng_acc_y']>0.3)&((data['gyro_z']<-0.6)|(data['slope_gyro_z']<-0.6)),1,0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>min_acc_x</th>\n",
       "      <th>max_acc_x</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>eng_acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>min_acc_y</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_acc_y</th>\n",
       "      <th>slope_gyro_z</th>\n",
       "      <th>time</th>\n",
       "      <th>agg_ACC</th>\n",
       "      <th>agg_Brake</th>\n",
       "      <th>agg_LLC</th>\n",
       "      <th>agg_RLC</th>\n",
       "      <th>agg_LT</th>\n",
       "      <th>agg_RT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.162598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.086670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.322754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.480225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.226807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.426025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.253906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_acceleration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554.5</th>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.277698</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>0.242419</td>\n",
       "      <td>0.132945</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>-0.076709</td>\n",
       "      <td>-0.352295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>-0.028628</td>\n",
       "      <td>554.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_braking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.0</th>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.272546</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>0.127542</td>\n",
       "      <td>-0.227051</td>\n",
       "      <td>-0.090149</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.010806</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_braking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.5</th>\n",
       "      <td>0.419189</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.234750</td>\n",
       "      <td>0.125461</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>-0.088672</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>555.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_braking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.0</th>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.274780</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.056057</td>\n",
       "      <td>0.236764</td>\n",
       "      <td>0.128759</td>\n",
       "      <td>-0.090088</td>\n",
       "      <td>-0.093872</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010400</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_braking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556.5</th>\n",
       "      <td>0.098145</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>-0.04541</td>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.234750</td>\n",
       "      <td>0.132529</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>-0.100293</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>556.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aggressive_braking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_x  mean_acc_x  min_acc_x  max_acc_x  var_acc_x  std_acc_x  \\\n",
       "second                                                                     \n",
       "0.0     0.162598    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "0.5     0.175781    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "1.0     0.322754    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "1.5     0.480225    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "2.0     0.426025    0.000000    0.00000   0.000000   0.000000   0.000000   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "554.5   0.472900    0.277698   -0.04541   0.631592   0.058767   0.242419   \n",
       "555.0   0.459961    0.272546   -0.04541   0.631592   0.056063   0.236777   \n",
       "555.5   0.419189    0.270386   -0.04541   0.631592   0.055108   0.234750   \n",
       "556.0   0.308838    0.274780   -0.04541   0.631592   0.056057   0.236764   \n",
       "556.5   0.098145    0.283154   -0.04541   0.631592   0.055108   0.234750   \n",
       "\n",
       "        eng_acc_x     acc_y  mean_acc_y  min_acc_y  ...  slope_acc_y  \\\n",
       "second                                              ...                \n",
       "0.0      0.000000 -0.086670    0.000000   0.000000  ...     0.000000   \n",
       "0.5      0.000000 -0.100586    0.000000   0.000000  ...     0.000000   \n",
       "1.0      0.000000 -0.140381    0.000000   0.000000  ...     0.000000   \n",
       "1.5      0.000000 -0.226807    0.000000   0.000000  ...     0.000000   \n",
       "2.0      0.000000 -0.253906    0.000000   0.000000  ...     0.000000   \n",
       "...           ...       ...         ...        ...  ...          ...   \n",
       "554.5    0.132945 -0.431152   -0.076709  -0.352295  ...     0.032104   \n",
       "555.0    0.127542 -0.227051   -0.090149  -0.431152  ...    -0.026880   \n",
       "555.5    0.125461 -0.192871   -0.088672  -0.431152  ...     0.002954   \n",
       "556.0    0.128759 -0.090088   -0.093872  -0.431152  ...    -0.010400   \n",
       "556.5    0.132529 -0.015869   -0.100293  -0.431152  ...    -0.012842   \n",
       "\n",
       "        slope_gyro_z   time  agg_ACC  agg_Brake  agg_LLC  agg_RLC  agg_LT  \\\n",
       "second                                                                      \n",
       "0.0         0.000000    0.0        0          0        0        1       0   \n",
       "0.5         0.000000    0.5        0          0        0        1       0   \n",
       "1.0         0.000000    1.0        0          0        0        0       0   \n",
       "1.5         0.000000    1.5        0          0        0        0       0   \n",
       "2.0         0.000000    2.0        0          0        0        0       0   \n",
       "...              ...    ...      ...        ...      ...      ...     ...   \n",
       "554.5      -0.028628  554.5        0          0        0        1       0   \n",
       "555.0      -0.010806  555.0        0          0        0        1       0   \n",
       "555.5      -0.004162  555.5        0          0        0        1       0   \n",
       "556.0       0.006596  556.0        0          0        0        1       0   \n",
       "556.5       0.007540  556.5        0          0        0        0       0   \n",
       "\n",
       "        agg_RT                 category  \n",
       "second                                   \n",
       "0.0          0  aggressive_acceleration  \n",
       "0.5          0  aggressive_acceleration  \n",
       "1.0          0  aggressive_acceleration  \n",
       "1.5          0  aggressive_acceleration  \n",
       "2.0          0  aggressive_acceleration  \n",
       "...        ...                      ...  \n",
       "554.5        0       aggressive_braking  \n",
       "555.0        0       aggressive_braking  \n",
       "555.5        0       aggressive_braking  \n",
       "556.0        0       aggressive_braking  \n",
       "556.5        0       aggressive_braking  \n",
       "\n",
       "[1114 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['agg_ACC'] =  np.where(((data['acc_x']>2)|(data['slope_acc_x']>5)),1,0)\n",
    "\n",
    "data['agg_Brake'] =  np.where(((data['acc_x']<-2)|(data['slope_acc_x']<-5)),1,0)\n",
    " \n",
    "\n",
    "#agg_ACC_Brake = ['acc_x','slope_acc_x', 'agg_ACC', 'agg_Brake','category']\n",
    "new_true_value = ['agg_ACC','agg_Brake', 'agg_LLC', 'agg_RLC', 'agg_LT', 'agg_RT', 'category']\n",
    "features = ['acc_x', 'mean_acc_x', 'min_acc_x', 'max_acc_x', 'var_acc_x', 'std_acc_x', 'eng_acc_x',\\\n",
    "            'acc_y', 'mean_acc_y', 'min_acc_y', 'max_acc_y', 'var_acc_y', 'std_acc_y', 'eng_acc_y',\\\n",
    "            'gyro_z', 'mean_gyro_z', 'min_gyro_z', 'max_gyro_z', 'var_gyro_z', 'std_gyro_z', \\\n",
    "            'eng_gyro_z', 'slope_acc_x', 'slope_acc_y', 'slope_gyro_z', 'time']\n",
    "data = data[features + new_true_value]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 1114 entries, 0.0 to 556.5\n",
      "Data columns (total 32 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   acc_x         1114 non-null   float64\n",
      " 1   mean_acc_x    1114 non-null   float64\n",
      " 2   min_acc_x     1114 non-null   float64\n",
      " 3   max_acc_x     1114 non-null   float64\n",
      " 4   var_acc_x     1114 non-null   float64\n",
      " 5   std_acc_x     1114 non-null   float64\n",
      " 6   eng_acc_x     1114 non-null   float64\n",
      " 7   acc_y         1114 non-null   float64\n",
      " 8   mean_acc_y    1114 non-null   float64\n",
      " 9   min_acc_y     1114 non-null   float64\n",
      " 10  max_acc_y     1114 non-null   float64\n",
      " 11  var_acc_y     1114 non-null   float64\n",
      " 12  std_acc_y     1114 non-null   float64\n",
      " 13  eng_acc_y     1114 non-null   float64\n",
      " 14  gyro_z        1114 non-null   float64\n",
      " 15  mean_gyro_z   1114 non-null   float64\n",
      " 16  min_gyro_z    1114 non-null   float64\n",
      " 17  max_gyro_z    1114 non-null   float64\n",
      " 18  var_gyro_z    1114 non-null   float64\n",
      " 19  std_gyro_z    1114 non-null   float64\n",
      " 20  eng_gyro_z    1114 non-null   float64\n",
      " 21  slope_acc_x   1114 non-null   float64\n",
      " 22  slope_acc_y   1114 non-null   float64\n",
      " 23  slope_gyro_z  1114 non-null   float64\n",
      " 24  time          1114 non-null   float64\n",
      " 25  agg_ACC       1114 non-null   int32  \n",
      " 26  agg_Brake     1114 non-null   int32  \n",
      " 27  agg_LLC       1114 non-null   int32  \n",
      " 28  agg_RLC       1114 non-null   int32  \n",
      " 29  agg_LT        1114 non-null   int32  \n",
      " 30  agg_RT        1114 non-null   int32  \n",
      " 31  category      1114 non-null   object \n",
      "dtypes: float64(25), int32(6), object(1)\n",
      "memory usage: 261.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabel_count =  0\n",
      "label_count =  1114\n",
      "agg_acc_count =  252\n",
      "agg_brake_count =  224\n",
      "agg_LLC_count =  0\n",
      "agg_LT_count =  350\n",
      "agg_RLC_count =  0\n",
      "agg_RT_count =  288\n",
      "non_agg_count =  0\n"
     ]
    }
   ],
   "source": [
    "#unlabel_count = dataset_acc_gyro[['category']].eq('unlabeled').sum()  This is also ok\n",
    "unlabel_count = ((data['category'])== 'unlabeled').sum()\n",
    "agg_acc_count = ((data['category'])== 'aggressive_acceleration').sum()\n",
    "agg_brake_count = ((data['category'])== 'aggressive_braking').sum()\n",
    "agg_LLC_count = ((data['category'])== 'aggressive_left_lane_change').sum()\n",
    "agg_LT_count = ((data['category'])== 'aggressive_left_turn').sum()\n",
    "agg_RLC_count = ((data['category'])== 'aggressive_right_lane_change').sum()\n",
    "agg_RT_count = ((data['category'])== 'aggressive_right_turn').sum()\n",
    "non_agg_count = ((data['category'])== 'non_aggressive').sum()\n",
    "label_count = ((data['category'])!= 'unlabeled').sum()\n",
    "print('unlabel_count = ', unlabel_count)\n",
    "print('label_count = ', label_count)\n",
    "print('agg_acc_count = ', agg_acc_count)\n",
    "print('agg_brake_count = ', agg_brake_count)\n",
    "print('agg_LLC_count = ', agg_LLC_count)\n",
    "print('agg_LT_count = ', agg_LT_count)\n",
    "print('agg_RLC_count = ', agg_RLC_count)\n",
    "print('agg_RT_count = ', agg_RT_count)\n",
    "print('non_agg_count = ', non_agg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114, 31)\n"
     ]
    }
   ],
   "source": [
    "#del data['category']\n",
    "dataset = data.values\n",
    "X = dataset[:, :-1].astype(float)\n",
    "Y = dataset[:, -1]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x = MinMaxScaler()\n",
    "X = sc_x.fit_transform(X)\n",
    "#X_test = sc_x.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(fold):\n",
    "    return 'unsupervised_model_'+str(fold)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_model_name(fold):\n",
    "    return 'unsupervised_encoder_model_'+str(fold)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supervised_model_name(skf_fold):\n",
    "    return 'semi_supervised_model_'+str(skf_fold)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Fold #1\n",
      "X_train =  (1002, 31, 1)\n",
      "X_test =  (112, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1002 samples, validate on 112 samples\n",
      "Epoch 1/300\n",
      "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2146 - val_loss: 0.1525\n",
      "Epoch 2/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1349 - val_loss: 0.1318\n",
      "Epoch 3/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1302 - val_loss: 0.1220\n",
      "Epoch 4/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1194 - val_loss: 0.1152\n",
      "Epoch 5/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1147 - val_loss: 0.1109\n",
      "Epoch 6/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1116 - val_loss: 0.1065\n",
      "Epoch 7/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1069 - val_loss: 0.1027\n",
      "Epoch 8/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1045 - val_loss: 0.0994\n",
      "Epoch 9/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1028 - val_loss: 0.0983\n",
      "Epoch 10/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1016 - val_loss: 0.0961\n",
      "Epoch 11/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0993 - val_loss: 0.0948\n",
      "Epoch 12/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0979 - val_loss: 0.0932\n",
      "Epoch 13/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0956 - val_loss: 0.0947\n",
      "Epoch 14/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0923 - val_loss: 0.0903\n",
      "Epoch 15/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0899 - val_loss: 0.0870\n",
      "Epoch 16/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0879 - val_loss: 0.0851\n",
      "Epoch 17/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0884 - val_loss: 0.0886\n",
      "Epoch 18/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0875 - val_loss: 0.0836\n",
      "Epoch 19/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0879 - val_loss: 0.0890\n",
      "Epoch 20/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0914 - val_loss: 0.0896\n",
      "Epoch 21/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0894 - val_loss: 0.0864\n",
      "Epoch 22/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0874 - val_loss: 0.0864\n",
      "Epoch 23/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0861\n",
      "Epoch 24/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0870 - val_loss: 0.0846\n",
      "Epoch 25/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0858 - val_loss: 0.0836\n",
      "Epoch 26/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0841 - val_loss: 0.0825\n",
      "Epoch 27/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0828\n",
      "Epoch 28/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0826 - val_loss: 0.0806\n",
      "Epoch 29/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0840 - val_loss: 0.0848\n",
      "Epoch 30/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0832 - val_loss: 0.0849\n",
      "Epoch 31/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0855 - val_loss: 0.0816\n",
      "Epoch 32/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0836 - val_loss: 0.0815\n",
      "Epoch 33/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0817 - val_loss: 0.0799\n",
      "Epoch 34/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0825 - val_loss: 0.0808\n",
      "Epoch 35/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0815 - val_loss: 0.0806\n",
      "Epoch 36/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0794\n",
      "Epoch 37/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0811 - val_loss: 0.0777\n",
      "Epoch 38/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0795 - val_loss: 0.0776\n",
      "Epoch 39/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0773\n",
      "Epoch 40/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0787 - val_loss: 0.0770\n",
      "Epoch 41/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0786 - val_loss: 0.0775\n",
      "Epoch 42/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0788 - val_loss: 0.0764\n",
      "Epoch 43/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0781 - val_loss: 0.0782\n",
      "Epoch 44/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0792 - val_loss: 0.0813\n",
      "Epoch 45/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0763\n",
      "Epoch 46/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0763\n",
      "Epoch 47/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0797 - val_loss: 0.0772\n",
      "Epoch 48/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0777 - val_loss: 0.0757\n",
      "Epoch 49/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0781 - val_loss: 0.0763\n",
      "Epoch 50/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0769 - val_loss: 0.0757\n",
      "Epoch 51/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0800\n",
      "Epoch 52/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0826 - val_loss: 0.0809\n",
      "Epoch 53/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0791 - val_loss: 0.0797\n",
      "Epoch 54/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0827 - val_loss: 0.0800\n",
      "Epoch 55/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0821 - val_loss: 0.0778\n",
      "Epoch 56/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0773 - val_loss: 0.0763\n",
      "Epoch 57/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0770 - val_loss: 0.0753\n",
      "Epoch 58/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0763 - val_loss: 0.0735\n",
      "Epoch 59/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0730\n",
      "Epoch 60/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0752 - val_loss: 0.0728\n",
      "Epoch 61/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0725\n",
      "Epoch 62/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0739\n",
      "Epoch 63/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0735\n",
      "Epoch 64/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0735\n",
      "Epoch 65/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0779\n",
      "Epoch 66/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0755\n",
      "Epoch 67/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0720\n",
      "Epoch 68/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0745 - val_loss: 0.0714\n",
      "Epoch 69/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0713\n",
      "Epoch 70/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0717\n",
      "Epoch 71/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0706\n",
      "Epoch 72/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0702\n",
      "Epoch 73/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0746 - val_loss: 0.0721\n",
      "Epoch 74/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0747 - val_loss: 0.0699\n",
      "Epoch 75/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0732 - val_loss: 0.0725\n",
      "Epoch 76/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0758 - val_loss: 0.0758\n",
      "Epoch 77/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0711\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0736 - val_loss: 0.0712\n",
      "Epoch 79/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0692\n",
      "Epoch 80/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0717 - val_loss: 0.0688\n",
      "Epoch 81/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0714 - val_loss: 0.0692\n",
      "Epoch 82/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0695\n",
      "Epoch 83/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0684\n",
      "Epoch 84/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0706\n",
      "Epoch 85/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0715\n",
      "Epoch 86/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0687\n",
      "Epoch 87/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0715 - val_loss: 0.0682\n",
      "Epoch 88/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0684\n",
      "Epoch 89/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0676\n",
      "Epoch 90/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0676\n",
      "Epoch 91/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0687\n",
      "Epoch 92/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0712 - val_loss: 0.0681\n",
      "Epoch 93/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0677\n",
      "Epoch 94/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0702\n",
      "Epoch 95/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0720\n",
      "Epoch 96/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0709\n",
      "Epoch 97/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0692\n",
      "Epoch 98/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0702\n",
      "Epoch 99/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0723 - val_loss: 0.0699\n",
      "Epoch 100/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0683\n",
      "Epoch 101/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0691\n",
      "Epoch 102/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0715 - val_loss: 0.0707\n",
      "Epoch 103/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0724 - val_loss: 0.0680\n",
      "Epoch 104/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0701 - val_loss: 0.0675\n",
      "Epoch 105/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0670\n",
      "Epoch 106/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0671\n",
      "Epoch 107/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0675\n",
      "Epoch 108/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0668\n",
      "Epoch 109/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0674\n",
      "Epoch 110/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0684\n",
      "Epoch 111/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0670\n",
      "Epoch 112/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0673\n",
      "Epoch 113/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0695\n",
      "Epoch 114/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0681\n",
      "Epoch 115/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0674\n",
      "Epoch 116/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0699\n",
      "Epoch 117/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0722\n",
      "Epoch 118/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0722\n",
      "Epoch 119/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0677\n",
      "Epoch 120/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0674\n",
      "Epoch 121/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0675\n",
      "Epoch 122/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0669\n",
      "Epoch 123/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0671\n",
      "Epoch 124/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0680\n",
      "Epoch 125/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0677\n",
      "Epoch 126/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0675\n",
      "Epoch 127/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0663\n",
      "Epoch 128/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0666\n",
      "Epoch 129/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0669\n",
      "Epoch 130/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0668\n",
      "Epoch 131/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0686\n",
      "Epoch 132/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0692\n",
      "Epoch 133/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0671\n",
      "Epoch 134/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0668\n",
      "Epoch 135/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0667\n",
      "Epoch 136/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0665\n",
      "Epoch 137/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0672\n",
      "Epoch 138/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0689\n",
      "Epoch 139/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0685\n",
      "Epoch 140/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0703 - val_loss: 0.0684\n",
      "Epoch 141/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0664\n",
      "Epoch 142/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0703 - val_loss: 0.0676\n",
      "Epoch 143/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0685\n",
      "Epoch 144/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0668\n",
      "Epoch 145/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0705 - val_loss: 0.0692\n",
      "Epoch 146/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0713 - val_loss: 0.0699\n",
      "Epoch 147/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0717 - val_loss: 0.0672\n",
      "Epoch 148/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0694 - val_loss: 0.0670\n",
      "Epoch 149/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0663\n",
      "Epoch 150/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0660\n",
      "Epoch 151/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0661\n",
      "Epoch 152/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0665\n",
      "Epoch 153/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0673\n",
      "Epoch 154/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0674\n",
      "Epoch 155/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0660\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0662\n",
      "Epoch 157/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0669\n",
      "Epoch 158/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0664\n",
      "Epoch 159/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0682\n",
      "Epoch 160/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0712\n",
      "Epoch 161/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0695\n",
      "Epoch 162/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0707\n",
      "Epoch 163/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0675\n",
      "Epoch 164/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0665\n",
      "Epoch 165/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0657\n",
      "Epoch 166/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0657\n",
      "Epoch 167/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0659\n",
      "Epoch 168/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0657\n",
      "Epoch 169/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0660\n",
      "Epoch 170/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0670\n",
      "Epoch 171/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0661\n",
      "Epoch 172/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0660\n",
      "Epoch 173/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0675\n",
      "Epoch 174/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0673\n",
      "Epoch 175/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0674\n",
      "Epoch 176/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0678\n",
      "Epoch 177/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0667\n",
      "Epoch 178/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0705\n",
      "Epoch 179/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0713\n",
      "Epoch 180/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0702\n",
      "Epoch 181/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0667\n",
      "Epoch 182/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0672\n",
      "Epoch 183/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0678\n",
      "Epoch 184/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0662\n",
      "Epoch 185/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0659\n",
      "Epoch 186/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0657\n",
      "Epoch 187/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0659\n",
      "Epoch 188/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0666\n",
      "Epoch 189/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0669\n",
      "Epoch 190/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0689\n",
      "Epoch 191/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0691\n",
      "Epoch 192/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0666\n",
      "Epoch 193/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0669\n",
      "Epoch 194/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0660\n",
      "Epoch 195/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0658\n",
      "Epoch 196/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0655\n",
      "Epoch 197/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0655\n",
      "Epoch 198/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0654\n",
      "Epoch 199/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0655\n",
      "Epoch 200/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0653\n",
      "Epoch 201/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0653\n",
      "Epoch 202/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0655\n",
      "Epoch 203/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0657\n",
      "Epoch 204/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0676\n",
      "Epoch 205/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0677\n",
      "Epoch 206/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0659\n",
      "Epoch 207/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0664\n",
      "Epoch 208/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0665\n",
      "Epoch 209/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0661\n",
      "Epoch 210/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0679\n",
      "Epoch 211/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0690\n",
      "Epoch 212/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0667\n",
      "Epoch 213/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0669\n",
      "Epoch 214/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0656\n",
      "Epoch 215/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0655\n",
      "Epoch 216/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0657\n",
      "Epoch 217/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0655\n",
      "Epoch 218/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0664\n",
      "Epoch 219/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0677\n",
      "Epoch 220/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0667\n",
      "Epoch 221/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0661\n",
      "Epoch 222/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0651\n",
      "Epoch 223/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0657\n",
      "Epoch 224/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0664\n",
      "Epoch 225/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0670\n",
      "Epoch 226/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0698\n",
      "Epoch 227/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0699\n",
      "Epoch 228/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0665\n",
      "Epoch 229/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0665\n",
      "Epoch 230/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0659\n",
      "Epoch 231/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0658\n",
      "Epoch 232/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0653\n",
      "Epoch 233/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0656\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0655\n",
      "Epoch 235/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0654\n",
      "Epoch 236/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0650\n",
      "Epoch 237/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0652\n",
      "Epoch 238/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0656\n",
      "Epoch 239/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0662\n",
      "Epoch 240/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0683\n",
      "Epoch 241/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0687\n",
      "Epoch 242/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0663\n",
      "Epoch 243/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0663\n",
      "Epoch 244/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0650\n",
      "Epoch 245/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0660\n",
      "Epoch 246/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0665\n",
      "Epoch 247/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0672\n",
      "Epoch 248/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0707\n",
      "Epoch 249/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0713\n",
      "Epoch 250/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0667\n",
      "Epoch 251/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0652\n",
      "Epoch 252/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0650\n",
      "Epoch 253/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0650\n",
      "Epoch 254/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0648\n",
      "Epoch 255/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0648\n",
      "Epoch 256/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0651\n",
      "Epoch 257/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0656\n",
      "Epoch 258/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0648\n",
      "Epoch 259/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0646\n",
      "Epoch 260/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0648\n",
      "Epoch 261/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0650\n",
      "Epoch 262/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0653\n",
      "Epoch 263/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0670\n",
      "Epoch 264/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0708\n",
      "Epoch 265/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0707\n",
      "Epoch 266/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0668\n",
      "Epoch 267/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0655\n",
      "Epoch 268/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0649\n",
      "Epoch 269/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0677 - val_loss: 0.0648\n",
      "Epoch 270/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0673 - val_loss: 0.0648\n",
      "Epoch 271/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0647\n",
      "Epoch 272/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0653\n",
      "Epoch 273/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0676 - val_loss: 0.0660\n",
      "Epoch 274/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0658\n",
      "Epoch 275/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0675 - val_loss: 0.0652\n",
      "Epoch 276/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0678 - val_loss: 0.0650\n",
      "Epoch 277/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0681 - val_loss: 0.0659\n",
      "Epoch 278/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0689 - val_loss: 0.0672\n",
      "Epoch 279/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0661\n",
      "Epoch 280/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0671\n",
      "Epoch 281/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0675\n",
      "Epoch 282/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0696 - val_loss: 0.0650\n",
      "Epoch 283/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0642\n",
      "Epoch 284/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0675 - val_loss: 0.0644\n",
      "Epoch 285/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0669 - val_loss: 0.0643\n",
      "Epoch 286/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0641\n",
      "Epoch 287/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0643\n",
      "Epoch 288/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0655\n",
      "Epoch 289/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0674 - val_loss: 0.0648\n",
      "Epoch 290/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0639\n",
      "Epoch 291/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0651\n",
      "Epoch 292/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0667\n",
      "Epoch 293/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0657\n",
      "Epoch 294/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0683\n",
      "Epoch 295/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0682\n",
      "Epoch 296/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0654\n",
      "Epoch 297/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0653\n",
      "Epoch 298/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0644\n",
      "Epoch 299/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0641\n",
      "Epoch 300/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):328.38392857142856\n",
      "Fold score (RMSE):18.121366630898137\n",
      "Unsupervised Fold #2\n",
      "X_train =  (1002, 31, 1)\n",
      "X_test =  (112, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1002 samples, validate on 112 samples\n",
      "Epoch 1/300\n",
      "1002/1002 [==============================] - 5s 5ms/step - loss: 0.2123 - val_loss: 0.1471\n",
      "Epoch 2/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1365 - val_loss: 0.1303\n",
      "Epoch 3/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1284 - val_loss: 0.1218\n",
      "Epoch 4/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1162 - val_loss: 0.1148\n",
      "Epoch 5/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1110 - val_loss: 0.1058\n",
      "Epoch 6/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1031 - val_loss: 0.1036\n",
      "Epoch 7/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1058 - val_loss: 0.1014\n",
      "Epoch 8/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0997 - val_loss: 0.0990\n",
      "Epoch 9/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0976 - val_loss: 0.0978\n",
      "Epoch 10/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0957 - val_loss: 0.0975\n",
      "Epoch 11/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0934 - val_loss: 0.0970\n",
      "Epoch 12/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0929 - val_loss: 0.0941\n",
      "Epoch 13/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0900 - val_loss: 0.0922\n",
      "Epoch 14/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0909 - val_loss: 0.0932\n",
      "Epoch 15/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0898 - val_loss: 0.0933\n",
      "Epoch 16/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0896 - val_loss: 0.0922\n",
      "Epoch 17/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0873 - val_loss: 0.0899\n",
      "Epoch 18/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0891 - val_loss: 0.0932\n",
      "Epoch 19/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0896 - val_loss: 0.0905\n",
      "Epoch 20/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0873 - val_loss: 0.0912\n",
      "Epoch 21/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0872 - val_loss: 0.0917\n",
      "Epoch 22/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0877 - val_loss: 0.0899\n",
      "Epoch 23/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0897\n",
      "Epoch 24/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0841 - val_loss: 0.0869\n",
      "Epoch 25/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0856 - val_loss: 0.0890\n",
      "Epoch 26/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0859 - val_loss: 0.0868\n",
      "Epoch 27/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0836 - val_loss: 0.0892\n",
      "Epoch 28/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0903\n",
      "Epoch 29/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0853 - val_loss: 0.0844\n",
      "Epoch 30/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0818 - val_loss: 0.0848\n",
      "Epoch 31/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0812 - val_loss: 0.0840\n",
      "Epoch 32/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0818 - val_loss: 0.0861\n",
      "Epoch 33/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0841\n",
      "Epoch 34/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0811 - val_loss: 0.0860\n",
      "Epoch 35/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0812 - val_loss: 0.0849\n",
      "Epoch 36/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0812 - val_loss: 0.0824\n",
      "Epoch 37/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0807 - val_loss: 0.0838\n",
      "Epoch 38/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0829\n",
      "Epoch 39/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0817 - val_loss: 0.0861\n",
      "Epoch 40/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0841 - val_loss: 0.0846\n",
      "Epoch 41/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0836\n",
      "Epoch 42/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0807 - val_loss: 0.0846\n",
      "Epoch 43/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0803 - val_loss: 0.0809\n",
      "Epoch 44/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0818\n",
      "Epoch 45/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0818\n",
      "Epoch 46/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0800\n",
      "Epoch 47/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0778 - val_loss: 0.0808\n",
      "Epoch 48/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0769 - val_loss: 0.0795\n",
      "Epoch 49/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0809\n",
      "Epoch 50/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0796\n",
      "Epoch 51/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0797\n",
      "Epoch 52/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0824\n",
      "Epoch 53/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0779 - val_loss: 0.0787\n",
      "Epoch 54/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0782\n",
      "Epoch 55/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0783\n",
      "Epoch 56/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0775\n",
      "Epoch 57/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 58/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0780\n",
      "Epoch 59/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0762 - val_loss: 0.0790\n",
      "Epoch 60/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0834\n",
      "Epoch 61/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0816\n",
      "Epoch 62/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0770\n",
      "Epoch 63/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0770\n",
      "Epoch 64/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0771\n",
      "Epoch 65/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0756\n",
      "Epoch 66/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0752\n",
      "Epoch 67/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0746\n",
      "Epoch 68/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0724 - val_loss: 0.0745\n",
      "Epoch 69/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0778\n",
      "Epoch 70/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0753\n",
      "Epoch 71/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0776\n",
      "Epoch 72/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0793\n",
      "Epoch 73/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0788\n",
      "Epoch 74/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0776 - val_loss: 0.0751\n",
      "Epoch 75/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0773\n",
      "Epoch 76/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0770\n",
      "Epoch 77/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0733\n",
      "Epoch 79/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0735\n",
      "Epoch 80/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0726\n",
      "Epoch 81/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0734\n",
      "Epoch 82/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0749\n",
      "Epoch 83/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0749\n",
      "Epoch 84/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0733\n",
      "Epoch 85/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0732\n",
      "Epoch 86/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0764\n",
      "Epoch 87/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0764\n",
      "Epoch 88/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0727\n",
      "Epoch 89/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0758\n",
      "Epoch 90/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0757\n",
      "Epoch 91/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0722\n",
      "Epoch 92/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0729\n",
      "Epoch 93/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0734\n",
      "Epoch 94/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0722\n",
      "Epoch 95/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0717\n",
      "Epoch 96/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0722\n",
      "Epoch 97/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0727\n",
      "Epoch 98/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0724\n",
      "Epoch 99/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0725\n",
      "Epoch 100/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0754\n",
      "Epoch 101/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0753\n",
      "Epoch 102/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0722\n",
      "Epoch 103/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0729\n",
      "Epoch 104/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0731\n",
      "Epoch 105/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0718\n",
      "Epoch 106/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0716\n",
      "Epoch 107/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0723\n",
      "Epoch 108/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0731\n",
      "Epoch 109/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0724\n",
      "Epoch 110/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0711\n",
      "Epoch 111/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0699 - val_loss: 0.0722\n",
      "Epoch 112/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0730\n",
      "Epoch 113/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0716\n",
      "Epoch 114/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0716\n",
      "Epoch 115/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0724\n",
      "Epoch 116/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0728\n",
      "Epoch 117/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0718\n",
      "Epoch 118/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0710\n",
      "Epoch 119/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0730\n",
      "Epoch 120/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0733\n",
      "Epoch 121/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0713\n",
      "Epoch 122/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0724\n",
      "Epoch 123/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0730\n",
      "Epoch 124/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0716\n",
      "Epoch 125/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0709\n",
      "Epoch 126/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0711\n",
      "Epoch 127/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0722\n",
      "Epoch 128/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0717\n",
      "Epoch 129/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0705\n",
      "Epoch 130/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0721\n",
      "Epoch 131/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0728\n",
      "Epoch 132/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0715\n",
      "Epoch 133/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0706\n",
      "Epoch 134/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0708\n",
      "Epoch 135/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0715\n",
      "Epoch 136/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0714\n",
      "Epoch 137/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0706\n",
      "Epoch 138/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0716\n",
      "Epoch 139/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0717\n",
      "Epoch 140/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0708\n",
      "Epoch 141/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0706\n",
      "Epoch 142/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0715\n",
      "Epoch 143/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0721\n",
      "Epoch 144/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0716\n",
      "Epoch 145/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0715\n",
      "Epoch 146/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0729\n",
      "Epoch 147/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0728\n",
      "Epoch 148/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0709\n",
      "Epoch 149/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0703\n",
      "Epoch 150/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0685 - val_loss: 0.0706\n",
      "Epoch 151/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0704\n",
      "Epoch 152/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0704\n",
      "Epoch 153/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0689 - val_loss: 0.0705\n",
      "Epoch 154/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0717\n",
      "Epoch 155/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0714\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0702\n",
      "Epoch 157/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0718\n",
      "Epoch 158/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0722\n",
      "Epoch 159/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0708\n",
      "Epoch 160/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0707\n",
      "Epoch 161/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0709\n",
      "Epoch 162/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0708\n",
      "Epoch 163/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0702\n",
      "Epoch 164/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0694\n",
      "Epoch 165/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0699\n",
      "Epoch 166/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0704\n",
      "Epoch 167/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0701\n",
      "Epoch 168/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0702\n",
      "Epoch 169/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0706\n",
      "Epoch 170/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0714\n",
      "Epoch 171/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0707\n",
      "Epoch 172/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0697\n",
      "Epoch 173/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0724\n",
      "Epoch 174/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0728\n",
      "Epoch 175/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0704\n",
      "Epoch 176/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0705\n",
      "Epoch 177/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0704\n",
      "Epoch 178/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0703\n",
      "Epoch 179/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0698\n",
      "Epoch 180/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0692\n",
      "Epoch 181/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0697\n",
      "Epoch 182/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0697\n",
      "Epoch 183/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0694\n",
      "Epoch 184/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0690\n",
      "Epoch 185/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0696\n",
      "Epoch 186/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0708\n",
      "Epoch 187/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0708\n",
      "Epoch 188/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0707\n",
      "Epoch 189/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0713\n",
      "Epoch 190/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0709\n",
      "Epoch 191/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0693\n",
      "Epoch 192/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0708\n",
      "Epoch 193/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0715\n",
      "Epoch 194/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0694\n",
      "Epoch 195/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0704\n",
      "Epoch 196/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0704\n",
      "Epoch 197/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0694\n",
      "Epoch 198/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0688\n",
      "Epoch 199/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0691\n",
      "Epoch 200/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0693\n",
      "Epoch 201/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0690\n",
      "Epoch 202/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0693\n",
      "Epoch 203/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0711\n",
      "Epoch 204/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0706\n",
      "Epoch 205/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0691\n",
      "Epoch 206/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0711\n",
      "Epoch 207/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0721\n",
      "Epoch 208/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0696\n",
      "Epoch 209/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0699\n",
      "Epoch 210/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0703\n",
      "Epoch 211/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0696\n",
      "Epoch 212/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0687\n",
      "Epoch 213/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0682\n",
      "Epoch 214/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0683\n",
      "Epoch 215/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0684\n",
      "Epoch 216/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0683\n",
      "Epoch 217/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0695\n",
      "Epoch 218/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0696\n",
      "Epoch 219/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0690\n",
      "Epoch 220/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0687\n",
      "Epoch 221/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0696\n",
      "Epoch 222/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0715\n",
      "Epoch 223/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0709\n",
      "Epoch 224/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0696\n",
      "Epoch 225/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0707\n",
      "Epoch 226/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0697\n",
      "Epoch 227/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0683\n",
      "Epoch 228/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0688\n",
      "Epoch 229/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0694\n",
      "Epoch 230/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0690\n",
      "Epoch 231/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0689\n",
      "Epoch 232/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0695\n",
      "Epoch 233/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0701\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0689\n",
      "Epoch 235/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0676\n",
      "Epoch 236/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0694\n",
      "Epoch 237/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0706\n",
      "Epoch 238/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0692\n",
      "Epoch 239/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0687\n",
      "Epoch 240/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0688\n",
      "Epoch 241/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0687\n",
      "Epoch 242/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0677\n",
      "Epoch 243/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0678\n",
      "Epoch 244/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0693\n",
      "Epoch 245/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0694\n",
      "Epoch 246/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0683\n",
      "Epoch 247/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0690\n",
      "Epoch 248/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0689\n",
      "Epoch 249/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0682\n",
      "Epoch 250/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0677\n",
      "Epoch 251/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0680\n",
      "Epoch 252/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0689\n",
      "Epoch 253/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0687\n",
      "Epoch 254/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0679\n",
      "Epoch 255/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0698\n",
      "Epoch 256/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0692\n",
      "Epoch 257/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0674\n",
      "Epoch 258/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0690\n",
      "Epoch 259/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0708\n",
      "Epoch 260/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0697\n",
      "Epoch 261/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0678\n",
      "Epoch 262/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0679\n",
      "Epoch 263/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0690\n",
      "Epoch 264/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0678\n",
      "Epoch 265/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 266/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0670\n",
      "Epoch 267/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0658 - val_loss: 0.0679\n",
      "Epoch 268/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0691\n",
      "Epoch 269/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0658\n",
      "Epoch 270/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0670\n",
      "Epoch 271/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0657 - val_loss: 0.0674\n",
      "Epoch 272/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0665\n",
      "Epoch 273/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0665\n",
      "Epoch 274/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0674\n",
      "Epoch 275/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0665\n",
      "Epoch 276/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0663\n",
      "Epoch 277/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0651\n",
      "Epoch 278/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0638\n",
      "Epoch 279/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0631 - val_loss: 0.0637\n",
      "Epoch 280/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0627 - val_loss: 0.0612\n",
      "Epoch 281/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0691\n",
      "Epoch 282/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0696\n",
      "Epoch 283/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0673\n",
      "Epoch 284/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0641\n",
      "Epoch 285/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0670\n",
      "Epoch 286/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0683\n",
      "Epoch 287/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0654\n",
      "Epoch 288/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0636\n",
      "Epoch 289/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0617\n",
      "Epoch 290/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0621 - val_loss: 0.0597\n",
      "Epoch 291/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0602\n",
      "Epoch 292/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0621 - val_loss: 0.0611\n",
      "Epoch 293/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0608 - val_loss: 0.0586\n",
      "Epoch 294/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0581\n",
      "Epoch 295/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0617\n",
      "Epoch 296/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0656 - val_loss: 0.0620\n",
      "Epoch 297/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0645 - val_loss: 0.0587\n",
      "Epoch 298/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0590 - val_loss: 0.0561\n",
      "Epoch 299/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0601 - val_loss: 0.0609\n",
      "Epoch 300/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0589 - val_loss: 0.0562\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):275.0982142857143\n",
      "Fold score (RMSE):16.58608495955915\n",
      "Unsupervised Fold #3\n",
      "X_train =  (1002, 31, 1)\n",
      "X_test =  (112, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1002 samples, validate on 112 samples\n",
      "Epoch 1/300\n",
      "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2114 - val_loss: 0.1366\n",
      "Epoch 2/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1354 - val_loss: 0.1214\n",
      "Epoch 3/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1280 - val_loss: 0.1129\n",
      "Epoch 4/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1154 - val_loss: 0.1059\n",
      "Epoch 5/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1124 - val_loss: 0.1042\n",
      "Epoch 6/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1071 - val_loss: 0.0975\n",
      "Epoch 7/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1031 - val_loss: 0.0990\n",
      "Epoch 8/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1036 - val_loss: 0.0959\n",
      "Epoch 9/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0986 - val_loss: 0.0922\n",
      "Epoch 10/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0957 - val_loss: 0.0935\n",
      "Epoch 11/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0937 - val_loss: 0.0915\n",
      "Epoch 12/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0890\n",
      "Epoch 13/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0909 - val_loss: 0.0886\n",
      "Epoch 14/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0908 - val_loss: 0.0920\n",
      "Epoch 15/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0907 - val_loss: 0.0876\n",
      "Epoch 16/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0908 - val_loss: 0.0903\n",
      "Epoch 17/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0906 - val_loss: 0.0917\n",
      "Epoch 18/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0911 - val_loss: 0.0862\n",
      "Epoch 19/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0918 - val_loss: 0.0915\n",
      "Epoch 20/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0906 - val_loss: 0.0924\n",
      "Epoch 21/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0918 - val_loss: 0.0859\n",
      "Epoch 22/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0860 - val_loss: 0.0852\n",
      "Epoch 23/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0838\n",
      "Epoch 24/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0853 - val_loss: 0.0844\n",
      "Epoch 25/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0859 - val_loss: 0.0864\n",
      "Epoch 26/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0870 - val_loss: 0.0834\n",
      "Epoch 27/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0849 - val_loss: 0.0848\n",
      "Epoch 28/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0841 - val_loss: 0.0849\n",
      "Epoch 29/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0845 - val_loss: 0.0821\n",
      "Epoch 30/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0853 - val_loss: 0.0861\n",
      "Epoch 31/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0855\n",
      "Epoch 32/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0851 - val_loss: 0.0815\n",
      "Epoch 33/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 34/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0820 - val_loss: 0.0809\n",
      "Epoch 35/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0812 - val_loss: 0.0803\n",
      "Epoch 36/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0812 - val_loss: 0.0809\n",
      "Epoch 37/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0802 - val_loss: 0.0801\n",
      "Epoch 38/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0804 - val_loss: 0.0803\n",
      "Epoch 39/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0859\n",
      "Epoch 40/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0835 - val_loss: 0.0858\n",
      "Epoch 41/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0838 - val_loss: 0.0790\n",
      "Epoch 42/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0802\n",
      "Epoch 43/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0834\n",
      "Epoch 44/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0806 - val_loss: 0.0818\n",
      "Epoch 45/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0815 - val_loss: 0.0796\n",
      "Epoch 46/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0807\n",
      "Epoch 47/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0797 - val_loss: 0.0777\n",
      "Epoch 48/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0779\n",
      "Epoch 49/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0788 - val_loss: 0.0787\n",
      "Epoch 50/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0772 - val_loss: 0.0778\n",
      "Epoch 51/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0774 - val_loss: 0.0765\n",
      "Epoch 52/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0784 - val_loss: 0.0795\n",
      "Epoch 53/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0792\n",
      "Epoch 54/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0781 - val_loss: 0.0754\n",
      "Epoch 55/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0771\n",
      "Epoch 56/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0761\n",
      "Epoch 57/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0761\n",
      "Epoch 58/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0778 - val_loss: 0.0773\n",
      "Epoch 59/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0753\n",
      "Epoch 60/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0772 - val_loss: 0.0765\n",
      "Epoch 61/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0765 - val_loss: 0.0762\n",
      "Epoch 62/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0740\n",
      "Epoch 63/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0751\n",
      "Epoch 64/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0738\n",
      "Epoch 65/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0737\n",
      "Epoch 66/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0754\n",
      "Epoch 67/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0732\n",
      "Epoch 68/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0753\n",
      "Epoch 69/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0767\n",
      "Epoch 70/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0730\n",
      "Epoch 71/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0749\n",
      "Epoch 72/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0741\n",
      "Epoch 73/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0732\n",
      "Epoch 74/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0741\n",
      "Epoch 75/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0733\n",
      "Epoch 76/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0735\n",
      "Epoch 77/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0729\n",
      "Epoch 79/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0733\n",
      "Epoch 80/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0737\n",
      "Epoch 81/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0728\n",
      "Epoch 82/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0729\n",
      "Epoch 83/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0734 - val_loss: 0.0731\n",
      "Epoch 84/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0726\n",
      "Epoch 85/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0731\n",
      "Epoch 86/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0734\n",
      "Epoch 87/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0727\n",
      "Epoch 88/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0728 - val_loss: 0.0732\n",
      "Epoch 89/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0743\n",
      "Epoch 90/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0735\n",
      "Epoch 91/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 92/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0751\n",
      "Epoch 93/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0753\n",
      "Epoch 94/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0717\n",
      "Epoch 95/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0727 - val_loss: 0.0728\n",
      "Epoch 96/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0732\n",
      "Epoch 97/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0723 - val_loss: 0.0710\n",
      "Epoch 98/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0715\n",
      "Epoch 99/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0710 - val_loss: 0.0718\n",
      "Epoch 100/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0704\n",
      "Epoch 101/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0713\n",
      "Epoch 102/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0734\n",
      "Epoch 103/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0712\n",
      "Epoch 104/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0706\n",
      "Epoch 105/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0744\n",
      "Epoch 106/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0726\n",
      "Epoch 107/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0721 - val_loss: 0.0707\n",
      "Epoch 108/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0719 - val_loss: 0.0728\n",
      "Epoch 109/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0732 - val_loss: 0.0737\n",
      "Epoch 110/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0732\n",
      "Epoch 111/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0704\n",
      "Epoch 112/300\n",
      "1002/1002 [==============================] - 2s 1ms/step - loss: 0.0714 - val_loss: 0.0716\n",
      "Epoch 113/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0726\n",
      "Epoch 114/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0703\n",
      "Epoch 115/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0701 - val_loss: 0.0697\n",
      "Epoch 116/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0700 - val_loss: 0.0698\n",
      "Epoch 117/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0695\n",
      "Epoch 118/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0695\n",
      "Epoch 119/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0705\n",
      "Epoch 120/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0711\n",
      "Epoch 121/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0706\n",
      "Epoch 122/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0696\n",
      "Epoch 123/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0705\n",
      "Epoch 124/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0709\n",
      "Epoch 125/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0705\n",
      "Epoch 126/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0726\n",
      "Epoch 127/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0717\n",
      "Epoch 128/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0696\n",
      "Epoch 129/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 130/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0704\n",
      "Epoch 131/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0692\n",
      "Epoch 132/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0695\n",
      "Epoch 133/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0709\n",
      "Epoch 134/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0700\n",
      "Epoch 135/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0690 - val_loss: 0.0691\n",
      "Epoch 136/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0701\n",
      "Epoch 137/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0707\n",
      "Epoch 138/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0701\n",
      "Epoch 139/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0708\n",
      "Epoch 140/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0720 - val_loss: 0.0733\n",
      "Epoch 141/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0728\n",
      "Epoch 142/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0694\n",
      "Epoch 143/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0693\n",
      "Epoch 144/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0696\n",
      "Epoch 145/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0689\n",
      "Epoch 146/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0694\n",
      "Epoch 147/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0706\n",
      "Epoch 148/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0693\n",
      "Epoch 149/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0687 - val_loss: 0.0687\n",
      "Epoch 150/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0685\n",
      "Epoch 151/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0685\n",
      "Epoch 152/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0688\n",
      "Epoch 153/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0685 - val_loss: 0.0689\n",
      "Epoch 154/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0696\n",
      "Epoch 155/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0699\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 2s 1ms/step - loss: 0.0693 - val_loss: 0.0687\n",
      "Epoch 157/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0685 - val_loss: 0.0688\n",
      "Epoch 158/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0700\n",
      "Epoch 159/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 160/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0708\n",
      "Epoch 161/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0717\n",
      "Epoch 162/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0692\n",
      "Epoch 163/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0685\n",
      "Epoch 164/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0690\n",
      "Epoch 165/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0685\n",
      "Epoch 166/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0687\n",
      "Epoch 167/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0701\n",
      "Epoch 168/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0708\n",
      "Epoch 169/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0706\n",
      "Epoch 170/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0683\n",
      "Epoch 171/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0684\n",
      "Epoch 172/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0694\n",
      "Epoch 173/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0683\n",
      "Epoch 174/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0696\n",
      "Epoch 175/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0707\n",
      "Epoch 176/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0689\n",
      "Epoch 177/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0683\n",
      "Epoch 178/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0678\n",
      "Epoch 179/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0679\n",
      "Epoch 180/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0688\n",
      "Epoch 181/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0692\n",
      "Epoch 182/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0703\n",
      "Epoch 183/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0706\n",
      "Epoch 184/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0679\n",
      "Epoch 185/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0693\n",
      "Epoch 186/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 187/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0721\n",
      "Epoch 188/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0731\n",
      "Epoch 189/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0711\n",
      "Epoch 190/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0695\n",
      "Epoch 191/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0690\n",
      "Epoch 192/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0682\n",
      "Epoch 193/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0680\n",
      "Epoch 194/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0683\n",
      "Epoch 195/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0679\n",
      "Epoch 196/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0677\n",
      "Epoch 197/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0679\n",
      "Epoch 198/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0682\n",
      "Epoch 199/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0682\n",
      "Epoch 200/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0681\n",
      "Epoch 201/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0686\n",
      "Epoch 202/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0688\n",
      "Epoch 203/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0677\n",
      "Epoch 204/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0676 - val_loss: 0.0679\n",
      "Epoch 205/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0685\n",
      "Epoch 206/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0675\n",
      "Epoch 207/300\n",
      "1002/1002 [==============================] - 2s 1ms/step - loss: 0.0675 - val_loss: 0.0679\n",
      "Epoch 208/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0686\n",
      "Epoch 209/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0682 - val_loss: 0.0676\n",
      "Epoch 210/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0671 - val_loss: 0.0671\n",
      "Epoch 211/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0681\n",
      "Epoch 212/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0676\n",
      "Epoch 213/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0674\n",
      "Epoch 214/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0686\n",
      "Epoch 215/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0685\n",
      "Epoch 216/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0674\n",
      "Epoch 217/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0675\n",
      "Epoch 218/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0683\n",
      "Epoch 219/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0680\n",
      "Epoch 220/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0670\n",
      "Epoch 221/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0670\n",
      "Epoch 222/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0695\n",
      "Epoch 223/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0688\n",
      "Epoch 224/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0693\n",
      "Epoch 225/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0696\n",
      "Epoch 226/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0686\n",
      "Epoch 227/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0681\n",
      "Epoch 228/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0673\n",
      "Epoch 229/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0666\n",
      "Epoch 230/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0661\n",
      "Epoch 231/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0661 - val_loss: 0.0654\n",
      "Epoch 232/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0649\n",
      "Epoch 233/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0647\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0646 - val_loss: 0.0682\n",
      "Epoch 235/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0669\n",
      "Epoch 236/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0652\n",
      "Epoch 237/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0667\n",
      "Epoch 238/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0646\n",
      "Epoch 239/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0636 - val_loss: 0.0618\n",
      "Epoch 240/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0622\n",
      "Epoch 241/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0668\n",
      "Epoch 242/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0753\n",
      "Epoch 243/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0674\n",
      "Epoch 244/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0676 - val_loss: 0.0649\n",
      "Epoch 245/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0636\n",
      "Epoch 246/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0620\n",
      "Epoch 247/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0599\n",
      "Epoch 248/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0579\n",
      "Epoch 249/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0574\n",
      "Epoch 250/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0575\n",
      "Epoch 251/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 252/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0575\n",
      "Epoch 253/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0589 - val_loss: 0.0606\n",
      "Epoch 254/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0599 - val_loss: 0.0630\n",
      "Epoch 255/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0661 - val_loss: 0.0631\n",
      "Epoch 256/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0659\n",
      "Epoch 257/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0682\n",
      "Epoch 258/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0638\n",
      "Epoch 259/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0610\n",
      "Epoch 260/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0613 - val_loss: 0.0590\n",
      "Epoch 261/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0591 - val_loss: 0.0580\n",
      "Epoch 262/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 263/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0624 - val_loss: 0.0605\n",
      "Epoch 264/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0618\n",
      "Epoch 265/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0639 - val_loss: 0.0642\n",
      "Epoch 266/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0603 - val_loss: 0.0588\n",
      "Epoch 267/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0576 - val_loss: 0.0566\n",
      "Epoch 268/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0564\n",
      "Epoch 269/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0556\n",
      "Epoch 270/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 271/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0588 - val_loss: 0.0569\n",
      "Epoch 272/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0574\n",
      "Epoch 273/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0604\n",
      "Epoch 274/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0578 - val_loss: 0.0567\n",
      "Epoch 275/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0546\n",
      "Epoch 276/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0542 - val_loss: 0.0559\n",
      "Epoch 277/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0567 - val_loss: 0.0557\n",
      "Epoch 278/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0552 - val_loss: 0.0592\n",
      "Epoch 279/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0571\n",
      "Epoch 280/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0578\n",
      "Epoch 281/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0598 - val_loss: 0.0606\n",
      "Epoch 282/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0627\n",
      "Epoch 283/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0636 - val_loss: 0.0603\n",
      "Epoch 284/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0615 - val_loss: 0.0569\n",
      "Epoch 285/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0543\n",
      "Epoch 286/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0527\n",
      "Epoch 287/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0530 - val_loss: 0.0527\n",
      "Epoch 288/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0537 - val_loss: 0.0520\n",
      "Epoch 289/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0527 - val_loss: 0.0519\n",
      "Epoch 290/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0525 - val_loss: 0.0532\n",
      "Epoch 291/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0519\n",
      "Epoch 292/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0537\n",
      "Epoch 293/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0561 - val_loss: 0.0562\n",
      "Epoch 294/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0528\n",
      "Epoch 295/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0542 - val_loss: 0.0507\n",
      "Epoch 296/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0513\n",
      "Epoch 297/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0542 - val_loss: 0.0516\n",
      "Epoch 298/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0527 - val_loss: 0.0568\n",
      "Epoch 299/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0585\n",
      "Epoch 300/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0593 - val_loss: 0.0556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):204.95535714285714\n",
      "Fold score (RMSE):14.316261982195531\n",
      "Unsupervised Fold #4\n",
      "X_train =  (1002, 31, 1)\n",
      "X_test =  (112, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1002 samples, validate on 112 samples\n",
      "Epoch 1/300\n",
      "1002/1002 [==============================] - 5s 5ms/step - loss: 0.2045 - val_loss: 0.1371\n",
      "Epoch 2/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1313 - val_loss: 0.1247\n",
      "Epoch 3/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1237 - val_loss: 0.1171\n",
      "Epoch 4/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1142 - val_loss: 0.1110\n",
      "Epoch 5/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1098 - val_loss: 0.1030\n",
      "Epoch 6/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.1027 - val_loss: 0.0982\n",
      "Epoch 7/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1035 - val_loss: 0.0975\n",
      "Epoch 8/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.1003 - val_loss: 0.0945\n",
      "Epoch 9/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0971 - val_loss: 0.0928\n",
      "Epoch 10/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0962 - val_loss: 0.0908\n",
      "Epoch 11/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0924 - val_loss: 0.0910\n",
      "Epoch 12/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0923 - val_loss: 0.0869\n",
      "Epoch 13/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0891 - val_loss: 0.0875\n",
      "Epoch 14/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0906 - val_loss: 0.0932\n",
      "Epoch 15/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0922 - val_loss: 0.0848\n",
      "Epoch 16/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0873 - val_loss: 0.0866\n",
      "Epoch 17/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0873 - val_loss: 0.0857\n",
      "Epoch 18/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0868 - val_loss: 0.0842\n",
      "Epoch 19/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0860 - val_loss: 0.0825\n",
      "Epoch 20/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0843 - val_loss: 0.0835\n",
      "Epoch 21/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0855 - val_loss: 0.0881\n",
      "Epoch 22/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0879 - val_loss: 0.0819\n",
      "Epoch 23/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0835 - val_loss: 0.0811\n",
      "Epoch 24/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0828 - val_loss: 0.0806\n",
      "Epoch 25/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0829 - val_loss: 0.0820\n",
      "Epoch 26/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0828 - val_loss: 0.0800\n",
      "Epoch 27/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0838\n",
      "Epoch 28/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0863 - val_loss: 0.0840\n",
      "Epoch 29/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0835 - val_loss: 0.0805\n",
      "Epoch 30/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0825 - val_loss: 0.0795\n",
      "Epoch 31/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0809 - val_loss: 0.0786\n",
      "Epoch 32/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0795\n",
      "Epoch 33/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0802 - val_loss: 0.0775\n",
      "Epoch 34/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0775\n",
      "Epoch 35/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0792 - val_loss: 0.0775\n",
      "Epoch 36/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0778\n",
      "Epoch 37/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0790 - val_loss: 0.0766\n",
      "Epoch 38/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0765\n",
      "Epoch 39/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0779\n",
      "Epoch 40/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0784 - val_loss: 0.0763\n",
      "Epoch 41/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0780 - val_loss: 0.0758\n",
      "Epoch 42/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0754\n",
      "Epoch 43/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0751\n",
      "Epoch 44/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0776 - val_loss: 0.0757\n",
      "Epoch 45/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0749\n",
      "Epoch 46/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0766 - val_loss: 0.0746\n",
      "Epoch 47/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0762 - val_loss: 0.0740\n",
      "Epoch 48/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0759 - val_loss: 0.0742\n",
      "Epoch 49/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0766 - val_loss: 0.0756\n",
      "Epoch 50/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0797 - val_loss: 0.0851\n",
      "Epoch 51/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0849 - val_loss: 0.0794\n",
      "Epoch 52/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0786 - val_loss: 0.0770\n",
      "Epoch 53/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0787 - val_loss: 0.0752\n",
      "Epoch 54/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0742\n",
      "Epoch 55/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0744\n",
      "Epoch 56/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0737\n",
      "Epoch 57/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0736\n",
      "Epoch 58/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0759 - val_loss: 0.0749\n",
      "Epoch 59/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0727\n",
      "Epoch 60/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0732\n",
      "Epoch 61/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0738\n",
      "Epoch 62/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0725\n",
      "Epoch 63/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0730\n",
      "Epoch 64/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0726\n",
      "Epoch 65/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0751\n",
      "Epoch 66/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0757 - val_loss: 0.0723\n",
      "Epoch 67/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0732\n",
      "Epoch 68/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0741\n",
      "Epoch 69/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0719\n",
      "Epoch 70/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0720\n",
      "Epoch 71/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0743\n",
      "Epoch 72/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0711\n",
      "Epoch 73/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0725\n",
      "Epoch 74/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0766 - val_loss: 0.0774\n",
      "Epoch 75/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0730\n",
      "Epoch 76/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0750 - val_loss: 0.0724\n",
      "Epoch 77/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0756 - val_loss: 0.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0722\n",
      "Epoch 79/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0721\n",
      "Epoch 80/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0746\n",
      "Epoch 81/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0744\n",
      "Epoch 82/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0763 - val_loss: 0.0765\n",
      "Epoch 83/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0698\n",
      "Epoch 84/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0735\n",
      "Epoch 85/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0743\n",
      "Epoch 86/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0756 - val_loss: 0.0705\n",
      "Epoch 87/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0720\n",
      "Epoch 88/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0739\n",
      "Epoch 89/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0696\n",
      "Epoch 90/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0697\n",
      "Epoch 91/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0694\n",
      "Epoch 92/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0685\n",
      "Epoch 93/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0684\n",
      "Epoch 94/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0687\n",
      "Epoch 95/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0682\n",
      "Epoch 96/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 97/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0689\n",
      "Epoch 98/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0695\n",
      "Epoch 99/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0699\n",
      "Epoch 100/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0687\n",
      "Epoch 101/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0719\n",
      "Epoch 102/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0732\n",
      "Epoch 103/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0685\n",
      "Epoch 104/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0724 - val_loss: 0.0698\n",
      "Epoch 105/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0700\n",
      "Epoch 106/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0723 - val_loss: 0.0682\n",
      "Epoch 107/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0709 - val_loss: 0.0681\n",
      "Epoch 108/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0693\n",
      "Epoch 109/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0675\n",
      "Epoch 110/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0676\n",
      "Epoch 111/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0678\n",
      "Epoch 112/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0672\n",
      "Epoch 113/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0675\n",
      "Epoch 114/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0701 - val_loss: 0.0677\n",
      "Epoch 115/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0683\n",
      "Epoch 116/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0690\n",
      "Epoch 117/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0705 - val_loss: 0.0669\n",
      "Epoch 118/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0673\n",
      "Epoch 119/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0686\n",
      "Epoch 120/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0674\n",
      "Epoch 121/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0702 - val_loss: 0.0677\n",
      "Epoch 122/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0675\n",
      "Epoch 123/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0705 - val_loss: 0.0679\n",
      "Epoch 124/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0688\n",
      "Epoch 125/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0667\n",
      "Epoch 126/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0673\n",
      "Epoch 127/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0682\n",
      "Epoch 128/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0671\n",
      "Epoch 129/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0671\n",
      "Epoch 130/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0673\n",
      "Epoch 131/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0675\n",
      "Epoch 132/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0678\n",
      "Epoch 133/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0664\n",
      "Epoch 134/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0666\n",
      "Epoch 135/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0667\n",
      "Epoch 136/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0665\n",
      "Epoch 137/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0668\n",
      "Epoch 138/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0676\n",
      "Epoch 139/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0671\n",
      "Epoch 140/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0677\n",
      "Epoch 141/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0662\n",
      "Epoch 142/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0666\n",
      "Epoch 143/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0669\n",
      "Epoch 144/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0663\n",
      "Epoch 145/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0666\n",
      "Epoch 146/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0680\n",
      "Epoch 147/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0669\n",
      "Epoch 148/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0672\n",
      "Epoch 149/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0660\n",
      "Epoch 150/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0661\n",
      "Epoch 151/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0667\n",
      "Epoch 152/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0663\n",
      "Epoch 153/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0691 - val_loss: 0.0665\n",
      "Epoch 154/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0682\n",
      "Epoch 155/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0711 - val_loss: 0.0670\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0672\n",
      "Epoch 157/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0692 - val_loss: 0.0660\n",
      "Epoch 158/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0664\n",
      "Epoch 159/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0697 - val_loss: 0.0668\n",
      "Epoch 160/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0661\n",
      "Epoch 161/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0689 - val_loss: 0.0665\n",
      "Epoch 162/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0699 - val_loss: 0.0679\n",
      "Epoch 163/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0664\n",
      "Epoch 164/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0663\n",
      "Epoch 165/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0658\n",
      "Epoch 166/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0658\n",
      "Epoch 167/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0660\n",
      "Epoch 168/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0661\n",
      "Epoch 169/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0661\n",
      "Epoch 170/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0666\n",
      "Epoch 171/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0657\n",
      "Epoch 172/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0680 - val_loss: 0.0657\n",
      "Epoch 173/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0656\n",
      "Epoch 174/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0655\n",
      "Epoch 175/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0657\n",
      "Epoch 176/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0662\n",
      "Epoch 177/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0662\n",
      "Epoch 178/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0665\n",
      "Epoch 179/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0655\n",
      "Epoch 180/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0658\n",
      "Epoch 181/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0662\n",
      "Epoch 182/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0656\n",
      "Epoch 183/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0663\n",
      "Epoch 184/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0692 - val_loss: 0.0671\n",
      "Epoch 185/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0695 - val_loss: 0.0658\n",
      "Epoch 186/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0657\n",
      "Epoch 187/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0652\n",
      "Epoch 188/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0652\n",
      "Epoch 189/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0652\n",
      "Epoch 190/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0650\n",
      "Epoch 191/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0651\n",
      "Epoch 192/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0653\n",
      "Epoch 193/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0649\n",
      "Epoch 194/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0648\n",
      "Epoch 195/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0650\n",
      "Epoch 196/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0649\n",
      "Epoch 197/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0645\n",
      "Epoch 198/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0647\n",
      "Epoch 199/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0657\n",
      "Epoch 200/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0646\n",
      "Epoch 201/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0651\n",
      "Epoch 202/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0659\n",
      "Epoch 203/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0652\n",
      "Epoch 204/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0654\n",
      "Epoch 205/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0666\n",
      "Epoch 206/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0676\n",
      "Epoch 207/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0663\n",
      "Epoch 208/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0641\n",
      "Epoch 209/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0640\n",
      "Epoch 210/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0653\n",
      "Epoch 211/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0649\n",
      "Epoch 212/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0643\n",
      "Epoch 213/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0677\n",
      "Epoch 214/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0662\n",
      "Epoch 215/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0658\n",
      "Epoch 216/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0661\n",
      "Epoch 217/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0656\n",
      "Epoch 218/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0662\n",
      "Epoch 219/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0650\n",
      "Epoch 220/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0649\n",
      "Epoch 221/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0649\n",
      "Epoch 222/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0642\n",
      "Epoch 223/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0644\n",
      "Epoch 224/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0667 - val_loss: 0.0649\n",
      "Epoch 225/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0643\n",
      "Epoch 226/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0642\n",
      "Epoch 227/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0625\n",
      "Epoch 228/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0657 - val_loss: 0.0628\n",
      "Epoch 229/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0636\n",
      "Epoch 230/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0633\n",
      "Epoch 231/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0617\n",
      "Epoch 232/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0682 - val_loss: 0.0632\n",
      "Epoch 233/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0626\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0628\n",
      "Epoch 235/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0668 - val_loss: 0.0602\n",
      "Epoch 236/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0674 - val_loss: 0.0621\n",
      "Epoch 237/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0656\n",
      "Epoch 238/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0626\n",
      "Epoch 239/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0636 - val_loss: 0.0594\n",
      "Epoch 240/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0615 - val_loss: 0.0589\n",
      "Epoch 241/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0591\n",
      "Epoch 242/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0591\n",
      "Epoch 243/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0595\n",
      "Epoch 244/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0606\n",
      "Epoch 245/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0658 - val_loss: 0.0614\n",
      "Epoch 246/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0613\n",
      "Epoch 247/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0589\n",
      "Epoch 248/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0635 - val_loss: 0.0601\n",
      "Epoch 249/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0621 - val_loss: 0.0568\n",
      "Epoch 250/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0591 - val_loss: 0.0564\n",
      "Epoch 251/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0571\n",
      "Epoch 252/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0554\n",
      "Epoch 253/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0582 - val_loss: 0.0557\n",
      "Epoch 254/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0565\n",
      "Epoch 255/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0603 - val_loss: 0.0571\n",
      "Epoch 256/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0585 - val_loss: 0.0574\n",
      "Epoch 257/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0558\n",
      "Epoch 258/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0576\n",
      "Epoch 259/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0629 - val_loss: 0.0583\n",
      "Epoch 260/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0611 - val_loss: 0.0575\n",
      "Epoch 261/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0572\n",
      "Epoch 262/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0599\n",
      "Epoch 263/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0566\n",
      "Epoch 264/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0597 - val_loss: 0.0566\n",
      "Epoch 265/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0595 - val_loss: 0.0551\n",
      "Epoch 266/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0588 - val_loss: 0.0547\n",
      "Epoch 267/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0591 - val_loss: 0.0559\n",
      "Epoch 268/300\n",
      "1002/1002 [==============================] - 2s 2ms/step - loss: 0.0605 - val_loss: 0.0568\n",
      "Epoch 269/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0607 - val_loss: 0.0567\n",
      "Epoch 270/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0608 - val_loss: 0.0567\n",
      "Epoch 271/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0610 - val_loss: 0.0556\n",
      "Epoch 272/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0598 - val_loss: 0.0567\n",
      "Epoch 273/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0584 - val_loss: 0.0544\n",
      "Epoch 274/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0552\n",
      "Epoch 275/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0565\n",
      "Epoch 276/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0566\n",
      "Epoch 277/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0603 - val_loss: 0.0595\n",
      "Epoch 278/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0570\n",
      "Epoch 279/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0575\n",
      "Epoch 280/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0584 - val_loss: 0.0550\n",
      "Epoch 281/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0569 - val_loss: 0.0551\n",
      "Epoch 282/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0535\n",
      "Epoch 283/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0566 - val_loss: 0.0535\n",
      "Epoch 284/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0567 - val_loss: 0.0537\n",
      "Epoch 285/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0550\n",
      "Epoch 286/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
      "Epoch 287/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0581 - val_loss: 0.0548\n",
      "Epoch 288/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0549\n",
      "Epoch 289/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0575 - val_loss: 0.0538\n",
      "Epoch 290/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0541\n",
      "Epoch 291/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0527\n",
      "Epoch 292/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0555 - val_loss: 0.0540\n",
      "Epoch 293/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0566 - val_loss: 0.0545\n",
      "Epoch 294/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0556\n",
      "Epoch 295/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0538\n",
      "Epoch 296/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0587 - val_loss: 0.0543\n",
      "Epoch 297/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0533\n",
      "Epoch 298/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0533\n",
      "Epoch 299/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0557 - val_loss: 0.0523\n",
      "Epoch 300/300\n",
      "1002/1002 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0524\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3iV5fnA8e99TjYZQBIIJIwgM2wMS1HEwXChxSIiTiy11aptadXaav21ttpaV6tSFKwbB1qpouAAFZkBQcIOYSQQyN475/n98RySQ3LABHNIgPtzXbk8513nfvPKufNsMcaglFJK1edo6QCUUkq1TpoglFJKeaUJQimllFeaIJRSSnmlCUIppZRXmiCUUkp5pQlCqR9ARLqLiBERv0Yce7OIrPih11HqZNEEoc4YIrJXRCpFJKre9o3uL+fuLROZUq2TJgh1ptkDXHfkjYgMBIJbLhylWi9NEOpM8ypwo8f7m4BXPA8QkQgReUVEskRkn4j8XkQc7n1OEXlcRLJFJBW4zMu580QkQ0QOiMifRcTZ1CBFpLOILBKRXBFJEZGfeOwbISJJIlIoIodF5An39iAReU1EckQkX0TWiUjHpn62UkdoglBnmtVAuIj0c39xXwu8Vu+YfwIRQA9gLDah3OLe9xPgcmAokAhcU+/cl4FqoKf7mPHAbScQ55tAOtDZ/Rl/EZGL3PueBp42xoQDZwFvu7ff5I67CxAJ3A6UncBnKwVoglBnpiOliEuA7cCBIzs8ksb9xpgiY8xe4B/ADe5DpgJPGWPSjDG5wF89zu0ITALuMcaUGGMygSeBaU0JTkS6AGOAe40x5caYjcCLHjFUAT1FJMoYU2yMWe2xPRLoaYypMcasN8YUNuWzlfKkCUKdiV4FpgM3U696CYgCAoB9Htv2AbHu152BtHr7jugG+AMZ7iqefODfQIcmxtcZyDXGFB0jhplAb2C7uxrpco/7WgIsEJGDIvI3EfFv4mcrVUsThDrjGGP2YRurLwXeq7c7G/uXeDePbV2pK2VkYKtwPPcdkQZUAFHGmLbun3BjTP8mhngQaC8iYd5iMMbsMsZch008jwHvikgbY0yVMeZhY0wCcA62KuxGlDpBmiDUmWomcKExpsRzozGmBlun/4iIhIlIN+BX1LVTvA3cJSJxItIOuM/j3AxgKfAPEQkXEYeInCUiY5sSmDEmDVgJ/NXd8DzIHe/rACIyQ0SijTEuIN99Wo2IjBORge5qskJsoqtpymcr5UkThDojGWN2G2OSjrH7F0AJkAqsAN4A5rv3vYCtxtkEbKBhCeRGbBXVViAPeBfodAIhXgd0x5Ym3gceMsZ86t43EdgiIsXYButpxphyIMb9eYXANuBLGjbAK9VoogsGKaWU8kZLEEoppbzSBKGUUsorTRBKKaW80gShlFLKq9NqauGoqCjTvXv3lg5DKaVOGevXr882xkR723daJYju3buTlHSsnotKKaXqE5F9x9qnVUxKKaW80gShlFLKK00QSimlvDqt2iCUUqqpqqqqSE9Pp7y8vKVD8amgoCDi4uLw92/8BL+aIJRSZ7T09HTCwsLo3r07ItLS4fiEMYacnBzS09OJj49v9HlaxaSUOqOVl5cTGRl52iYHABEhMjKyyaUkTRBKqTPe6ZwcjjiRe9QEATzz+S6+3JnV0mEopVSrogkCeH75blbs0gShlDr58vPzee6555p83qWXXkp+fv73H/gDaIIAnA7BpctiKKVawLESRE3N8RcDXLx4MW3btvVVWID2YgJABGo0QyilWsB9993H7t27GTJkCP7+/oSGhtKpUyc2btzI1q1bueqqq0hLS6O8vJy7776bWbNmAXVTCxUXFzNp0iTGjBnDypUriY2N5YMPPiA4OPgHx+bTBCEiE7FLIjqBF40xj9bbfz1wr/ttMfAzY8ymxpzbnGwJQhOEUme6h/+3ha0HC5v1mgmdw3noiv7H3P/oo4+SnJzMxo0bWb58OZdddhnJycm13VHnz59P+/btKSsrY/jw4UyZMoXIyMijrrFr1y7efPNNXnjhBaZOncrChQuZMWPGD47dZ1VM7oXTnwUmAQnAdSKSUO+wPcBYY8wg4E/A3Cac22ycIlqCUEq1CiNGjDhqrMIzzzzD4MGDGTVqFGlpaezatavBOfHx8QwZMgSAs88+m7179zZLLL4sQYwAUowxqQAisgCYjF3MHQBjzEqP41cDcY09tzk5tA1CKQXH/Uv/ZGnTpk3t6+XLl/PZZ5+xatUqQkJCuOCCC7yOZQgMDKx97XQ6KSsra5ZYfNlIHQukebxPd287lpnAx009V0RmiUiSiCRlZZ1YTySHgEszhFKqBYSFhVFUVOR1X0FBAe3atSMkJITt27ezevXqkxqbL0sQ3kZleP0WFpFx2AQxpqnnGmPm4q6aSkxMPKFveacINdoGoZRqAZGRkZx77rkMGDCA4OBgOnbsWLtv4sSJzJkzh0GDBtGnTx9GjRp1UmPzZYJIB7p4vI8DDtY/SEQGAS8Ck4wxOU05t7k4HKIlCKVUi3njjTe8bg8MDOTjjz/2uu9IO0NUVBTJycm122fPnt1scfmyimkd0EtE4kUkAJgGLPI8QES6Au8BNxhjdjbl3OakvZiUUqohn5UgjDHVInInsATbVXW+MWaLiNzu3j8HeBCIBJ5zzxNSbYxJPNa5vorVIUKN5gellDqKT8dBGGMWA4vrbZvj8fo24LbGnusr2kitlFIN6VQb2ComHQehlFJH0wSBrWLSNgillDqaJgg0QSillDeaINAqJqVUyznR6b4BnnrqKUpLS5s5ojqaILDjILQXk1KqJbTmBKHTfQNOsYt6K6XUyeY53fcll1xChw4dePvtt6moqODqq6/m4YcfpqSkhKlTp5Kenk5NTQ1/+MMfOHz4MAcPHmTcuHFERUWxbNmyZo9NEwTucRBaxaSU+vg+OLS5ea8ZMxAmHXu1As/pvpcuXcq7777L2rVrMcZw5ZVX8tVXX5GVlUXnzp356KOPADtHU0REBE888QTLli0jKiqqeWN20yom3FVMmiCUUi1s6dKlLF26lKFDhzJs2DC2b9/Orl27GDhwIJ999hn33nsvX3/9NRERESclHi1BYCfrq3a5WjoMpVRLO85f+ieDMYb777+fn/70pw32rV+/nsWLF3P//fczfvx4HnzwQZ/HoyUIdE1qpVTL8Zzue8KECcyfP5/i4mIADhw4QGZmJgcPHiQkJIQZM2Ywe/ZsNmzY0OBcX9ASBLomtVKq5XhO9z1p0iSmT5/O6NGjAQgNDeW1114jJSWF3/zmNzgcDvz9/Xn++ecBmDVrFpMmTaJTp04+aaSW06n3TmJioklKSmryeTe/tJbckkoW3Tnm+w9WSp1Wtm3bRr9+/Vo6jJPC272KyHpjTKK347WKCV2TWimlvNEEAYhoG4RSStWnCQJwOnS6b6XOZKdTVfuxnMg9aoLAPRfTGfA/iFKqoaCgIHJyck7rJGGMIScnh6CgoCadp72YcM/mqiUIpc5IcXFxpKenk5WV1dKh+FRQUBBxcXFNOsenCUJEJgJPY5cNfdEY82i9/X2Bl4BhwAPGmMc99v0Su9qcATYDtxhjyn0Rp073rdSZy9/fn/j4+JYOo1XyWRWTiDiBZ4FJQAJwnYgk1DssF7gLeLzeubHu7YnGmAHYBDPNV7FqFZNSSjXkyzaIEUCKMSbVGFMJLAAmex5gjMk0xqwDqryc7wcEi4gfEAIc9FWgtorJV1dXSqlTky8TRCyQ5vE+3b3texljDmBLFfuBDKDAGLPU27EiMktEkkQk6UTrEJ0OHUmtlFL1+TJBiJdtjfoWFpF22NJGPNAZaCMiM7wda4yZa4xJNMYkRkdHn1Cg2gahlFIN+TJBpANdPN7H0fhqoouBPcaYLGNMFfAecE4zx1fL4dAEoZRS9fkyQawDeolIvIgEYBuZFzXy3P3AKBEJEREBLgK2+ShOnWpDKaW88Fk3V2NMtYjcCSzB9kKab4zZIiK3u/fPEZEYIAkIB1wicg+QYIxZIyLvAhuAauBbYK6vYnXqgkFKKdWAT8dBGGMWA4vrbZvj8foQturJ27kPAQ/5Mr4jREBrmJRS6mg61QbuKibNEEopdRRNEGgVk1JKeaMJAtuLSQsQSil1NE0QgEPQKiallKpHEwTazVUppbzRBIGtYgJdNEgppTxpgsCWIAAdTa2UUh40QVBXgtB2CKWUqqMJAjtZH6BTfiullAdNENjpvkFLEEop5UkTBB4lCE0QSilVSxMEnlVMmiCUUuoITRDYqTZAV5VTSilPmiDQXkxKKeWNJgjqxkFoflBKqTqaILBzMYFWMSmllCdNEHhUMWmCUEqpWj5NECIyUUR2iEiKiNznZX9fEVklIhUiMrvevrYi8q6IbBeRbSIy2ldx6lQbSinVkM+WHBURJ/AscAmQDqwTkUXGmK0eh+UCdwFXebnE08AnxphrRCQACPFVrEd6MWkBQiml6viyBDECSDHGpBpjKoEFwGTPA4wxmcaYdUCV53YRCQfOB+a5j6s0xuT7KlDRNgillGrAlwkiFkjzeJ/u3tYYPYAs4CUR+VZEXhSRNt4OFJFZIpIkIklZWVknFGhdCUIThFJKHeHLBCFetjX2G9gPGAY8b4wZCpQADdowAIwxc40xicaYxOjo6BMK9EgbhJYglFKqji8TRDrQxeN9HHCwCeemG2PWuN+/i00YPuHQEoRSSjXgywSxDuglIvHuRuZpwKLGnGiMOQSkiUgf96aLgK3HOeUH0em+lVKqIZ/1YjLGVIvIncASwAnMN8ZsEZHb3fvniEgMkASEAy4RuQdIMMYUAr8AXncnl1TgFl/FqtN9K6VUQz5LEADGmMXA4nrb5ni8PoStevJ27kYg0ZfxHeHQNgillGpAR1JT14vJaAlCKaVqaYJASxBKKeWNJgg8EoSWIJRSqpYmCDwGymkvJqWUqqUJgrpeTDoOQiml6miCAESrmJRSqgFNEHhM962N1EopVUsTBHVtENqLSSml6miCoG66b80PSilVRxMEOt23Ukp5owkCne5bKaW80QSBTvetlFLeaILAY7pvTRBKKVVLEwSeVUwtHIhSSrUimiAAx5GR1NoGoZRStTRB4DEOQquYlFKqliYItA1CKaW88WmCEJGJIrJDRFJE5D4v+/uKyCoRqRCR2V72O0XkWxH50JdxOnSqDaWUasBnCUJEnMCzwCQgAbhORBLqHZYL3AU8fozL3A1s81WMR+hUG0op1ZAvSxAjgBRjTKoxphJYAEz2PMAYk2mMWQdU1T9ZROKAy4AXfRgj4NGLSfODUkrV8mWCiAXSPN6nu7c11lPAb4Hjdj4VkVkikiQiSVlZWU2PEhD3b0HXpFZKqTq+TBDiZVujvoFF5HIg0xiz/vuONcbMNcYkGmMSo6OjmxojoFNtKKWUN75MEOlAF4/3ccDBRp57LnCliOzFVk1dKCKvNW94dZwOQXBpN1ellPLgywSxDuglIvEiEgBMAxY15kRjzP3GmDhjTHf3eV8YY2b4JEpjCHy8G7/xe1t7MSmllAc/X13YGFMtIncCSwAnMN8Ys0VEbnfvnyMiMUASEA64ROQeIMEYU+iruBoQAWcg4ZSQq/lBKaVq+SxBABhjFgOL622b4/H6ELbq6XjXWA4s90F4dYIiCC8qJUtLEEopVUtHUgMSFEG4lOpIaqWU8qAJAiAograUaC8mpZTyoAkCbBWTlOqa1Eop5aFRCUJE7haRcLHmicgGERnv6+BOmqAIwijRKiallPLQ2BLEre6eReOBaOAW4FGfRXWyBbclnFKtYlJKKQ+NTRBHRkVfCrxkjNmE95HSp6agCAKliuqK0paORCmlWo3GJoj1IrIUmyCWiEgY3zNH0iklKAKA4oLcFg5EKaVaj8aOg5gJDAFSjTGlItIeW810eghqC0BZYU4LB6KUUq1HY0sQo4Edxph8EZkB/B4o8F1YJ5m7BFFRrCUIpZQ6orEJ4nmgVEQGY6fg3ge84rOoTjZ3gnCV5WtDtVJKuTU2QVQbu1jCZOBpY8zTQJjvwjrJ3FVMYaaUnOKKFg5GKaVah8YmiCIRuR+4AfjIvZyov+/COsncJYhwKeFQYXkLB6OUUq1DYxPEtUAFdjzEIezKcH/3WVQn25EEQSmHC7UEoZRS0MgE4U4KrwMR7tXeyo0xp08bhH8QxhlIuJRwWEsQSikFNH6qjanAWuDHwFRgjYhc48vATro2UURJIZmaIJRSCmj8OIgHgOHGmEwAEYkGPgPe9VVgJ5uEdaJLUT5JRVrFpJRS0Pg2CMeR5OCW04RzTw3hnYiRPHJKKls6EqWUahUa+yX/iYgsEZGbReRm4CPqrRTnjYhMFJEdIpIiIvd52d9XRFaJSIWIzPbY3kVElonINhHZIiJ3N/aGTlhYJ6JMLrmaIJRSCmhkFZMx5jciMgU4FztJ31xjzPvHO8fdFfZZ4BIgHVgnIouMMVs9DssF7gKuqnd6NfBrY8wG97xP60Xk03rnNq+wGNqYEkqLT95y2Eop1Zo1ek1qY8xCYGETrj0CSDHGpAKIyALsQLvaL3l3tVWmiFxW77MygAz36yIR2YbtWuvDBNEZAGfJIZ99hFJKnUqOmyBEpAjwNveEAMYYE36c02OBNI/36cDIpgYoIt2BocCaY+yfBcwC6Nq1a1MvXycsBoA2FdlU1bjwd55eTSxKKdVUx/0WNMaEGWPCvfyEfU9yAO/rRTRpoiMRCcWWWu5xL1jkLca5xphEY0xidHR0Uy5/tLBOAHSUPPK0HUIppXzaEykd6OLxPg442NiTRcQfmxxeN8a818yxNRR+JEHkak8mpZTCtwliHdBLROJFJACYBixqzIkiIsA8YJsx5gkfxlgnMJwav2BiJE97MimlFE1opG4qY0y1iNwJLAGcwHxjzBYRud29f46IxABJQDjgEpF7gARgEHZiwM0istF9yd8ZY763a+0JE6E6LI7YimwtQSilFD5MEADuL/TF9bbN8Xh9CFv1VN8KWmDNa2nbjS45u1inU34rpdRpNhr6B/KLiqeLZGkJQiml0ARxFEfbroRLKcX52S0dilJKtThNEJ7adQOgKCOlhQNRSqmWpwnCU1ubIKpz9uLStamVUmc4TRCe3CWI6JpDpOeVtXAwSinVsjRBeApuR01AOHGSxdYMnbRPKXVm0wRRj7jXhdh+SBOEUurMpgmiHkd4J+L8C9mdVdLSoSilVIvSBFFfaAwdJJ9DBdoGoZQ6s2mCqC+sI+1ceWTka4JQSp3ZNEHUFxqDn6mioihbu7oqpc5omiDqC+sIQDtXnk65oZQ6o2mCqC/UrizXQfLJ0HYIpdQZTBNEfe6lRzuQR0ZBeQsHo5RSLUcTRH1hdSWIjWn5FJRVtXBASinVMjRB1BfQBhMQRkfJ4/nlu/nNO5taOiKllGoRmiC8kLZd6BOYC8DSrYe1N5NS6ozk0wQhIhNFZIeIpIjIfV729xWRVSJSISKzm3KuT0X1ZmRYFo9cPQCAnZlFJ/XjlVKqNfBZghARJ/AsMAm7zvR1IpJQ77Bc4C7g8RM413ei++Is2M/Y+FAA1qTmnrSPVkqp1sKXJYgRQIoxJtUYUwksACZ7HmCMyTTGrAPqtwR/77k+Fd0bjIvYmgN0jghizZ6ck/bRSinVWvgyQcQCaR7v093bmvVcEZklIkkikpSVlXVCgTYQ3ddeO3snI3tEsnZPLsZoO4RS6sziywQhXrY19lu20ecaY+YaYxKNMYnR0dGNDu64InuCOCBrOyPi25NdXKmzuyqlzji+TBDpQBeP93HAwZNw7g/nFwidhsCq57jALxlAq5mUUmccXyaIdUAvEYkXkQBgGrDoJJzbPK57E0Kjidn4DB3CAvng24NU1bhOaghKKdWSfJYgjDHVwJ3AEmAb8LYxZouI3C4itwOISIyIpAO/An4vIukiEn6sc30Vq1dhMZBwFZK+jt9eGMfavbn8fcmOkxqCUkq1JDmdGl8TExNNUlJS811w9xfw6tVw/UJmfhPBnuwSvph9QfNdXymlWpiIrDfGJHrbpyOpj6fLKHAGQOoyhnVrR2p2ic7NpJQ6Y2iCOJ6AEIgfC8kLGdw5BIDkAwUtHJRSSp0cmiC+z4ifQFEGw4pXALApPd9uX/p7+PBXLRiYUkr5liaI79PzEmgXT8jGeXSPDOGFr1J5eeVe2PUpRds+5401+1s6QqWU8glNEN/H4bCliLTVPDGqnOg2fsxdvguTuweKD/PsspSWjlAppXxCE0RjDLke/EMY9vk0/t1mDjWFGUhNBWFSRnZ+AaWV1S0doVJKNTtNEI0R3BYm/wuALgXr6SaZtbuipYBUnYZDKXUa0gTRWAOmwIS/4FeWzblBu2s3R5NPSmZxCwamlFK+oQmiKWIGAjA1ZEPtpg6OfHZn1UsQZXnUZO+mslqn5lBKnbo0QTSFO0HElGyHALuYUJ/Qctbvy+NwYXndcZ89TMnciUx8+quWiFIppZqFJoimCG5X97r/VQCcG7ib/NT1nPfYMv6xdAfGGEzGRsIrM8nIyiG7uKKFglVKqR9GE0RTXf4kjL0XLn8KgtszsnApHwb/kTt7ZvHPL1J4dPFWXJnbAYiTbHYcOno960+SM5j87Dda/aSUavU0QTRV4q0w7nfg9Icyu1a1w+nHL/IeZfqwjny8Yi3O6jIA4iSL7fUSxDtJ6WxKyydpnw/Wud6+mPLiPF39TinVLDRBNIcp85DCA9zbaQN9nQdqN/cNzGXHocLa95XVLlal2oWHvtzZTMujHlGcCQuu49nHH2TRppO3tpJS6vSlCeKH+OnXcMsn0GcSxJ5NxPp/Mq2LnavJOPzpH5J/VBXTjrVLWMhsPgm8jxXbM5o3luLDAMRUH+C7dJ1QUCn1w/m1dACntE6D6l6f/1t481rGlS7AtOuOOAPo5crhuwMFPPhBMk6HMGrzPCY40gBwZibz8eZ+TBrYqXliKckGoKsc5qu80ua5plLqjKYliObSewLEDEKqy5ArnoG2XekVkMe4Ph34YNUWtqz9nPjKHRS37QPA5Mg0Zr+zicyi8u+5cCOV2qqr7nKY9Lyy5rmmUuqM5tMEISITRWSHiKSIyH1e9ouIPOPe/52IDPPY90sR2SIiySLypogE+TLWH0wEpr0Bty6BHmMhqjeOzK3MPyePDf3f4S3/h+kl6YQOmgwRXbg2JoOyqhpe+Cq1eT6/xLZpdJZsDuUWfs/BSin1/XyWIETECTwLTAISgOtEJKHeYZOAXu6fWcDz7nNjgbuARGPMAMAJTPNVrM2mbReIc6/cd/5voEM/eGMqzt2fIq5qxLig81CIG07o4fVcNbgzL67Yw0X/WM7aPT+wV5O7iskphrCKDArLdeU7pdQP48sSxAggxRiTaoypBBYAk+sdMxl4xVirgbYicqRS3g8IFhE/IAQ4tbrmhLSHWxbbbrE9LoCu59jtscPgrAuh6CB/6rqBX1zYC2dNBdfOXcWv3tpIQVkVLlfTu6kad4IA6CaZpOdqNZNS6ofxZSN1LJDm8T4dGNmIY2KNMUki8jiwHygDlhpjlnr7EBGZhS190LVr12YKvZkEhsHlT9jXB9bDzqUQFmOnD9/yHm0+v59f9ZnIL2u+4LmRr/DUuoMs3XqYymoXN47uxi8v6c3mAwUkdmuHn/P4ubw0/zAVJpT2UkxPOUDygQL6dQpDRE7CjSqlTke+TBDevpnq/2ns9RgRaYctXcQD+cA7IjLDGPNag4ONmQvMBUhMTGy9I8Riz7Y/YBchmjIP5k+ErR8gwB3hqxjxk5/x6qp9ALy4Yg9vrUujqKKKXh3C+MPlCZzfO/qYly/NO0SKqytD25czLvdbZiz8jsLyKm47r8dJuDml1OnIlwkiHeji8T6OhtVExzrmYmCPMSYLQETeA84BGiSIU1ZIe7jpf5C6HDa/DUnzGV6Wy3CTDulJXH3ZPBat3MzDQf/iV5W/5cb5xUwb3oWIYH/S88u4bUw8Q7vWzQ3lKs6m2C+OwIETOeebp0lsa1iwLo2ZY+KbrxSRu8eOHj+S6JRSpzVftkGsA3qJSLyIBGAbmRfVO2YRcKO7N9MooMAYk4GtWholIiFiv90uArb5MNaWEdYRBl8L595jp+7Y8j4c3gI1VYzb+ReebPMq4RWH+HeXJcwcE8+CdWm89M1evt6ZxbVzV/OXxds4XFiOMYagqjyCIjoi/a7AYWqY3W03KZnFbGrGQXMVi39H5evTKa+qabAvLbeU95NSyUrfRV5JJcAJtaUopVoPn5UgjDHVInInsATbC2m+MWaLiNzu3j8HWAxcCqQApcAt7n1rRORdYANQDXyLuxrptBR/Hvx6e937b1+HD35uX/e4AOeuJfzhwuHc/tvbiAiPoCTvMH/8/BAvfp3Kf77Zy5DYNrxNMVEdOtteUlG9ScxeSGjg77j+hdWM69uBa86OI7ekkrKqGiYN6ET7NgENwsgsLMfP6Wiw7+WVe8kpqWT63k3EVB/immc+5j93TuTjzRlUuwxjekbx4zmr+FvZQ0Q7NzPYvMkvLu7LP79I4dnpwxjTK4ryqho27M/jnLOifPiLVEo1JzmdJnZLTEw0SUlJLR1G88jdAzWVENEF/vsz2PpfCIqA2ETY/TmMvpP9w+5j7jd7SV7/Df913ou57Alk+ExYNw8++hXpV73HEzsj+XpXNllFFbSnkGKC6R0bycNX9ic00J/eHUMREVK3ruUX7+zgsDOGp64dymfbDhMe7M+1w7sw7vHlOF2VJPvfhFMM0yp/z87gIeSWVCICZ3dtx+5DeXwr0wE4p/wZDkkULgMBfg6++s04/vTRVj76LoMPfzGGAbERjfoVFFdUc9eb3/Lr8b3p37lx5yilmkZE1htjEr3u0wRxiti3Eta9CLu/gA4JsO8baBMNEx/FbHoLSVsDd2+0bRuVpfDMENuLasQsKrqex+KUci7/ajLpXa5g3NbLai8b7O8kPjKY+Xk3c9ARw11Bj3AwrwQ/aqjEn0mdy9h7OAeXy8WSQDvW8Y32d/Dn7PP57YQ+/PF/WznHkcyj7RfTtXgjAL8Nf4yPMqO4d2QgD65xkNApnK0ZdvDeneN6MrrhWfsAAB+fSURBVHtCn0bd8ifJh7j9tfWM6N6e124bySMfbeWG0d3p2SG0mX+5Sp25jpcgdC6mU0W3c+wPgDGw/UNY8SQsnGm7gl3yfzY5AASEwDUvwctXwMe/JTAglKujekNVIfEHP+Kpy3/CoB3PcLjd2XzqfyEmbQ0xkktHClhyc3eqX/0xZW1imZh1J7dn/57uETU8K9OgxF5+atdCJl6bQPuaHJb0iOTnaR8QV74b2nSAkkxujC/i/wofJGhTBWvPepv9qd/yfrvF/CPifj5OzuDX43s3quF8tXvm27V7c3lo0RbeXLufimoXj04Z9D1nKqWag5YgTmVV5bDxdWjbDXpeZKf78JS1E6rL4dM/wMFvIW4EpHwKQW2hPB/8Q2Dk7bDiibpzQmOg+BAgbJ/wBn2XXAdATt/ptN/+JhKXCBXuNbhzd7P78neIX/QjHOfeDefPhr90hsAIqLCN43vGz6d4xVwGlq7mk1GvcvtyJ/06hfPGbSNp56UdxNMtjy/gkbL/4//87+aT/DgAIoL9WffAxQT46TRip4LqGhdvJaVxxeDOhAf5t3Q4yovjlSD0X9mpzD8Ihs+EXhc3TA4A0b3tjLM3fgD37YfrFkC77hDawY7DAFsKAeg1HgLDbXK44H7A0Hf1b2svFbn7A6Rddxh6A2Rtsz/i4Kylt+AwNdDvcghoA8HtbXJoFw/iIP7QUgaWrgFgfPss/nzVALZlFPLyqr1eb2l/Til/X7KdJ5bu4I7Cf9C55gC/jrMN+P07h1NQVsXyHZnN8utTvvfKqn088H4y877e09KhqBOgVUxnEqcf/Hw1OAPA4YSoXuAXZL/YA8MheaFNNGffbNs60tZA9/MgYxNUFMLZN9mfsE5QdBD828Dn/weRPaGze57FiDg7VqLHWNi/Br5bAA5/cAbgyExmxuUzWbY9k1dW7WP6iK74Ox2sSMnmkoSO/G/TQR54P5kql4v+pPKrwJ0A9Aws4NEfDeTCfh340XMr+cfSnQQHOFmwLo0ZI7sx+qzIBrdaXePC6RBEhLySSj7cnEG/mDASu7dvcGxabim5JZUMios4aSPPM4vK6RDWuuef/KHySip58lP7DN9dn87dF/XC4dCR/acSTRBnGv/gutedBh+9L/GWutfT3oSiDIjqDe/eYpPEyNvtvt7j644b9OOjrxHRBQ59Z3tb5eyGLGDYjZC1HQ4lA3DXRb24du4qzvvbMgx2pb2o0ECyiys4t2ckT0wdQsTGFPjCxihZ25n2YzuNyoOXJzDr1fXcMG8tAJvTC3jyWtujanj3dlTVGO54YwNJe3MZGBvBPZf05nfvbSajoJyIYH/+ds0gMgvLSc8vI+VwMX1iwli06SDpeWVM7B/Dc9cPo7iymvTcMrpFhtAmsOE/kbTcUlakZDNlWJzXqq7ckkoWbTzAtBFdCfJ3Ntj/SXIGt7+2gT9N7s8No7s32G+MYf2+PAbERng9/1Tx1a4siiqqmTkmnnkr9vDVriwu6NOhpcNSTaBtEOr7leVDTRWEHnuqj1of3wtr5tiSSsYmeP+ncE8yrPwnrP03XPYE9L2M1PJQXlm1Dz+H0CM6lNdW72PykM7MjDuAX8oS2L/alkT6XWnPHXsvbP8QM+ER/pvfg5AAPwSY9er62o+ObRuMMYa80iquH9mVRZsOkllUQaCfg0enDOS+hZupqHYBEOB0ENsumD3ZJYjA1LO78FZSGuf1imLj/nyKKqppG+LPk1OHcEGfaMqrXAQHODlcWM6U51eSnldG35gw/n7NYDq1DeKLbZlc1K8D7UICuOmltXy9K5upiXE8NmXQUaWS7OIKLn36azKLKggL9OPDu8bQtX0Iy3dm0TM6lMjQAGa9sp4VKdncNLobD08e0KyPsqSiGpcxhDVje0BZZQ1J+3J54P1kXp05gm6Rbdh5uIh/f5nKZ9sOs+Z3F3HB35fTtX0Ib/10lM4P1spoN1d18qR8BmtfsGtjOJw2sTj9YfO7sHCmPcYvCK5/F7qPgfICCG5rG74X/wY2vVF3rSEz7CDC939q3zsDoOto20Prjakw5pcsLB1CoL+DNgF+3Pfed8REBPPwFQkMyf+Mkra9eWFnMAM6hXNx/xjWpOaQV1rJsK7taO9fiZ8Y3thUgMsYrh/ZlbsXbGTZ9kwu6NuBi/t14N9fprL9UCFnRYeyK7OYHlFtyCutpLzKxa/H9+aFr1PJLq4ksk0AmUUVBDgddGkfzO6sEhK7tSNpXx4X9+vI+P4dmftVKlU1LiqqXOSXVfL3awbzu/c3g4FzekayZItdMrZL+2AO5JUxMDaC7YeK+OxXY+nSPqTBr7m6xuV1AsfkAwXsyS6he2QbeseEEujnpKC0iiqXi5e+2cMLX++hY3ggn/5ybJNLJ3uzS3hj7X5+eXFv/J3Cgfwy1uzJ5d6F33Hka+TByxOICgvkrje/BWDSgBien3E2L6/cy0OLtnDPxb2orHYx5ew4OkcEE+Tv+MEJ47XV+9iXU8LdF/cm1EuJTx2fJgjV8lwuyN8L1RXw9k1QeABCIiF/H/S51FZB5e6x62iIA758FK54xlaDzR1rjx31M/jiz9DtXDsOJKoP3LGmtoHe5TI4XFXw2UOw+jnoMspOuf7q1bad5MjMugUHYN4ltjps5hJb9VVZAl1HYoyp/cIqq6zhzjc2sGF/HtNGdCUls5gal+G+SX3p3TGMgrIq/vzhVr7cmcUfLk9gw/48vksvYPrgtlw9qh/zv9nD35fsoKLaRZ+OYfTsGEpOQTGP9N7NWedNJa1Y+N37m/l6VzY/PjuOmIggXvx6D7MvjOOigfFc8uSXVNUYxid0JMjfSWllDftySsgoKKe4opqL+nbgFxf1QoAaY9iwL49HP95OtXuKk9i2wVzUrwML16dTVlWDy8D5vaP5amcWs87vwW8m9MH/e2YJ9nTrf9bxxfZMJvTvyLaMIvbn2qVtB8ZG0C0yhI82Z3Bhnw5sP1TEgXw73fwfr0jg5nPjKa+q4WevrWfZDruwVbsQf0oqarhySGemDItjcJcIQgK+/8t9ZUo2oUF+DIprC0B+aSWj//oFZVU1XNS3A/NuHt7o+1GWJgjVuuTthWV/hYoiCO8Em9+xvZ7G/wniz7fJJPULiB8L4oRV/4JBU+3rf55te0kdSRLx59vr9bwEQjvCd29B7m6bPLJ3wOg77flgj3UGQsbG2hX4mDIP/ncPuKpsMhGHbVzf/DYYF+bWpVSLX90X6bYP7aj2dvF2CvdrX8P4B9f9FZw035aEpr8FnYZyuKYNy3dkcuXgWIIDnLWj3Em8Fcb9HtpEsj+nlC7t7TVqslJwvnABjLuf7fE38L9NB5m/Yi9hQX60Cwkgtl0w3SJDEIRXVu2tTQZHjO4Rye8u7ceenBKe+XwXabmljO0dTaeIIAL9ndw3oQ+/fvc73v/2AB3CArl0YCcC/BzklVTSuW0wReXVtSUqgM0HCpjQP4ZN6flMf2EN0WGBZBVV0DcmjKuGxpKSWcwD57Sh3bfP8UD+FbyebJPGy7eOYH9OCVP6hxHy7gyY8GdM52FsP1REaWU1dy/YSKeIINbtzQNsknnttpFEBDes+krLLSU8yJ8APwcj/vIZbUP8WfbrC/BzOvjn57v4x6c7Gd69HTsPF7PxwUu0CquJNEGo00dVOVSV2p5Xr02xa3GHdbLTjyC2Curcu2zJ48n+YFzQbYwdD1J0yE5XEt7ZNri/MRVMDYR1tv8tPlz3OWGdbCP9mF/asSHigJoK+OyP4KquO27Mr2yVWdY2GHYTvHurbTsBe86Mhbahf/3LkDAZ3roeCtLrrnHlP+3suBtegaEzYPmjdhBkUATcsQ7COh7VIwuAfaugfQ9SytqwL8e2oQhCbLtgenUIRfL2QGAEJqQ9LgNOh9gqvHdvgcoSam5YxPJdObyxZj/f7M7G5YLwYD+yiysJ8nfgMrbjQO2vItCPKpeLmPAg3v7paNbuzWV8QoxtoK+pstPWH0giNfYKLtx9HeMTOjL3Rvf3zbb/wVszbEK/+aMG3bHX7sllV2YRf1y0hbG9oxkZH0nSPtvB4KZzuttf8WPLiA4L5MbR3Xjwgy0APHPdUHKLK3j4w62M69OB83pF8fD/tpL0+4uJCg1spv/ZzgyaINTpL3uXTRrhneu2rfynTQzDf2LbOer77x22lDHlRXDVwM4ltior/ny7sNP8Cbarr6ce4+DSx6FgP6z8lzsxAQGhUFls20mungM7PoH0dbaUZGqgLK/uGtfMh8NbIXUZHNps59wC7PIoBgZMgeT37OuEyXY1woI0WwVXmG4b/9vFw+VPQtuuNtbDW+CbpyFtLZRkQvsecNUcu83hsMkxfZ39mHPusj3LonrhchlqjMHf6aDGZXAIZBdXsnhzBvmlVZzdrR0fbc6guLyKB8dFEd2pKxRn2vjOvgm+ehy+fry2RPdgzHPc9uOr6RrpbjdZ+gdY+Yx9PeR6W3LrMtJOc3/u3dDrEgDmrdjDnz7cCkDX9iHszy0lItifQXERfL0rGxE7gUCP6Db21+10kJ5XxtCubZl7QyLr9uZy4/y1vDVrFCN7HN3tOaOgjO2HihjbK1q72XqhCUKpE1FwwI5A7zLCJpqKIujYv25/7h5bpTXgGggMhd3LoNtoOxgRIH09fHAHRJ5lSywZm+yXYxd3PXnePvtX/VkXQv8fwdf/sONHhlwPBzfC9v/B6jlQXWarxtrHQ0iUXfd8zb/tdk+BEZBwBYTH2i9uU2PHt1SX2/3XvAQbXoZdS8HhB4OvswktIMS2x2TvtG0xQ2+wgzDz99vR9+Gd4cN7YMOrMPVlWP4YHN5sk1TeXhh6PYx/BB7vbbtKnzcbltwPfS+D1c/bdqeO/WHTAmgTVVdSaxNtY/ILwhUziCeX7SUxopCxQ/uzObOKpz7byefbMxnbO5qbzunGmj25XNKvI7uzirl34WYA3rl9NMM3/oHS4jwSkq/nL1cPZPrIo1eWnP7CalbuzqF/53CemDqEPjFhzfv/ySlOE4RSp6rKElutFtzOlgSOyE+D3FT7JV6aDeFxdkR9sHsRqa2LbEeAQdfav/hrKmy1W001ZG6Fb56yS+D6BdrEV1NhBz46nHZQZC2xCS4nxValVZfbgY/n3gWpX0LnIXDxwzZBvn0j7P3GrsGe/G7dJUbfCRMesZ8tDtiz3Ca8V6+2nwu2BNJ5qO1cENUbxj0AvcaTkldNdGggESF1bRMV1TWc/7dlhAX58+k95yF/74GpLGFI5YtMGdGLB69IqD32u/R8rvzXN1w2qBNrUnOoqHaxfPYFRGo1VC1NEEqpY6uusGNd2kTZarK9K2wiaNcddn1qG+O7n2e7Ja/6l22XiRnY8Do7l9h2HbCLYPkFwpeP2aleelzQ8PiCA7b3WvYuW+IwBhKuhD1f2Sq5AVNsddzWRbardK/xNoEBuw4X4ed0EG8OwLO2RHZ/6CMcaD+CV24dUfsRv3p7I59uOczK+y/kcGE5E576mukjuvKnq5p3fMmpTGdzVUodm1+gXd0QbON437rp4BssL3vN/GNfp/cEuHGR7UU2eLqtpjr3HluF5U1ErP3peRH0vdSWUEI72FLTZw/D2rm2GmrNHHv8kBm2dGNc9BowBTr0g/S6PwgvDt7B3ft6UVZZQ2llNQVlVSxJPsTlgzoTFuRPWJA/14/syutr9nPTOd3o2cF7VZMxho82Z/DRdxnER7Xh7ot7kVVUQVRo4Ck9sv1EaAlCKdX6FGfCUwNtSab/j2zngXUvHH1Mx4HQeTBs/wjaxVNYBYPSZjO2dzSrU3OorHFhDLx+20jO7WlXMswpruCCvy9neHx75h9jzMSRdUg6hAWSWVTBuD7RLNuRRUiAk5duHt6gEfxU12KzuYrIRBHZISIpInKfl/0iIs+4938nIsM89rUVkXdFZLuIbBOR0b6MVSnVioR2gJsXw6wvball3O9sI3xkL7hzPYz4qW0o37rI9jrrMZawnO/oGQFf7szion4d6NUhlNi2wYyqXA3v3AJJLxEZGsjM8+L5YnsmhwvLvX70mj05BPs7WXnfhfTrFM6yHVn07hhKx/Ag7l6wkYLSqmOGXVJRfcx9pyKfJQgRcQLPApOABOA6EUmod9gkoJf7ZxbwvMe+p4FPjDF9gcHANl/FqpRqheLOto3gInYxrJlL4KZFENUTRrqnX6kohLNvge7nIa5qHh9VxgOX9uNf1w3jf78YwyeXleF850bY8TF8+EsozuTifrY6beXu7NqPqqiuYeXubA4VlLPlQCH9OoXh53Twk/PiAXjgsgSenjaEQ4XlzPumbury6hoX//5yNzfMW8P5f1tG/4eW8OrqfQ1uZVtGIct3ZFJeVePDX1jz82UbxAggxRiTCiAiC4DJwFaPYyYDrxhbz7XaXWrohF277HzgZgBjTCVQiVLqzNWhX93ryLMgup8dAR8/1nb5dfgzpHozQ8ZdA0Bg8WECP/q57WJ76eMwfzwsmE5/Vw3tgu9lxa4cLu7XkZAAP1782k6LEujnoKLaxY2juwFw9dBYzu7Wjm4BRbDkXq7qM4P/fLOHC/t2YEiXtixYl8ZfP95O35gwBsZG2BmDP97OhISOdAi307k/uyyFeUvWUUAbxvSO4T+3DD9lRnv7MkHEAmke79OBkY04Jhaoxk4U/ZKIDAbWA3cbY0rqf4iIzMKWPujatWv93Uqp09W0123pwuGwgyTjEmHTm4CxY0z2fGkHIV7zkk0okT0hfR0C/KhrMfM2pLNwQzqdIoJwiNCvUzjb3GunD+gcAYCI0C2yDXzzIiQvZPYFY1i6pzNXPfsN1yZ24fPtmYzo3r52ltq92SWMf+or/vzRNp65bigrd2fz7JJNrA/5NRu73Mh1O87j+S938/MLeja4HZfLNGogX1F5FRXuKfJ9zZdtEN7utH6L+LGO8QOGAc8bY4ZiSxQN2jAAjDFzjTGJxpjE6OhGTEetlDo9RJ5lR4wfMekxOzBw5b/syPLu59n5taJ62kQy9IbaQ6fHHGRs72h+fUlv8korOZBfxk2juzE4ziaGhM7hkJ1iF8Qqy7PdfYG4ok2suv8ibj6nO28lpeEyhgevSKgtEXSPasPPxp7Fok0H+XpXFn/6cBuXhqUS7CphVNmXXD6oE3/7ZAfvbUg/6lYqqmu44l8ruOKfK/jTh1v58LuDDW532Y5MHnh/M+MeX86Yx77g9TUNq7Kamy9LEOlAF4/3cUD9uz7WMQZIN8YcmefgXY6RIJRSCrADAe9Ya0sN/l5W6xtzj53e44l+nFW6iZdvvQtcNbQN8eeZL1KYNLATEzqXk5SUSn//g/DiRLt2e/JCO2IcYP9qIoL9eeiKBGaOiadjeFCDRaN+dsFZLNyQzs9e20BxRTXPDtgPKSCZW3k67mWcnUfwt092cNmgTgT62W6zzy/fzZaDhUQE+7PlYAHzVkDygUJ+cl48kaGBlFfV8Jt3NlFUXs2guAj8HA7+uGgLF/frSMdw361M6MsEsQ7oJSLxwAFgGjC93jGLgDvd7RMjgQJjTAaAiKSJSB9jzA7gIo5uu1BKqYYcDnAc5wtT3BM6pi63Eyvu/YYbfr6KGcNGIUtnw/r/cAlAWi87P9cVT9vZeQF6TYBdS2DtC8iwG+06HcVZ8OmDgIG23WD4TII2vMLvzxvL7YsyuSKulPjcb2zvq5xdODf8hwc77+Psgz/h1v+sY0BsBCUV1by2ej9XDu7ME1MHU1Ht4vf/TWbOl7t5/9t0Xp05knV7c8kuruSNn4zknLOi2JdTwgWPL+fllXv57cS+Pvt1+nQchIhcCjwFOIH5xphHROR2AGPMHLHlsn8BE4FS4BZjTJL73CHAi0AAkOrel+flY2rpOAil1PfauwIWTLeLVYGdkfdAEuz5Gkb93M6mm78PRv4MJj1qR5rnpkJVGbwwzp5z8R/t/v9cZidcbBNdt8ZJaTZm5O2857qAH62/AXFV2UZyEVj7IiZvL48NXMzSXYWk55VRWePiysGd+ds1g44aiJd8oIBb/7MOEahxGeLaBvP+z0YiTjvtyB2vb+DTbYf5z83DOcc9zuNE6FQbSinlqSzffqF/+hCk2PYFrv43DJ5mVz9cdBf8bMXRbRxgk8rC2+wsvwN/DOtehKmv2ilC1r4Ai2fb+aZCY+zo9IJ0uOlDiO5jE8TuZfDqVXY9kFF34Gp/FgCOzC12xuGgtnaG4XbxENKeLQcL+NFzK3FSw7ruc2jjNHDzhyBCXkkl0+auJi2vlFdnjuTsbu1O6FehCUIppbzJ2mHX4uh3JXT16GRZUw3OY9TAH94KL14MVSU2SUx50W43xi65W5Bmx1wATH3FTtlee90qeHIAFB+yKx7e+olNVP8aDv7BgNjJFzsk2PUz/INJ2pNDXNIjxOx0L8c74a+2vaX7uWQWlTN1zioKy6v56rfjTmjJVU0QSinVnPL2wcbX7YjuNvWm3qgogleugiHTYfjMhudWFMP6l2Dp7+3Eh/tW2qngQ6LsXFiDptplcxE71bzDH/atgOG3wZb/2gTiDLDzXsUlkl5Yxa7MYsb16XBCt6IJQimlWpOqcltqKNhvq5UufsiuA+Lwtw3tX/4d9q+E3V/Y4y99HEb8xC55ezjZlnoKD9ixHbcutbPcelsUqxE0QSilVGtzZPncoLZHr/VxhKsGXrwIELjts9qpzgHb7XbrIvjiz4Cx67H/MvmEwtDpvpVSqrXxD/I+XuMIhxNu+cQ9WrzeNOPtuttFmzr2t72uovvZNpBmnsJDE4RSSrVWx0sgYNfS6HmRzz7ep9N9K6WUOnVpglBKKeWVJgillFJeaYJQSinllSYIpZRSXmmCUEop5ZUmCKWUUl5pglBKKeXVaTXVhohkASe6Dl8UkN2M4bQkvZfW53S5D9B7aa1O9F66GWO8rtd8WiWIH0JEko41H8mpRu+l9Tld7gP0XlorX9yLVjEppZTyShOEUkoprzRB1Jnb0gE0I72X1ud0uQ/Qe2mtmv1etA1CKaWUV1qCUEop5ZUmCKWUUl6d8QlCRCaKyA4RSRGR+1o6nqYSkb0isllENopIkntbexH5VER2uf/brqXj9EZE5otIpogke2w7Zuwicr/7Oe0QkQktE7V3x7iXP4rIAfez2Sgil3rsa8330kVElonINhHZIiJ3u7efUs/mOPdxyj0XEQkSkbUissl9Lw+7t/v2mRhjztgfwAnsBnoAAcAmIKGl42riPewFoupt+xtwn/v1fcBjLR3nMWI/HxgGJH9f7ECC+/kEAvHu5+Zs6Xv4nnv5IzDby7Gt/V46AcPcr8OAne6YT6lnc5z7OOWeCyBAqPu1P7AGGOXrZ3KmlyBGACnGmFRjTCWwAJjcwjE1h8nAy+7XLwNXtWAsx2SM+QrIrbf5WLFPBhYYYyqMMXuAFOzzaxWOcS/H0trvJcMYs8H9ugjYBsRyij2b49zHsbTK+wAwVrH7rb/7x+DjZ3KmJ4hYIM3jfTrH/x+oNTLAUhFZLyKz3Ns6GmMywP4jATq0WHRNd6zYT9VndaeIfOeugjpS/D9l7kVEugNDsX+xnrLPpt59wCn4XETEKSIbgUzgU2OMz5/JmZ4gxMu2U63f77nGmGHAJOAOETm/pQPykVPxWT0PnAUMATKAf7i3nxL3IiKhwELgHmNM4fEO9bKt1dyPl/s4JZ+LMabGGDMEiANGiMiA4xzeLPdypieIdKCLx/s44GALxXJCjDEH3f/NBN7HFiMPi0gnAPd/M1suwiY7Vuyn3LMyxhx2/6N2AS9QV8Rv9fciIv7YL9XXjTHvuTefcs/G232cys8FwBiTDywHJuLjZ3KmJ4h1QC8RiReRAGAasKiFY2o0EWkjImFHXgPjgWTsPdzkPuwm4IOWifCEHCv2RcA0EQkUkXigF7C2BeJrtCP/cN2uxj4baOX3IiICzAO2GWOe8Nh1Sj2bY93HqfhcRCRaRNq6XwcDFwPb8fUzaenW+Zb+AS7F9m7YDTzQ0vE0MfYe2J4Km4AtR+IHIoHPgV3u/7Zv6ViPEf+b2CJ+FfYvnpnHix14wP2cdvD/7d09aBRBHIbx5xVB1IA2CmKhqI0IMWDnBwhWWllEBDWFtY2dCH6AvaVgyqgpRDGNpSkCKUQxhihiZZVeAhG0iGOxE4myHieanIfPDw7uhrlhhmX5782x78LJXs+/i7XcB94Ac/WE3dEnazlKsx0xB8zW16l+OzYd1tF3xwUYBF7XOb8FbtT2VT0mRm1Iklr971tMkqRfsEBIklpZICRJrSwQkqRWFghJUisLhPQPSHI8ydNez0NayQIhSWplgZB+Q5ILNZd/NsloDVBbTHI7yUySySTbat+hJM9rKNzEcihckn1JntVs/5kke+vwA0keJ3mfZLzeCSz1jAVC6lKS/cBZmoDEIWAJOA9sBmZKE5o4BdysX7kHXCmlDNLcubvcPg7cKaUcBA7T3IENTdroZZos/z3AkVVflNTB+l5PQOojJ4BDwMt6cb+RJhztK/Cw9nkAPEmyBdhaSpmq7WPAo5qdtbOUMgFQSvkMUMd7UUqZr59ngd3A9OovS2pngZC6F2CslHL1h8bk+k/9OuXXdNo2+rLi/RKen+oxt5ik7k0Cw0m2w/fnAe+iOY+Ga59zwHQpZQH4mORYbR8BpkrzPIL5JKfrGBuSbFrTVUhd8gpF6lIp5V2SazRP8FtHk9x6CfgEHEjyClig+Z8Cmvjlu7UAfAAu1vYRYDTJrTrGmTVchtQ101ylP5RksZQy0Ot5SH+bW0ySpFb+gpAktfIXhCSplQVCktTKAiFJamWBkCS1skBIklp9A8tWLGHtkiq3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):268.20535714285717\n",
      "Fold score (RMSE):16.376976434704215\n",
      "Unsupervised Fold #5\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 4s 4ms/step - loss: 0.2142 - val_loss: 0.1472\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1352 - val_loss: 0.1270\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1289 - val_loss: 0.1187\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1171 - val_loss: 0.1134\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.1137 - val_loss: 0.1056\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1079 - val_loss: 0.1026\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1059 - val_loss: 0.0989\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1034 - val_loss: 0.0975\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1012 - val_loss: 0.0955\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0980 - val_loss: 0.0940\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0950 - val_loss: 0.0904\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0893\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0922 - val_loss: 0.0884\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0914 - val_loss: 0.0873\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0905 - val_loss: 0.0874\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0907 - val_loss: 0.0872\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0891 - val_loss: 0.0851\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0880 - val_loss: 0.0845\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0875 - val_loss: 0.0851\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0872 - val_loss: 0.0846\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0889 - val_loss: 0.0892\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0921 - val_loss: 0.0905\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0906 - val_loss: 0.0861\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0904 - val_loss: 0.0845\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0878 - val_loss: 0.0850\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0892 - val_loss: 0.0873\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0875 - val_loss: 0.0824\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0860 - val_loss: 0.0843\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0852 - val_loss: 0.0840\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0861 - val_loss: 0.0815\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0813\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0825 - val_loss: 0.0807\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0854 - val_loss: 0.0850\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0876 - val_loss: 0.0838\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0804\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0851 - val_loss: 0.0842\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0810\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0818 - val_loss: 0.0803\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0849\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0845 - val_loss: 0.0795\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0807 - val_loss: 0.0785\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0786\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0772\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0807 - val_loss: 0.0792\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0815 - val_loss: 0.0794\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0784\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0802 - val_loss: 0.0771\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0822 - val_loss: 0.0845\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0853\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0847 - val_loss: 0.0772\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0803 - val_loss: 0.0799\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0789\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0791 - val_loss: 0.0767\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0792 - val_loss: 0.0760\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0752\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0768 - val_loss: 0.0744\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0767\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0780\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0777 - val_loss: 0.0774\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0740\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0783\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0783\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0786 - val_loss: 0.0738\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0790 - val_loss: 0.0797\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0788 - val_loss: 0.0807\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0831 - val_loss: 0.0760\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0739\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0740\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0742\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0739\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0719\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0726\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0727\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0714\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0723\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0717\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0733\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0724\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0752 - val_loss: 0.0721\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0739\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0728\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0714\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0728\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0720\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0711\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0719\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0714\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0715\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0727\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0737 - val_loss: 0.0717\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 2s 1ms/step - loss: 0.0743 - val_loss: 0.0710\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0719\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0734 - val_loss: 0.0712\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0739 - val_loss: 0.0711\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0723\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0715\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0707\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0714\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0708\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0712\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0718\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0710\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0706\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0712\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0706\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0715\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0728\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0714\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0701\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0709\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0705\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0703\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0741\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0727\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0709\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0736\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0777 - val_loss: 0.0737\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0707\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0725\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0730\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0698\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0692\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0698\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0699\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0693\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0686\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0685\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0689\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0692\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0687\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0690\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0723\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0723\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0702\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0708\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0684\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0685\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0681\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0680\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0685\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0700\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0700\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0721 - val_loss: 0.0686\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0683\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0708 - val_loss: 0.0692\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0716 - val_loss: 0.0704\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0715 - val_loss: 0.0704\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0723 - val_loss: 0.0686\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 3s 3ms/step - loss: 0.0702 - val_loss: 0.0680\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0703 - val_loss: 0.0683\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0706 - val_loss: 0.0678\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0679\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0699 - val_loss: 0.0684\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0710\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0716\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0692\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0681\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0703 - val_loss: 0.0673\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0694 - val_loss: 0.0676\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0693 - val_loss: 0.0677\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0697 - val_loss: 0.0671\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0691 - val_loss: 0.0682\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0701 - val_loss: 0.0693\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0715 - val_loss: 0.0688\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0697 - val_loss: 0.0686\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0673\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0689\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0698\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0677\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0673\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0669\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0671\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0672\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0669\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0682\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0690\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0679\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0676\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0669\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0685\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0691\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0673\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0679\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0686\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0675\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0674\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0669\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0669\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0672\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0675\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0685\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0674\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0672\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0665\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0669\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0671\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0667\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0687\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0671\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0669\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0662\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0664\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0682 - val_loss: 0.0666\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0665\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0667\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0685\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0696\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0698\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0675\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0670\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0665\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0664\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0663\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0679 - val_loss: 0.0661\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0665\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0670\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0664\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0678 - val_loss: 0.0662\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0664\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0673\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0681\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0684\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0706\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0718\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0678\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0665\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0661\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0660\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0662\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0660\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0660\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0658\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0663\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0666\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0664\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0660\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0656\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0665\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0681\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0675\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0666\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0665\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0665\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0668\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0658\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0680 - val_loss: 0.0656\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0677 - val_loss: 0.0662\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0675 - val_loss: 0.0664\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0656\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0665\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0663\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0654\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0652\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0649\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0653\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0663\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0687\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0672\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0660\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0650\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0649\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0657\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0673\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0688\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0673\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0681\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0692\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0661\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0654\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0651\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0650\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0667 - val_loss: 0.0647\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0645\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0643\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0658 - val_loss: 0.0640\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0639\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0641\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0651\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0680\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0675\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0653\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0645\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0639\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0634\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0652 - val_loss: 0.0634\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0640\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0661\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0661\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0651\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0645\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0641\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0637\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0630\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):307.9009009009009\n",
      "Fold score (RMSE):17.54710520002946\n",
      "Unsupervised Fold #6\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 5s 5ms/step - loss: 0.2102 - val_loss: 0.1453\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1377 - val_loss: 0.1297\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1277 - val_loss: 0.1204\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1165 - val_loss: 0.1148\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1126 - val_loss: 0.1071\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1038 - val_loss: 0.1037\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1010 - val_loss: 0.0983\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0986 - val_loss: 0.1011\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1006 - val_loss: 0.0982\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0972 - val_loss: 0.0970\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0958 - val_loss: 0.0958\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0940 - val_loss: 0.0936\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0914 - val_loss: 0.0917\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0900 - val_loss: 0.0907\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0893 - val_loss: 0.0900\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0882 - val_loss: 0.0895\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0878 - val_loss: 0.0894\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0872 - val_loss: 0.0893\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0869 - val_loss: 0.0868\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0862 - val_loss: 0.0878\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0842 - val_loss: 0.0860\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0868 - val_loss: 0.0912\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0877 - val_loss: 0.0878\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0888 - val_loss: 0.0948\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0879 - val_loss: 0.0951\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0910 - val_loss: 0.0880\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0852 - val_loss: 0.0872\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0836 - val_loss: 0.0843\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0857\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0814 - val_loss: 0.0843\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0862 - val_loss: 0.0903\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0900 - val_loss: 0.0904\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0879 - val_loss: 0.0888\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0876\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0853 - val_loss: 0.0869\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0843 - val_loss: 0.0866\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0840 - val_loss: 0.0861\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0838 - val_loss: 0.0856\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0828 - val_loss: 0.0848\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0821 - val_loss: 0.0844\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0817 - val_loss: 0.0837\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0813 - val_loss: 0.0836\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0803 - val_loss: 0.0823\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0795 - val_loss: 0.0815\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0804\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0781 - val_loss: 0.0805\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0781 - val_loss: 0.0808\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0795\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0803\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0779 - val_loss: 0.0797\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0790 - val_loss: 0.0825\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0794\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0800\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0784 - val_loss: 0.0795\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0777 - val_loss: 0.0806\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0774 - val_loss: 0.0784\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0792\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0785\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0805\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0782\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0756 - val_loss: 0.0782\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0763 - val_loss: 0.0790\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0771\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0793\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0790\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0825\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0811 - val_loss: 0.0800\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0752 - val_loss: 0.0796\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0785\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0762\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0762 - val_loss: 0.0799\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0771 - val_loss: 0.0776\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0783\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0766\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0780\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0760\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0762\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0756\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0757\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0764\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0753\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0772\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0780\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0743 - val_loss: 0.0754\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0795\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0752 - val_loss: 0.0803\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0763 - val_loss: 0.0752\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0763\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0758\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0751\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0763\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0758\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0754\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0772\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0774\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0748\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0773\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0780\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0744\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0732 - val_loss: 0.0760\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0767\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0741\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0751\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0758\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0737\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0759\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0767\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0733\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0746\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0760\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0733\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0762\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0783\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0757 - val_loss: 0.0749\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0739\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0743\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0735\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0729\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0731\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0746\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0738\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0728\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0731\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0734\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0732\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0730\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0743\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0762\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0751\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0736\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0732 - val_loss: 0.0767\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0770\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0722\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0720\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0717\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0717\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0717\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0715\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0719\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0724\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0723\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0720\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0734\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0755\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0755\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0734\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0759\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0761\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0716\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0713\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0716\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0712\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0713\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0716\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0729\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0732\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0714\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0722\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0728\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0713\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0715\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0716\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0722\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0723\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0706\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0713\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0724\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0711\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0722\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0716\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0710\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0713\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0701\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0709\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0715\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0708\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0708\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0689 - val_loss: 0.0701\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0709\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0716\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0707\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0710\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0719\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0742\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0743\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0710\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0703\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0699\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0700\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0703\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0723\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0706\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0700\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0699\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0701\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0695\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0696\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0694\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0695\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0692\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0694\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0706\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0732\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0709\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0695\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0690\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0688\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0687\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0686\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0688\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0703\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0769\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0745\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0739\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0712\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0715\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0705\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0712\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0707\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0707\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0702\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0698\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0692\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0671 - val_loss: 0.0692\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0690\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0696\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0698\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0690\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0690\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0690\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0702\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0714\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0700\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0699\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0687\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0684\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0682\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0680\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0682\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0705\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0716\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0713\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0689\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0679\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0671\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0666\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0655\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0661\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0689\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0674\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0670\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0668\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0655 - val_loss: 0.0683\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0652 - val_loss: 0.0657\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0649\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0684\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0755\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0774 - val_loss: 0.0736\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0710\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0705\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0699\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0685\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0682\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0682\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0680\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0678\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0655\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0654\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0639 - val_loss: 0.0640\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0622 - val_loss: 0.0759\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0729\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0708\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0696\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0684\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0684\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0679\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0622\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0637\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0655\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0645 - val_loss: 0.0628\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0607 - val_loss: 0.0705\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0701\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0692\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0661\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0590\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0602 - val_loss: 0.0638\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0662\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0622\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0620 - val_loss: 0.0604\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0595 - val_loss: 0.0601\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0585 - val_loss: 0.0607\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0587\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0623\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0613\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0641 - val_loss: 0.0610\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0597\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUVfrA8e87k94rISShN2kiBARpFjquyOIPBbGvyCoquqhYdl1X195XBVFgVezYWAVBFASkhiK9hJrQEkgCpJc5vz/uEIZkAgkyCZD38zw+mbn3nJn3ZnDenHLPEWMMSimlVFm2mg5AKaXUuUkThFJKKbc0QSillHJLE4RSSim3NEEopZRySxOEUkoptzRBKPUHiEhDETEi4lWJsreKyKI/+jpKVRdNEKrWEJFdIlIoIlFljq9xfjk3rJnIlDo3aYJQtc1OYPjxJyLSFvCvuXCUOndpglC1zUfAzS7PbwE+dC0gIqEi8qGIpIvIbhF5QkRsznN2EXlZRA6JyA5gkJu6k0Vkv4jsFZFnRMRe1SBFpJ6IzBCRDBFJFpE7Xc51FpEkETkqIgdF5FXncT8RmSYih0UkS0RWiEhMVd9bqeM0QajaZikQIiIXOb+4rwemlSnzHyAUaAz0wkootznP3QlcDVwCJALXlan7AVAMNHWW6Qv85Qzi/BRIBeo53+NZEbnKee4N4A1jTAjQBPjCefwWZ9wJQCQwGsg7g/dWCtAEoWqn462IPsBmYO/xEy5J41FjzDFjzC7gFeAmZ5FhwOvGmBRjTAbwnEvdGGAAMNYYk2OMSQNeA26oSnAikgB0Bx4xxuQbY9YA77vEUAQ0FZEoY0y2MWapy/FIoKkxpsQYs9IYc7Qq762UK00Qqjb6CBgB3EqZ7iUgCvABdrsc2w3EOR/XA1LKnDuuAeAN7Hd28WQB7wJ1qhhfPSDDGHOsghjuAJoDm53dSFe7XNds4DMR2SciL4qIdxXfW6lSmiBUrWOM2Y01WD0Q+LrM6UNYf4k3cDlWnxOtjP1YXTiu545LAQqAKGNMmPO/EGNM6yqGuA+IEJFgdzEYY7YZY4ZjJZ4XgOkiEmiMKTLGPGWMaQVchtUVdjNKnSFNEKq2ugO40hiT43rQGFOC1af/bxEJFpEGwIOcGKf4ArhPROJFJBwY71J3PzAHeEVEQkTEJiJNRKRXVQIzxqQAi4HnnAPP7ZzxfgwgIiNFJNoY4wCynNVKROQKEWnr7CY7ipXoSqry3kq50gShaiVjzHZjTFIFp+8FcoAdwCLgE2CK89x7WN04vwOrKN8CuRmri2ojkAlMB2LPIMThQEOs1sQ3wJPGmJ+c5/oDG0QkG2vA+gZjTD5Q1/l+R4FNwK+UH4BXqtJENwxSSinljrYglFJKuaUJQimllFuaIJRSSrmlCUIppZRbF9TSwlFRUaZhw4Y1HYZSSp03Vq5cecgYE+3u3AWVIBo2bEhSUkUzF5VSSpUlIrsrOqddTEoppdzSBKGUUsotTRBKKaXcuqDGIJRSqqqKiopITU0lPz+/pkPxKD8/P+Lj4/H2rvwCv5oglFK1WmpqKsHBwTRs2BARqelwPMIYw+HDh0lNTaVRo0aVrqddTEqpWi0/P5/IyMgLNjkAiAiRkZFVbiVpglBK1XoXcnI47kyuURME8ObP2/h1a3pNh6GUUucUTRDAhPnbWbRNE4RSqvplZWXxzjvvVLnewIEDycrKOn3BP0ATBGC3CQ7dFkMpVQMqShAlJafeDHDmzJmEhYV5KixAZzEBIAIlmiGUUjVg/PjxbN++nfbt2+Pt7U1QUBCxsbGsWbOGjRs3cu2115KSkkJ+fj73338/o0aNAk4sLZSdnc2AAQPo3r07ixcvJi4uju+++w5/f/8/HJsmCI63IDRBKFXbPfW/DWzcd/SsvmareiE8+afWFZ5//vnnWb9+PWvWrGH+/PkMGjSI9evXl05HnTJlChEREeTl5dGpUyeGDh1KZGTkSa+xbds2Pv30U9577z2GDRvGV199xciRI/9w7JogALuItiCUUueEzp07n3Svwptvvsk333wDQEpKCtu2bSuXIBo1akT79u0B6NixI7t27TorsWiCAGzaglBKwSn/0q8ugYGBpY/nz5/P3LlzWbJkCQEBAVx++eVu72Xw9fUtfWy328nLyzsrseggNWATcDhqOgqlVG0UHBzMsWPH3J47cuQI4eHhBAQEsHnzZpYuXVqtsWkLAmcXk7YglFI1IDIykm7dutGmTRv8/f2JiYkpPde/f38mTpxIu3btaNGiBV26dKnW2DRB4Oxi0jEIpVQN+eSTT9we9/X1ZdasWW7PHR9niIqKYv369aXHx40bd9bi0i4mrFlM2oJQSqmTeTRBiEh/EdkiIskiMt7N+RtFZK3zv8UicnFl655NNtEb5ZRSqiyPJQgRsQNvAwOAVsBwEWlVpthOoJcxph3wNDCpCnXPGmuQWjOEUkq58mQLojOQbIzZYYwpBD4DBrsWMMYsNsZkOp8uBeIrW/dsstv0PgillCrLkwkiDkhxeZ7qPFaRO4DjozGVrisio0QkSUSS0tPPbME9m85iUkqpcjyZINwtPu72W1hErsBKEI9Uta4xZpIxJtEYkxgdHX1GgdptgtEEoZRSJ/FkgkgFElyexwP7yhYSkXbA+8BgY8zhqtQ9W2y61IZSqoac6XLfAK+//jq5ublnOaITPJkgVgDNRKSRiPgANwAzXAuISH3ga+AmY8zWqtQ9m2w2oUTzg1KqBpzLCcJjN8oZY4pFZAwwG7ADU4wxG0RktPP8ROAfQCTwjnM7vGJnd5Hbup6K1a6zmJRSNcR1ue8+ffpQp04dvvjiCwoKChgyZAhPPfUUOTk5DBs2jNTUVEpKSvj73//OwYMH2bdvH1dccQVRUVHMmzfvrMfm0TupjTEzgZlljk10efwX4C+Vresputy3UgqAWePhwLqz+5p128KA5ys87brc95w5c5g+fTrLly/HGMM111zDggULSE9Pp169evzwww+AtUZTaGgor776KvPmzSMqKursxuykd1JjbeatYxBKqZo2Z84c5syZwyWXXEKHDh3YvHkz27Zto23btsydO5dHHnmEhQsXEhoaWi3x6FpMWIv1FetyrkqpU/ylXx2MMTz66KPcdddd5c6tXLmSmTNn8uijj9K3b1/+8Y9/eDwebUGgN8oppWqO63Lf/fr1Y8qUKWRnZwOwd+9e0tLS2LdvHwEBAYwcOZJx48axatWqcnU9QVsQHN8wqKajUErVRq7LfQ8YMIARI0bQtWtXAIKCgpg2bRrJyck89NBD2Gw2vL29mTBhAgCjRo1iwIABxMbGemSQWi6kG8QSExNNUlJSlevdOnU5GTmFzBjT3QNRKaXOZZs2beKiiy6q6TCqhbtrFZGVxphEd+W1iwndk1oppdzRBIHzRjlNEEopdRJNEFgtCL0PQqna60Lqaq/ImVyjJgjAZkMHqZWqpfz8/Dh8+PAFnSSMMRw+fBg/P78q1dNZTDh3lNMMoVStFB8fT2pqKme6XcD5ws/Pj/j4+NMXdKEJAt2TWqnazNvbm0aNGtV0GOck7WJCZzEppZQ7miCw1mLSBoRSSp1MEwRgt6EtCKWUKkMTBDoGoZRS7miCQGcxKaWUO5og0A2DlFLKHY8mCBHpLyJbRCRZRMa7Od9SRJaISIGIjCtz7gER2SAi60XkUxGp2h0eVWDTWUxKKVWOxxKEiNiBt4EBQCtguIi0KlMsA7gPeLlM3Tjn8URjTBusfalv8FSsNtHlvpVSqixPtiA6A8nGmB3GmELgM2CwawFjTJoxZgVQ5Ka+F+AvIl5AALDPU4HqLCallCrPkwkiDkhxeZ7qPHZaxpi9WK2KPcB+4IgxZs5Zj9DJpmMQSilVjicThLg5VqlvYREJx2ptNALqAYEiMrKCsqNEJElEks50LRWbruaqlFLleDJBpAIJLs/jqXw3UW9gpzEm3RhTBHwNXOauoDFmkjEm0RiTGB0dfUaB6lIbSilVnicTxAqgmYg0EhEfrEHmGZWsuwfoIiIBIiLAVcAmD8VZuif1hbzcr1JKVZXHVnM1xhSLyBhgNtYspCnGmA0iMtp5fqKI1AWSgBDAISJjgVbGmGUiMh1YBRQDq4FJnorVLuKMGcRdx5hSStVCHl3u2xgzE5hZ5thEl8cHsLqe3NV9EnjSk/EdZ3MmhRJjsLkdOlFKqdpH76TG6mICneqqlFKuNEFgLbUB6EwmpZRyoQmCE2MQ2oJQSqkTNEFwYmBa84NSSp2gCQKXLibNEEopVUoTBCcShG4apJRSJ2iCwFpqA7QFoZRSrjRB4JIgND8opVQpTRBYy32DdjEppZQrTRBoF5NSSrmjCQKXQWpNEEopVUoTBHontVJKuaMJAhDRBKGUUmVpgsB1qY0aDkQppc4hmiBwmcWkYxBKKVVKEwSu90FoglBKqeM0QaAJQiml3PFoghCR/iKyRUSSRWS8m/MtRWSJiBSIyLgy58JEZLqIbBaRTSLS1VNx6jRXpZQqz2NbjoqIHXgb6AOkAitEZIYxZqNLsQzgPuBaNy/xBvCjMeY6EfEBAjwVq02nuSqlVDmebEF0BpKNMTuMMYXAZ8Bg1wLGmDRjzAqgyPW4iIQAPYHJznKFxpgsTwWqs5iUUqo8TyaIOCDF5Xmq81hlNAbSgakislpE3heRwLMd4HG20g2DtAWhlFLHeTJBiJtjlf0G9gI6ABOMMZcAOUC5MQwAERklIkkikpSenn5Ggdp0wyCllCrHkwkiFUhweR4P7KtC3VRjzDLn8+lYCaMcY8wkY0yiMSYxOjr6jALVDYOUUqo8TyaIFUAzEWnkHGS+AZhRmYrGmANAioi0cB66Cth4iip/iE10FpNSSpXlsVlMxphiERkDzAbswBRjzAYRGe08P1FE6gJJQAjgEJGxQCtjzFHgXuBjZ3LZAdzmqViPj0FoA0IppU7wWIIAMMbMBGaWOTbR5fEBrK4nd3XXAImejO84vQ9CKaXK0zupceli0iaEUkqV0gSBy34Q2oJQSqlSmiBwXYuphgNRSqlziCYIXJb71i4mpZQqpQkClxaENiGUUqqUJgh0FpNSSrmjCQLdD0IppdzRBIEu962UUu5ogkCX+1ZKKXc0QQA2ncWklFLlaILgRAvCaIJQSqlSmiDQ1VyVUsodTRCATQxeFGuCUEopF5oggJBX6/M3ry91FpNSSrnQBAHgHUAg+TqLSSmlXGiCAIxPEIGSpy0IpZRyoQkCEN8gAinQtZiUUsqFJggAnyACydP7IJRSyoVHE4SI9BeRLSKSLCLj3ZxvKSJLRKRARMa5OW8XkdUi8r1H4/QNIkjytQWhlFIuPJYgRMQOvA0MAFoBw0WkVZliGcB9wMsVvMz9wCZPxVjK2YLQ/KCUUid4sgXRGUg2xuwwxhQCnwGDXQsYY9KMMSuAorKVRSQeGAS878EYLb7BBEm+djEppZQLTyaIOCDF5Xmq81hlvQ48DJxy8qmIjBKRJBFJSk9Pr3qUAD6BBKBdTEop5apSCUJE7heRELFMFpFVItL3dNXcHKvUN7CIXA2kGWNWnq6sMWaSMSbRGJMYHR1dmZcvzyfIug9Cb4RQSqlSlW1B3G6MOQr0BaKB24DnT1MnFUhweR4P7Kvk+3UDrhGRXVhdU1eKyLRK1q063yC8pQRKCjz2Fkopdb6pbII43hoYCEw1xvyO+xaCqxVAMxFpJCI+wA3AjMq8mTHmUWNMvDGmobPeL8aYkZWMtep8ggEozD3msbdQSqnzjVcly60UkTlAI+BREQnmNGMDxphiERkDzAbswBRjzAYRGe08P1FE6gJJQAjgEJGxQCtna6X6+AYBUJCTVa1vq5RS57LKJog7gPbADmNMrohEYHUznZIxZiYws8yxiS6PD2B1PZ3qNeYD8ysZ55nxCQQgX1sQSilVqrJdTF2BLcaYLBEZCTwBHPFcWNXMx2pBFOdVb8NFKaXOZZVNEBOAXBG5GGvq6W7gQ49FVd18rTGIknxtQSil1HGVTRDFxtqPczDwhjHmDSDYc2FVM2cLwlaYTZFOdVVKKaDyCeKYiDwK3AT84FxGw9tzYVUz5yB1oOSTmVtYw8EopdS5obIJ4nqgAOt+iANYd0S/5LGoqpuzBRFIPpk55Vb9UEqpWqlSCcKZFD4GQp13OecbYy6cMQiXBJGRoy0IpZSCyi+1MQxYDvwfMAxYJiLXeTKwauXlg8PmQ5DkaReTUko5VfY+iMeBTsaYNAARiQbmAtM9FVi18wshtDBHWxBKKeVU2TEI2/Hk4HS4CnXPD4HRRMgxMjVBKKUUUPkWxI8iMhv41Pn8esrcIX2+swVGUceWxlJNEEopBVQyQRhjHhKRoVirrAowyRjzjUcjq26BUUTZtnMkT2cxKaUUVL4FgTHmK+ArD8ZSswKjieCIJgillHI6ZYIQkWO43+RHAGOMCfFIVDUhIIogk0N2Tk5NR6KUUueEUyYIY8yFs5zG6QRGAWByD9dwIEopdW64sGYi/RHOBGHPy6jhQJRS6tygCeK4QGs/a5+Cw1jrEiqlVO2mCeK4AKsFEWaOkl1QXMPBKKVUzfNoghCR/iKyRUSSRWS8m/MtRWSJiBSIyDiX4wkiMk9ENonIBhG535NxAqVdTJFylKxcncmklFIeSxDOJcHfBgYArYDhItKqTLEM4D7g5TLHi4G/GWMuAroA97ipe3b5heEQO5FyVKe6KqUUnm1BdAaSjTE7jDGFwGdYGw6VMsakGWNWAEVlju83xqxyPj4GbMJaYtxzbDaK/aOpK5maIJRSCs8miDggxeV5KmfwJS8iDYFLgGUVnB8lIkkikpSenn4GYZ5QHNqA+nJQu5iUUgrPJghxc6xK04NEJAjr7u2xxpij7soYYyYZYxKNMYnR0dFnEKaLiMY0lINk5el6TEop5ckEkQokuDyPB/ZVtrKIeGMlh4+NMV+f5djc8o5uSh3JIufYkep4O6WUOqd5MkGsAJqJSCMR8QFuAGZUpqKICDAZ2GSMedWDMZ7EO7qJ9f5Zu6rrLZVS6pxV6cX6qsoYUywiY4DZgB2YYozZICKjnecnikhdIAkIARwiMhZrxlM74CZgnYiscb7kY8YYzy4xHt4IAMnY6dG3UUqp84HHEgSA8wt9ZpljE10eH8DqeiprEe7HMDwrwkoQJYe2V/tbK6XUuUbvpHblF0quVxjBeSl6N7VSqtbTBFFGSVAsdchk4z63k6aUUqrW0ARRhk94HHUki/V7dSaTUqp20wRRhm9YLLG2LDYf0BaEUqp20wRRVnAsERzh8NHcmo5EKaVqlCaIsoLrYsdB8bG0mo5EKaVqlCaIsoJjAbBlH6jhQJRSqmZpgigruC4AvnlpurOcUqpW0wRRljNBRJoMjubpvRBKqdpLE0RZgXUwCHUki0M5BTUdjVJK1RhNEGXZvSj0jyZe0jl0TBOEUqr20gThRmF0O9pLMoeydV8IpVTtpQnCDanfhSa2/RzL2F/ToSilVI3RBOGGf9NuAPgdSKrhSJRSquZognDDHteBQrwIP7SypkNRSqkaownCHW8/9no3JCBra01HopRSNUYTRAVKwhsRXbiXg0fzazoUpZSqER5NECLSX0S2iEiyiIx3c76liCwRkQIRGVeVup4WGteSeEnn91VL4agOViulah+PJQgRsQNvAwOw9pkeLiKtyhTLAO4DXj6Duh4VVf8ivMRBr1+vZ/9Hf2HuxoPV+fZKKVXjPNmC6AwkG2N2GGMKgc+Awa4FjDFpxpgVQFFV63qaRDYFwNfkE562jLfnrq/Ot1dKqRrnyQQRB6S4PE91HjurdUVklIgkiUhSenr6GQXqVmST0od+UkTQwZXk6D7VSqlaxJMJQtwcq+zyqJWua4yZZIxJNMYkRkdHVzq40wqIxPiGsIcYioydbrKW31Ozzt7rK6XUOc6TCSIVSHB5Hg/sq4a6Z4cIctl9FPd8lNyEnoyw/8zmrduqNQSllKpJnkwQK4BmItJIRHyAG4AZ1VD37On1EI2vvI3Qa1/GT4pouvrfOBy6R4RSqnbwWIIwxhQDY4DZwCbgC2PMBhEZLSKjAUSkroikAg8CT4hIqoiEVFTXU7GeVlRTtrUcTc/Chfw26+MaC0MppaqTXEi7piUmJpqkJM+sn+QoKmDv8x3Jc3jR9O+rsdncDZO4YQykJkFxHjTq6ZHYlFLqTInISmNMortzeid1Jdm8fclqfTPNzU6Slv9W+YpL3oLJveGDP0GJzoJSSp0/NEFUQcvet1KMncNLPqx8pf2/n3icrTfbKaXOH5ogqsA7pA7bQy8jMetHcnJzK1fp6D73j5VS6hynCaKKHB1vJ1qOsG1+JQerj6RCHecqIUdTPReYUkqdZZogqqjZZdewhxhi1rwFhadoRRzZC7uXWK2G+E4AFGakVFxeKaXOMZogqsjLy4tfGz9ETMFucr4YBSVll5Fy+vV5+OBqcBRBTBuKbH58+csySlzvoygphl2LYM/S6gleKaWqQBPEGeh37U28YkYQmPw/Sj4cAoeSrdaE65Th9C3gcM5aCo0jXSIJK07jgOv+EmumwX8HwZR+5O9cUr0XoZRSp6EJ4gzUCfEjduAj/K1wNMV7lsNbHeHZWJj25xOFDp1YliO5IJRdReHESgZ7Drt0S6VvoVh8yDBBZM56thqvQCmlTk8TxBka2aUBHQbfTd/85/ipyWOY1kNg+y+QlQK5GZCXUVr2+k/3sM9EECsZpGS4JIjM3ey3x/J+8SBi0xbAjvnVfyFKKVUBTRB/wIjO9bm4XQfu3NCGsQcHWQc/GwFvXwpArlcY+cabw4Sww1GXWMnAZ9v3pfVN5k6Si6L41H41Oxx1Kfx6DBzTeyWUUucGTRB/gIjw+vXteWFoW37NCCXZUQ8OrIWcNADuzh3FV02eZvljvelx099Zb2vBwG1PQkE2GIPJ3M2ukiju7duWp73G4MhOw0zqBQtegsKcGr46pVRtpwniD7LZhOs71Wfe3y5na6v7eL9kUOm5PWGduW7EKOqE+NG1ZX3+F3k7PqYAdi6AfauxFeWQYurQo1kUAwZcy9CCJznkEw+/PAMTulnTZJVSqoZogjhLwgN9GHjDX7H3/zf3Fd7D5OIB9G2bgK+XvbRMXt1E8vGGr++E964AYJ8thkZRgVzXMR6v+PYMODKeYzd8C8YBUwfAyg9q6pKUUrWcJoizbGjHeGbbevB08U30aVXnpHMt4qNZVnIRFGafOBjWAC+7DZtN+Pe1bTiSV8g9iwM5cst8aHoV/O8++HQ4ZJ/F7VSVUqoSNEGcZSF+3gxuX4/YUD/aJ4SfdG5oh3h+9elOhoSxtO4IsgnAP6Zp6fk2caH885rWLNiaTuLLSxmaOYasSx+C7fOsm+4WvwVFedV9SUqpWsqrpgO4EP1rcBvyCkuwl9kzws/bTrN+f6XrjO4U7AIYxAN1T95H+8ZLG9A+IYwf1u5n2tLd3CyXM33YZfh8PwbmPA7ZB6DvM9V2LUqp2ktbEB7g520nPNDH7bnhneuT9ERffLxsgNC0TlC5Mq3rhfJw/5a89H8Xs27vEf7vJ1+2jFgGHW6GpROsDYjcyT8CLzaBddPPLPDPR8J3Y86srlLqguPRBCEi/UVki4gki8h4N+dFRN50nl8rIh1czj0gIhtEZL2IfCoifp6MtToF+3lzRQur5dAspnyCOK5f67pMHNmRHenZ9H9jAU8cuw5HSLx1x3ba5vIVdsyH3EOw6X9VD6q4ELbOwaybTlpGxunLK6UueB5LECJiB94GBgCtgOEi0qpMsQFAM+d/o4AJzrpxwH1AojGmDWAHbvBUrDXhzh6N6dPKmsF0Kv1a12Xhw1cwqmdjPtuQwwN+/8LYfWD6bdZ02KmDrBZFVgpsnW1V2rXIWhfK4bDuqXDdtGjXb1bZsg6sg5ICpDiPTz6twoZIleFwWMueK6XOK54cg+gMJBtjdgCIyGfAYGCjS5nBwIfG2hh7qYiEiUisS2z+IlIEBAAX1G47iQ0jSGwYUamyYQE+PDrgIprVCWbcl7/TtsXD3JHyGLLgZfD2t+7ePr5bnZcf5B7C8Xo7bLHtYPP3sHc1DP/EWgLko2uhaW8Y/unJb5K6HIA848NVhz+B9IEQ3dxqqaz9HKJbwMVnkKNLiuC/V0PKUhi3DYLqnL6OUuqc4MkupjjA9U/VVOex05YxxuwFXgb2APuBI8aYOe7eRERGiUiSiCSlp1/YU0Gv6xjPfVc25ZktcTzR7BvyH06BoZOt5BDbHhNYh7n1RgNgO7LHSg52X9g2B2Y+DN+PhZJCSJ4LeVmw8TvYvxZ++Bv8OJ5830ieKR5Jo5LdmP8OgpxD8MODsOhV+P7BU+9/UZHV06zkAJC26Sz+NpRSnubJFoS4OWYqU0ZEwrFaF42ALOBLERlpjJlWrrAxk4BJAImJiWVf/4LzQJ/m2GzC63O3sSd3IwPbtuFQ40ksOBJFvYQIvluzj1uCH2RhThzXtAymV6MALvl5JCx/FwATEIXkHuLge9cRk7ECwhpA1h6w+7A04HI+PtKblY7mzMr7h5U49q6EmLZwcB3M+7e1+VGLgVCcB36hFQdqDORlwl6XAfXD26Bxr8pdaG4GBFSuhVXO6mnWLn5xHU5fVilVIU+2IFKBBJfn8ZTvJqqoTG9gpzEm3RhTBHwNXObBWM8bIsLY3s15cWg7FiUf4tGv1/H+znCOFHvx3Zp9dG8axb33j+doQAMmbgvhzzOFhRFDOXTVq9BtLMsTX2Wdo6GVHKJaQNZuwFBw12LuzbyehAh/Npv67G82HDZ+C8X50H0sBNaBJW/BV3+xBslfbQ1b3TbqrI2QPvgTvNjIWlak8eXgHXjSEujlpG2C9V9ZdWc/btVN/rnqv6Cj+6yZWAternpdpSrgcBh+3ZqOMRf836An8WQLYgXQTEQaAXuxBplHlCkzAxjjHJ+4FKsrab+I7AG6iEgAkAdcBVQwt7N2GtYpgctbRlNQ5CAuzB8DzNlwgMuaRBEa4M3yx3pTUOzghR83c1fSMHzm2agb0oxdh3PIL/o3XuJg+Y3dCZ/QDoluwa/pwRzLL2b8gJY8/s16koKv4BqsZT6K44/ar1sAACAASURBVC9luv/1xBetplvREmTXQvALgy9uhntXQqiz59AYKC6AZRNh10LrWNYeaD3Eak1UlCB2zIcPrwUMJN4OSVOs49t/gUY9YcO30HIQ+AScqGOM1XWWcCn4h504vvYL63VSllllxF0jtZIydsCPj4HNDjdUcg9y5V5RvrXEzOXjIaZ1TUdTZQuTD3HLlOVMH9210mOHFwKPtSCMMcXAGGA2sAn4whizQURGi8hoZ7GZwA4gGXgPuNtZdxkwHVgFrHPGOclTsZ6v6gT7kRARgM0m2G3CgLaxhAZ4A9Yigv4+dv55TWtm3d+D5jHBhAV4M7RDPM8OaUexsdPhhSW8UfdZvoh/jOd/3ExEoA9DO8QDcP8iLw5KFCYknn/Mz2J8aldGHr2b5eGDKIlswe4h31nrRU3pDx8Ngb2rrMHyV1vCkrehUS8Ids43qNuOfV7xsP1nHC81gxWTrXGQl1vAry/BotetweuASEiaag20x7SB3Yut1/76L9ZrGgM7frXuJp85Dj4ZBvOcGy2t+cRKQGs/B7FB7iGKD22v+i91+XvwzV+tmVdz/wlbZ1ljOflHz+xDKi6An/8Fn1wPOYfP7DUuBGkbYdMMmDa0piM5I8f3cdl1uArjcNt+OvN/N+cIj95JbYyZiZUEXI9NdHlsgHsqqPsk8KQn46stGkQG8sVdXUufF5c4eOybdQC8vjUStubTMDKAe65oip+3tbigwcbDBXfQwM/OJ8v28NfLm5BfVMKIJTfQpm4QGz/cx9xOY2iw+ytrmu17V1hfzN4BVmuhy39g64+wcirbbA1ZlGLjNoDcw9bAt83bmoE1z3lX+OWPQuYu+P1Tq0sqogksffvERWydBflZVjdX8/7WawPsW2UljW//arUm0jaS3/ZG/NZ9zP++/4Yhtz1U+V9UYS788rR1w2FMK2u6sF+Y9b7pmyGhc+VeJzUJPrvRSqAdboaFr1jHd/4Kbf586roXqmP7T/x0lFitsvNF2iau+6kPH8njpGY2q1yd3Az4+DpI6AJ3zPZsfB6kS23UQl52G9/f251Qf2++XJlKVJAPN3VpgDi7Y4Z3rs++rDygNzNSs3h8YFP+0qMRezJymfrbLn7fl42ft42rV1/KdYlDMYd38ESrdLwadLFu1Nv8A3kNrmT54RCKoooZNW0/vfwvpYdjDZ83foHHG2y0/lK/8UsrYaz9AtPpTmTXAitBNO9PiV8YdsCR0AVb06usAfK9K8E3xEoOYrem3a77EmY9Yl1YyjIAXjpyJfeab6m782vY0xNC4090gy18xWqJ9Phb+e6n9dOt5BDdEn56EkwJ9HwYFrxojZFUNkEsnWDt51GYbc0AC461ZpqdS7O4cjOsVlxwLDTq4fn3c70PZvMP0Ooaz7/n2bLtJ/xKjvGw1+f8mFnJodC8TOvn8Rl85ylNELVUmzhrBtKDfZqXO/fcn9sCVksDrIQCVkukW9NI1qYc4au7L+PmycuZ+tsuwIZfzGWMat2YDUejCWzdlmemrGDVnix87IO4o3sD7rmiH0/O6M5vyYe4a8h9rIwYScfgCKJiffkisxkvvraKa9o2xi53MvenWIJsBbzoqM8iv1u5s2U7K0G0vBpaDbb6shtfjqPFQGxrPob0TdB2GKz7gpKgekzZ5sdR24285D0JpvSFoLpw6/fgKIafnwacYyVXPm5N5S3Ks7q4Fr4KMW1YmvgqnWcOsPpfL7kRFv/HakFURl6mdSd7x1soSduMfdcCPs/rxJDQDfikbTx9/ery/VhrmrNPEDyyG+we/io44pzNHtkMvrwVbvzCuh/nfFCcD0B323o+OlzJVQbys1weHwW/EA8E5nmaIFSFjicGV68Oa09WbhHNY4L5cnRXktOzmbVuPxN/3c7kRTsoKrFmeXjZrN32ereKIcjX+mc2oE1dvluzj8Rn5paWuTghjJW7Mwn192bKklQuThhC+6hADmUX8Erdqcxdd5AF+dnUD3uRDg2v5E/NYpF6iexqPJJ7vipgDpAR3Zn1LR7l0nXfsqikHcYITfuO5qE5MLB5ID0PfIj9/asguJ71hdi8n9UqSFkGu3+zEkdgNOSks3vgNG75LoNH6EPvoB3c98le3vGpT8GmJBr1r8QvbcVkKCng18B+fLvNi9e8F/BlTnvaBR/jInctCEeJNY6y8r8wZKL1pbn9F6jfBXxOfZf9GSvItu66D461unwOroN6l5z56x1KtsaJhn0EYQnuyxxJhcimcOfPFL/TDfuCV5DzJUEc3QuArxTRMGMRcMXp6+S5JIjdv0GLAZ6JzcM0QagqiQnxIybEWhYrISKAhIgAejSNom1cKJsPHKNPqxhKHIbmMcEkRAScVLd/m1im3taJxcmH6NY0il82p/HzpjTG9m7GqJ6NWbD1EJe3iC4dBykoLuHl2VuYtyWdvaYFH3+7lb99uxV4EHZAXJg/T3mPZ/Ghhmz7eBOXeP2THZkRJET4c32nBNrPupwvN0HHkOZ8HvMRXnmH4U+vczCuD+GHd1t/0Xe52/qi3DEPwhvy0KooQvxzeMdxB//KKiS0IIclxdH0syVx9H+PE9KmvzXWYfe2xhgKc2Dxm7DpewiKhr2rKGo2kHGLICC0D48FtQVpyIK0TbQ08ynOz8Hbz+WLf8VkWPgyePlbU3NXT7OmF3e4Ba550+ry+ulJOLgeuj8ATfvAN6NO/PUdXLfqf4lv/dH6q7jvM/DVHZTsWozdNUHsXGgN9v/pjcqNFaz9HPatht8/g14VjPlkpUBoPDuzvfg8syfjj35MXsoa/BPaVy32mnB0H1tMA6I5TPu8pZQ4TLmVmstxaUFkrZxO2HmaIORCmtebmJhokpJ0NuyFqMRh+Hb1XvZl5RHk54UxMLBtLHsychn27hIaRwXywe2dGfbuEq7rGM/f+rbg9v+uoKjEweLth+nSOIK3hnfgcE4hw95dQm5+IQ/2bU67hAh+XH+AVrEhtKgbzOC3f+PvV7eiSXQgq/dkce+VTUlZt4C0rx+hkz0Zmym2BuNt1mwxvPyg4Ig1ayvnEGTu4qN2H/D33wr59p5utE8IY/6WND7/4C0m+LxBar3+xHtnQ9MrrWVIFr8F8YnWwPxc55yM2PbW2liNe1k/8zLBP9waMG/ezxqot3mDo8gq33WMdVNgVAuIambN+PIPh8TbnL+8Iuumx/wjMPBl+OBqHPlHGBf3CWM3Xc8uryZ0f3wWtuNfelMGwJ7FcP00uOhPp/9wJvaAA2tJ92+C/9jlpS3Gk7zcApr15lnvMUxftI753vdTFFCHyMYdrDiNsWIPqVe1fxhbZll1Ww6suMyK92H913DpXVYXZRWVvH0ZvxzwxeEbQueiJPLu30K9iIoX2bTeczL88CA/l1xCV9tGAh7bDr7BVX7v6iAiK40xiW7PaYJQ57tZ6/bTJi6UhIgACosdeNuldMAd4IukFJ74Zj3edqHIYQjx8+Li+DB+3pyGj90GAoXFDkL9vXE4DIsfvZJgP++T3qP3q7/SILCYyT3zrMUPi/OtrqmcQ9D1bo5FtOG35EP0aBJOz5cX0i4+lKm3nRjU3n3gEFvevZlerMQ3sj4c2mqdaNCNo/3/w/T1WXRbehf57W6iaY9h8E5XvIOj8I5rx/LIITQPzCZ8pnN2eKvBmG1zIboFGaFtiNzkXFwxuB6ExFqD+QCxF0PjKyBj+4kVfu2+YBy8XOdZJuyJ579hU7gkZyH7rp1O80t6QPpWeLuTVbbeJXDbj+B9ioWUj+yF11pxNKABIbm7+bbzp1w7sMyXdXEBPFOH4p6P0GlRIl0aR9Lg2CoeOPgoPlKC2H2gOJ8CeyC5dS4hPHGYNfvrdPewpG2Gd3tYExbuW21de1mpK2FyH/DyteJ4KLnKd+iXPN+QT7I7QsMe3JT6JPsbDiH2hjdPPa6w8FX4+SmGFz7Opz7/pmjAy3hfemfF5fcspcBhw56Q6LZr15NOlSC0i0md9wa0PfHFYO2zcbJhiQlcHB/G5EU78PWyM6pnY6KDfRk6YTF5RSV8eVdXJi3cwdYDx7irV5NyyQFgUNtY3vh5G3+PaUjTOm0Y1C4Wb7uN4hIHxQ7DQ5+sZsHWdIJ8vcguKOauXk1Oqt+gbhTvtnuBsav3kjSqN3t2JtM4LoZ5uwv428TfyS4oJiroObKWFVFvy2b2ZL9F97rRXBoewSuzt9I0sg5Twjrjn9CetEvH8/i22URJPRasy6NdSUMujzzCmOz/WLOlrpvK+t9XEJuxjMjfXrcC6P88DmMwqSvZkvB/vPVtCY/0b0G75s+T9W4/msy4FlZ2sAbj7T7suvhBGq56nuK3OuMV2ciaAtzrEQgIt2Z5FeZaXWq/PA1i562wh/lrziM0XPkcpn9/xObyOexfC8DWgggyc4sYlphAQXEcl04L5qVBCXRdcDO7o69kz4F0mu/bQfj/7rO6q/o+bbWuwEpEW3+0WlfxHa2xm+/uAe8ATGEO5tMbsHW7v/w04l9fgMAo5rZ4it4rR/PxR5MYfucjJ1pLp1OUhz0/k/0mgi7db2DyZ6u5ddd38P4GuPWHihefzM/CYfNhiaMVyx0tuOTnp6H14IrLTx2IrylhQslgetz1Jm3iw9yXq2baglC1VkFxCQC+XqfvZy8qcfDw9LV8s3pvhWVu6JRAZm4hQy6Jo3+b8n/N/pZ8iBvfX4aft438IqvFciSviIsTwnhuSFviI/x5asZG9mblEh7gw6z1BwDo3jSKpTsOU+wwBPrYKTEGb7uNY/nFRAb68H+JCUz8dTuP1d9IbEwMaTE9ePr7jfh72/m+TybrUzPYHt2H+VvSKChyEOBrZ19WHvPHXYG/j52/Tvie3hmf8efYw0hUU+hwC9d+V0DY3nnc5TuHNmHFBBRlYs8us1JOWH3I2kNJ94e4eGEnRtrmMN68T0ajq4noerPVAgmIsu4H2Leaxxt8zIzNx1j5RB9E4Oo3F7Hl4DEEBwabtSKAo4Thtp8Z4/0tkp1mrf0VlmBNjS3KBbuP1VV07ACs+xLHkElM/fl3rsn+kihzGPnL3BNrcOVlwUtNKe40is4rLmemYzS/lzSCGz6mX+u6J66jMNeaghzfsfyHeng7/KcDD5fczZNPPM1Ls7ewffksPvR5Hmk/HK75j/t/DDPuI3/jTFpmvUET2cuPvo9iv+hqbNd/UL6sowT+daJV827gXdz10IsV/js727QFoZQblUkMx3nbbbx2fXueHdKW7enZ/JZ8CLtN8Lbb8LIL9cL8ubx59EldW2V1axrFhBs78NPGg7SOCyVpVwYdG4QzskuD0oH5V4ZdDEB2QTEpmbl0bxrNQ/1asPtwDnlFJYz7ci0NIwP45zWt+XVLOs1igmgQGcjkRTt4dk8ra/1jNtKjWRSLtx/mqpkh2G2hOMw27CIUO6w/CJ/7c1v8faz37NulPQ98LuxMbEqjqEACs7xYk7KS27oNYfzmbuzen0sI2VwfsZ2rLqpDp6BD2O12axn5xDuYGzKU7IK1tBh2P+/MOMqdO7+Bnd9bF+3lB8X5FF/1L77/JZs+F8WUtvIm35rIXz5Iol/ruqzbe4ThnesDcOeHhey/+GoetH9JRE4ytuS5UL8rXPkEuf97BP8lbyPGcLDREF7b1pLP0oJ4g4tZHPI4flOvxt7qaqTFQEjfAo4ifqILGblFONpfw1WbP+Sfs6fTt9U9pZ9V1i+vEbb0RYpvm4NXg0ut9bxW/hd6PoTjyF5sQN34xgT6enFz1wb8KakNnzj6MGL1NMQvzFoBIOFS6z6Z44P6+VkU2K1xihGD+vD6rBU8tOkL+HCwNSW7/YgTXWg5hwD4R9EtDPFaSs9js0hO+4fb3Sarm7YglLoATF+Ziq+Xjc9W7CHQx4v/jLiEDxbvYk9GLmOuaMbR/CKKSwzvLtjO9vRsvr27W2lft8Nh+POExaxJOTHzJirIl3njeuFwwPytaaQdLeCrValsPnCMUH9vQvy9GNS2Hv7edj5etpvwAB9m3NuNCfO3M2nuOl7tKfQN248tazckdOaNA2157edkpt1xKd2bRZ3yWl6avZkJ87fjMHBZk0ju6tWEb1alkldUws+b0qgT7Mvt3Rvx75mbMAY6Nggn7Vg+vpnbuNM+k2t8kvB3ZANg6rSm17FniAz25evbWpP19lXYj+0l5dqvaX2JddPb9ue60KRgEykhHUi4fw58ezes+wJGfs3ubetosOxJ5vT9ib6XWWNKO9KzGT9tAaMzXuAKr7WIse4XIjAaRn4Nse3gg2vYfziTrmnj2fx0fx74dAW9k5/jT+G78TmyE/q/AF2cY0r71sCkXowqfICbmuTRI2UibyXOYczVl57NfyIV0kFqpWoJY8wpWzHGGEocptxA6N6sPFbtziQu3J/UzDx6NosiLMCnXN2fN6UxZ+MB9h/JZ+E26y/f6GBfpt7aiTZxoRzNL2LUh0ks3ZFB46hAAnzt1Av155fNaQxsG8ubwyt3v8WO9GzmbDzI87OsGxTDArzx97bTtE4QS7Zb3W09mkXx+vXtCfH3Zkd6Dvuy8li2M4Mpv27m/jYFdG0QxD7/5oyZvpWJIzvSv01dctN3c+yty/H3MoQMm8A239Y0mdqOXRJHY1I55BNPZNE+60v/0tGs3baTmMPLCRi/lWD/E7+P/KIS+r++ALujCH/Jp0PRGp5kEvbW18C178C7vdiWG8DgzPvZ+K/+pB3Np89rCwj3t/O9uRd7fEf8b/wIh8PA1h+xfXYD1xb8i4d6N6bbwpG8FP4PHrr/b5X6Xf1R2sWkVC1xquRw/LyXvXyZuDB/4sL8AehQP7zCur1bxdC7VQxgfUl62eSkZBPi582nd3Zh1voDTP1tJz5eNlanZDG0QzyPDbqo0tfRODqI0b2CiA31Q0To1zqmtEvwp40HKSguYWCb2NLB5hZ1g2lRN5jLW0STmpnLS2v3w3rwsSdzUWwIfZ0xB0Q3YGqr/3DlhkcJ/nQ4h0MH0EwMocMn8fnydcRv/ZAWoYFEhYVits4mMjOX1MA2dPQ/OVn6edsZ27s5Yz9fQ/OYUL4v6Epv37X03PQ/uPo1yM/iKNGEO5NsnRA/pt7WiVsmLyfJEUWj3ZtoAPR4cR73hiVxA3DQhGOL70Ch+FL/6GrrjZZOAJsXdD7FDCgP0gShlDojx8dNyhIRBraNZWBbN9NOq2hw+7KbUEIf55d9Re/91ogOPPfnIl74cTPJadm8NaLDSbOWRl7Tj+F7bEzMGUuXIzPZE3Qx9Zt1YVjzy7jzw478sjmNe4sW8EDBROKAjIY3VRBbPSICfUhsGM6HS3YzeXYHevr8xLE3LiP42C6ygtsREXgisXSoH86Sx65i4/ufE542i+SDx3g65yk65G0DgXRCCQ8N5lBQc+KP7KAgPxffX/6NCYxE3CSIeVvSSmfeeUr1TrhVSqlqEOznzTPXtuWzUV2JCvI96Vyovzfv3NaLF0Kf5E3HMHxu+w5sdkSEF6+7mLsvb8qmmGtIxUpEzRLd36kuIvRsHk2AjxcjuzQg6KLeTPMeSsExa+vjjBJ/wgJOnjId5OtF0xZtCZFc5k6fyJX2NYRJDpkSSjFeRAT4UBIcR10yyFw3GwqPIZm7yMk6dNLr5BeV8PD0tTw3azM/Ome7eYImCKVUrdMwKpA37x/BzePfpm7kiS61iEAfxvVrwaTbuxH/2Gq46Rv8Gnc9xStZgny9ePumznS5803edFwPQNbRYye1IErfI6ElAEPTTkyRFUcxAOGBPniHxxErGZiNM0rPvzf9u9LHJQ7Du7/uIP1YAdHBvjz9/UZrLMMDNEEopWolu03KDcSfxCcQmlxZpddsWieI2+/9B6943cF7xYNKxyBOEt4IgGg5wkxHFwDCJIcQPy+87TYCo+oTIAWEps5jmcNKJjm7VrI3Kw+A52dt4rW5W+nRLIonBl3E3qw8lu+q5CqzVaQJQimlzqKG0cEE97yHNMLJzC0sXyC8QenDKeFjAfiyuCf5RdZ02cBo63xAUSZLHReR41eXNrKTL1ZYS6b/lnyYu+tt44Nmv9Hnojr4e9uZ8XuZmxjPEo8mCBHpLyJbRCRZRMa7OS8i8qbz/FoR6eByLkxEpovIZhHZJCKnb+cppdQ5YGSXBlzVsg43d21Q/qS3P0Vtrmdc8V+pV7cuv9+2nYeK76LQuf+KLfTEwHyyIw5p0JXeXmv5cfV2ShyG7enZ3HfkRWy/PEXAqkn0uyiSmev2U1jsOOvX4bFZTCJiB94G+gCpwAoRmWGMcd01ZQDQzPnfpcAE50+AN4AfjTHXiYgPcPLa0UopdY4K8PFi8q2dKjzvfd0kejTdS/OYYBpHBwIuU49dVrRNNnH4X3Y1suUbOh2ZzdYftjLU7MbbOFsmsx/j+ajW7LjtO7zdTF/+ozw5zbUzkGyM2QEgIp8BgwHXBDEY+NC5N/VSZ6shFsgBegK3AhhjCgE3bTWllDo/uU7h/Uv3RlwU61wdNqguRmw4HIYdJhap34WimPY8c3AqrIRnvQEHMGQSFOXi9/1YWu35BBLuP+sxerKLKQ5IcXme6jxWmTKNgXRgqoisFpH3RcTt9loiMkpEkkQkKT09/exFr5RS1eSJq1sxtGO89cTuhQTVpSikPl/ccwWI4H3Tl/w38HbeKHZZrbbBZdZeGs0HwKLXrEUHzzJPJgh37Z2yc7EqKuMFdAAmGGMuwWpRlBvDADDGTDLGJBpjEqOjo/9IvEopdW6IbYdf425cnOBc9juoDs3//DivFQ9lo6OBtc96qDOhDHgBbp8DPme/F96TXUypgOsGtfFA2aH2isoYINUYs8x5fDoVJAillLrgXP9xuUOXNYnirREdSEl/jVZN/U+sBhvuZiD8LPFkglgBNBORRsBe4AZgRJkyM4AxzvGJS4Ejxpj9ACKSIiItjDFbgKs4eexCKaUuXHb3X81Xt6sHVHFb1j/AYwnCGFMsImOA2YAdmGKM2SAio53nJwIzgYFAMpAL3ObyEvcCHztnMO0oc04ppZSH6XLfSilVi51quW+9k1oppZRbmiCUUkq5pQlCKaWUW5oglFJKuaUJQimllFuaIJRSSrl1QU1zFZF0YPcZVo8CDp221PlBr+Xcc6FcB+i1nKvO9FoaGGPcrlN0QSWIP0JEkiqaC3y+0Ws591wo1wF6LecqT1yLdjEppZRySxOEUkoptzRBnDCppgM4i/Razj0XynWAXsu56qxfi45BKKWUcktbEEoppdzSBKGUUsqtWp8gRKS/iGwRkWQROe92rRORXSKyTkTWiEiS81iEiPwkItucP8NrOk53RGSKiKSJyHqXYxXGLiKPOj+nLSLSr2aidq+Ca/mniOx1fjZrRGSgy7lz+VoSRGSeiGwSkQ0icr/z+Hn12ZziOs67z0VE/ERkuYj87ryWp5zHPfuZGGNq7X9YGxltBxoDPsDvQKuajquK17ALiCpz7EVgvPPxeOCFmo6zgth7Yu09vv50sQOtnJ+PL9DI+bnZa/oaTnMt/wTGuSl7rl9LLNDB+TgY2OqM+bz6bE5xHefd5wIIEOR87A0sA7p4+jOp7S2IzkCyMWaHMaYQ+AwYXMMxnQ2DgQ+cjz8Arq3BWCpkjFkAZJQ5XFHsg4HPjDEFxpidWLsQdq6WQCuhgmupyLl+LfuNMaucj48Bm4A4zrPP5hTXUZFz8joAjCXb+dTb+Z/Bw59JbU8QcUCKy/NUTv0P6FxkgDkislJERjmPxRjn3t7On3VqLLqqqyj28/WzGiMia51dUMeb/+fNtYhIQ+ASrL9Yz9vPpsx1wHn4uYiIXUTWAGnAT8YYj38mtT1BiJtj59u8327GmA7AAOAeEelZ0wF5yPn4WU0AmgDtgf3AK87j58W1iEgQ8BUw1hhz9FRF3Rw7Z67HzXWcl5+LMabEGNMeiAc6i0ibUxQ/K9dS2xNEKpDg8jwe2FdDsZwRY8w+58804BusZuRBEYkFcP5Mq7kIq6yi2M+7z8oYc9D5P7UD/r+9uwmxKQ7jOP79yUveIholCwazkELZeSlFwooaESbJ0sZO8lb27BTJwsskEZGlKVMWmskYDEZiZY+iSDwW//9l6MzteLnO3Pw+dZsz/zn39Dz9O/Occ+49z+E030/xR3wuksaQ/ql2RsTVPNx0c1OURzPPC0BEvAFuA+to8Jz87wWiF2iT1CppLLAVuFFxTKVJmihpcm0ZWAsMkHLYmVfbCVyvJsLfMlzsN4CtksZJagXagJ4K4iuttuNmm0hzAyM8F0kCzgBPI+L4kD811dwMl0czzoukFklT8/J4YA0wSKPnpOpP56t+ARtI3254ARyoOp5fjH0u6ZsKD4DHtfiB6UAX8Dz/nFZ1rMPEf5F0iv+JdMSzu17swIE8T8+A9VXHXyKX88Aj4GHeYWc2SS4rSJcjHgL9+bWh2eamTh5NNy/AIuB+jnkAOJzHGzonbrVhZmaF/vdLTGZmNgwXCDMzK+QCYWZmhVwgzMyskAuEmZkVcoEwGwEkrZJ0s+o4zIZygTAzs0IuEGa/QNKO3Je/X9Kp3EDtnaRjkvokdUlqyesukXQ3N4W7VmsKJ2m+pFu5t3+fpHl585MkXZE0KKkz3wlsVhkXCLOSJC0AtpAaJC4BPgPbgYlAX6Smid3AkfyWc8C+iFhEunO3Nt4JnIiIxcAy0h3YkLqN7iX18p8LLG94UmZ1jK46ALMmshpYCvTmg/vxpOZoX4BLeZ0LwFVJU4CpEdGdx88Cl3PvrFkRcQ0gIj4A5O31RMSr/Hs/MAe40/i0zIq5QJiVJ+BsROz/YVA69NN69frX1Lts9HHI8me8f1rFfInJrLwuoF3SDPj2PODZpP2oPa+zDbgTEW+B15JW5vEOoDvS8wheSdqYtzFO0oR/moVZST5CMSspIp5IOkh6gt8oUufWPcB7YKGke8Bb0ucUkNovn8wF4CWwK493AKckHc3b2PwP0zArzd1c54d1HQAAADtJREFUzf6QpHcRManqOMz+Nl9iMjOzQj6DMDOzQj6DMDOzQi4QZmZWyAXCzMwKuUCYmVkhFwgzMyv0FZ+rNWzQhybIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):282.5405405405405\n",
      "Fold score (RMSE):16.808942279053152\n",
      "Unsupervised Fold #7\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 5s 5ms/step - loss: 0.2024 - val_loss: 0.1343\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1299 - val_loss: 0.1168\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1201 - val_loss: 0.1084\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1095 - val_loss: 0.1016\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1078 - val_loss: 0.1020\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1048 - val_loss: 0.0968\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0998 - val_loss: 0.0936\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0986 - val_loss: 0.0938\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0974 - val_loss: 0.0967\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0958 - val_loss: 0.0928\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0948 - val_loss: 0.0902\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0923 - val_loss: 0.0890\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0935 - val_loss: 0.0900\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0931 - val_loss: 0.0948\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0922 - val_loss: 0.0867\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0888 - val_loss: 0.0867\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0901 - val_loss: 0.0914\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0902 - val_loss: 0.0865\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0907 - val_loss: 0.0913\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0890 - val_loss: 0.0895\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0897 - val_loss: 0.0844\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0819\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0848 - val_loss: 0.0827\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0839 - val_loss: 0.0825\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0835\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0858 - val_loss: 0.0827\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0813\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0840 - val_loss: 0.0855\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0847 - val_loss: 0.0789\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0830 - val_loss: 0.0810\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0833 - val_loss: 0.0804\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0814 - val_loss: 0.0804\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0816 - val_loss: 0.0781\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0799 - val_loss: 0.0808\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0821 - val_loss: 0.0859\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0880 - val_loss: 0.0848\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0845 - val_loss: 0.0805\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0800 - val_loss: 0.0791\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0803 - val_loss: 0.0778\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0765\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0780 - val_loss: 0.0765\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0772 - val_loss: 0.0758\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0772 - val_loss: 0.0765\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0780 - val_loss: 0.0754\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0761\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0805\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0792 - val_loss: 0.0752\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0756\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0776 - val_loss: 0.0760\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0769 - val_loss: 0.0753\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0747\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0746\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0793\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0753\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0763 - val_loss: 0.0740\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0750\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0751 - val_loss: 0.0732\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0744\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0742\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0752 - val_loss: 0.0744\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0748\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0741\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0784\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0764\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0762 - val_loss: 0.0770\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0769 - val_loss: 0.0729\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0740\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0746\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0726\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0732\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0736\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0728\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0747 - val_loss: 0.0745\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0751\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0722\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0731\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0728\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0735\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0731\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0724\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0729\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0724\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0726\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0728\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0723\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0724\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0716\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0756\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0732\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0732\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0745\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0757\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0768\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0716\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0709\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0704\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0699\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0697\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0698\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0695\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0701 - val_loss: 0.0694\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0698\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0696\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0698\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0723\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0742\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0750\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0769 - val_loss: 0.0714\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0721\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0715\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0700\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0694\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0691\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0688\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0688\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0685\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0687\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0693\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0685\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0694\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0730\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0716\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0732\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0703\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0733\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0746\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0689\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0690\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0693\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0696\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0700\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0686\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0685\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0685\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0683\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0686\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0695\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0706\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0713\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0689\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0689\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0684\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0680\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0679\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0683\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0689\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0698\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0708 - val_loss: 0.0684\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0692\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0709\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0685\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0691\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0707\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0692\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0691\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0677\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0680\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0691\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0684\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0706\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0687\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0694\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0677\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0678\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0683\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0679\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0682\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0689\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0688\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0692\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0675\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0686\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0705\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0683\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0689\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0695\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0677\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0678\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0671\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0670\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0675\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0671\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0673\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0682\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0672\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0674\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0675\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0685\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0697\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0693\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0696\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0704\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0706 - val_loss: 0.0675\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0681 - val_loss: 0.0671\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0677\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0686\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0695\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0675\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0683\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0699\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0672\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0674\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0675\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0668\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0665\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0665\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0663\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0667\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0665\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0670\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0690\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0680\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0688\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0685\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0668\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0667\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0671\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0670\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0677\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0677\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0674\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0673\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0660\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0670\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0682\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0675\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0681\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0680\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0665\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0672\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0660\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0669\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0685\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0664\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0674\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0680\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0656\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0654\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0660\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0677 - val_loss: 0.0662\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0689\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0694\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0732\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0724\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0676\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0663\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0661\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0662\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0655\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0671\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0674\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0664\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0662\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0657\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0652\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0649\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0661 - val_loss: 0.0633\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0649\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0638\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0631\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0646 - val_loss: 0.0621\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0627 - val_loss: 0.0600\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0648\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0678\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0640\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0665\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0661 - val_loss: 0.0640\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0638 - val_loss: 0.0621\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0585\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0615 - val_loss: 0.0602\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0620\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0646\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0645\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0713 - val_loss: 0.0692\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0631\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0615\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0589\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0571\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0586 - val_loss: 0.0571\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0584\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0566\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0641 - val_loss: 0.0586\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0638 - val_loss: 0.0639\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0615\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0622 - val_loss: 0.0588\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0588 - val_loss: 0.0566\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0577 - val_loss: 0.0549\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0545\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0556 - val_loss: 0.0548\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0558\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0595 - val_loss: 0.0553\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0616 - val_loss: 0.0589\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0586\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0566\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0556\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0561\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0609 - val_loss: 0.0570\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):171.72972972972974\n",
      "Fold score (RMSE):13.10456904021379\n",
      "Unsupervised Fold #8\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 5s 5ms/step - loss: 0.2010 - val_loss: 0.1566\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1439 - val_loss: 0.1341\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1282 - val_loss: 0.1243\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1192 - val_loss: 0.1146\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1111 - val_loss: 0.1059\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1073 - val_loss: 0.1043\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1052 - val_loss: 0.0980\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0984 - val_loss: 0.0962\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0966 - val_loss: 0.0967\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0941 - val_loss: 0.0936\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0911 - val_loss: 0.0908\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0928 - val_loss: 0.0956\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0913 - val_loss: 0.0917\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0934 - val_loss: 0.0989\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0933 - val_loss: 0.0971\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0936 - val_loss: 0.0894\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0888 - val_loss: 0.0908\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0884 - val_loss: 0.0864\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0878 - val_loss: 0.0892\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0857\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0874\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0862 - val_loss: 0.0848\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0837\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0835 - val_loss: 0.0848\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0833 - val_loss: 0.0821\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0832 - val_loss: 0.0852\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0860\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0838 - val_loss: 0.0822\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0823 - val_loss: 0.0819\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0813 - val_loss: 0.0808\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0811\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0806 - val_loss: 0.0802\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0804 - val_loss: 0.0805\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0808 - val_loss: 0.0800\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0814 - val_loss: 0.0835\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0817\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0805 - val_loss: 0.0807\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0799 - val_loss: 0.0793\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0805\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0785\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0790 - val_loss: 0.0789\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0789\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0820\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0819 - val_loss: 0.0797\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0788\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0812\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0782\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0780 - val_loss: 0.0773\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0782 - val_loss: 0.0785\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0763\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0779 - val_loss: 0.0784\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0766 - val_loss: 0.0768\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0819\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0799 - val_loss: 0.0789\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0768 - val_loss: 0.0776\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0788 - val_loss: 0.0826\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0821 - val_loss: 0.0782\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0761\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0763 - val_loss: 0.0759\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0758\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0748\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0759\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0744\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0764\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0776\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0742\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0764\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0750\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0770 - val_loss: 0.0786\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0785 - val_loss: 0.0755\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0757 - val_loss: 0.0739\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0757 - val_loss: 0.0742\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0730\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0733\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0733\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0738\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0728\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0750\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0742\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0729\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0747\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0727\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0729\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0747\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0716\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0738\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0737\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0715\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0734 - val_loss: 0.0759\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0756\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0719\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0738\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0732\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0718\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0731\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0727\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0704\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0706\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0710\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0703\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0706\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0717\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0711\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0704\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0701\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0710\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0709\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0718\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0746\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0739\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0704\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0710\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0709\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0696\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0706\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0713\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0717 - val_loss: 0.0699\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0695\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0693\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0690\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0694\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0703\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0696\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0691\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0696\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0716\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0714\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0707\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0746\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0744\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0697\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0690\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0692\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0685\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0687\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0686\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0682\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0680\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0681\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0683\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0691\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0703\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0694\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0742\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0761\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0693\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0685\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0683\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0680\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0678\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0678\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0678\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0676\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0678\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0681\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0683\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0699\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0704\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0695\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0695\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0722\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0684\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0680\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0677\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0677\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0676\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0675\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0674\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0676\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0675\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0672\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0677\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0686\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0709\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0697\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0697\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0700\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0681\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0681\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0697\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0687\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0686\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0681\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0670\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0676\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0686\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0693\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0678\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0700\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0735\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0693\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0695\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0706\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0682\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0668\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0657\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0646\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0631\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0646\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0686\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0676\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0686\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0707\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0702\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0700 - val_loss: 0.0685\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0673\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0682\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0691\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0672\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0688\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0673\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0684 - val_loss: 0.0660\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0684 - val_loss: 0.0666\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0669\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0680\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0652\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0617\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0638\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0677\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0698\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0724 - val_loss: 0.0693\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0683\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0666\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0661\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0651\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0659\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0680\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0665\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0658 - val_loss: 0.0653\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0644\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0650\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0725\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0677\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0659\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0651 - val_loss: 0.0622\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0601\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0618\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0629 - val_loss: 0.0606\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0632\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0698\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0691\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0652\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0646 - val_loss: 0.0609\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0607 - val_loss: 0.0587\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0589 - val_loss: 0.0572\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0578\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0669\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0658 - val_loss: 0.0631\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0604\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0610 - val_loss: 0.0605\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0596\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0640 - val_loss: 0.0637\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0694\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0667\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0613\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0587\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0622 - val_loss: 0.0573\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0602\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0598\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0622 - val_loss: 0.0582\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0629 - val_loss: 0.0588\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0592\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0571\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0587 - val_loss: 0.0557\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0555\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0557\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0551\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0551\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0584 - val_loss: 0.0564\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0550\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0549\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0554\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0581 - val_loss: 0.0549\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0585 - val_loss: 0.0553\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0566 - val_loss: 0.0544\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0536\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0547\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0542\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0533\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0542\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0584 - val_loss: 0.0545\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0560 - val_loss: 0.0531\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0563 - val_loss: 0.0528\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0536\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0551 - val_loss: 0.0523\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0518\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0562 - val_loss: 0.0539\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0556 - val_loss: 0.0524\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0563 - val_loss: 0.0512\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0522\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0523\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0515\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):175.33333333333334\n",
      "Fold score (RMSE):13.241349377360804\n",
      "Unsupervised Fold #9\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 4s 4ms/step - loss: 0.2116 - val_loss: 0.1513\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1353 - val_loss: 0.1312\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1266 - val_loss: 0.1212\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1138 - val_loss: 0.1085\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1117 - val_loss: 0.1078\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1082 - val_loss: 0.1037\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1024 - val_loss: 0.0999\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1028 - val_loss: 0.0972\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0999 - val_loss: 0.0960\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0986 - val_loss: 0.0942\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0960 - val_loss: 0.0937\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0911\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0913 - val_loss: 0.0886\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0899 - val_loss: 0.0873\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0901 - val_loss: 0.0872\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0909 - val_loss: 0.0913\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0883 - val_loss: 0.0884\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0903 - val_loss: 0.0954\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0898 - val_loss: 0.0921\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0921 - val_loss: 0.0868\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0875 - val_loss: 0.0862\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0876 - val_loss: 0.0877\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0854 - val_loss: 0.0848\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0876 - val_loss: 0.0855\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0829\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0833 - val_loss: 0.0818\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0824\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0827 - val_loss: 0.0817\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0833 - val_loss: 0.0826\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0818 - val_loss: 0.0819\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0832 - val_loss: 0.0816\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0822 - val_loss: 0.0810\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0804 - val_loss: 0.0845\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0863 - val_loss: 0.0900\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0896 - val_loss: 0.0903\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0871 - val_loss: 0.0884\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0862 - val_loss: 0.0868\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0846 - val_loss: 0.0857\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0852\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0835 - val_loss: 0.0838\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0826 - val_loss: 0.0830\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0820 - val_loss: 0.0820\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0820 - val_loss: 0.0807\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0810 - val_loss: 0.0810\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0787\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0780\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0775 - val_loss: 0.0768\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0771 - val_loss: 0.0769\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0768\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0779\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0768 - val_loss: 0.0764\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0756\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0754\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0751 - val_loss: 0.0750\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0749 - val_loss: 0.0748\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0746\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0744\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0746\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0745\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0747\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0745\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0739\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0740\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0737\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0736\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0739 - val_loss: 0.0735\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0735\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0735 - val_loss: 0.0735\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0738\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0741\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0746 - val_loss: 0.0732\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0734\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0737\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0733\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0747\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0729\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0730 - val_loss: 0.0729\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0728\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0728\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0726\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0726\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0726\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0725\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0725\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0724\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0724\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0724\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0724\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0724 - val_loss: 0.0723\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0724 - val_loss: 0.0725\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0723\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0722\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0722\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0721 - val_loss: 0.0721\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0725\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0732\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0738 - val_loss: 0.0729\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0730\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0736\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0745\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0799\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0770\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0768 - val_loss: 0.0774\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0813\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0838 - val_loss: 0.0817\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0779 - val_loss: 0.0768\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0771 - val_loss: 0.0729\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0743 - val_loss: 0.0729\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0725\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0731\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0721\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0732\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0740\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0733 - val_loss: 0.0719\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0766\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0766\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0711\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0726 - val_loss: 0.0733\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0725 - val_loss: 0.0728\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0715\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0769\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.0760\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0727\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0744 - val_loss: 0.0754\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0741 - val_loss: 0.0732\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0719\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0735 - val_loss: 0.0730\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0705\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0714\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0709\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0702\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0716\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0704\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0730\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0706\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0723\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0716\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0717 - val_loss: 0.0698\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0713\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0711\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0697\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0710\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0707\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0694\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0708\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0708\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0699\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0718\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0716\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0695\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0700\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0702\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0693\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0705\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0706\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0689\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0702\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0703\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0696\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0707\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0708\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0688\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0688\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0700\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0703\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0684\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0688\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0691\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0684\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0705\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0685\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0689\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0691\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0683\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0693\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0697\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0684\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0680\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0681\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0679\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0686\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0692\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0682\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0682\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0685\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0679\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0687\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0701\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0692\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0681\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0675\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0683\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0683\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0691\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0699\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0694\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0675\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0680\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0681\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0674\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0688\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0689\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0677\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0678\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0679\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0676\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0682\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0685\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0678\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0672\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0673\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0675\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0677\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0683\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0684\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0677\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0670\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0687\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0687\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0674\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0690\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0690\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0671\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0669\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0672\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0665\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0672\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0672\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0669\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0667\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0673\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0668\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0685\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0690\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0670\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0671\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0677\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0670\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0674\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0682\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0670\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0662\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0663\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0667\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0667\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0673\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0680\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0668\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0665\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0681\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0675\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0668\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0675\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0659\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0664\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0667\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0657\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0675\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0676\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0659\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0663\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0670\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0665\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0669\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0669\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0658\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0664\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0659\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0664\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0667\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0656\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0663\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0654\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0666\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0668\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0654\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0653\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0662\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0655\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0656\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0664\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0657\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0661 - val_loss: 0.0646\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0656\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0664 - val_loss: 0.0663\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0657\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0669\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):287.5405405405405\n",
      "Fold score (RMSE):16.95702039099265\n",
      "Unsupervised Fold #10\n",
      "X_train =  (1003, 31, 1)\n",
      "X_test =  (111, 31, 1)\n",
      "batch_size =  100\n",
      "Train on 1003 samples, validate on 111 samples\n",
      "Epoch 1/300\n",
      "1003/1003 [==============================] - 5s 5ms/step - loss: 0.2009 - val_loss: 0.1384\n",
      "Epoch 2/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1351 - val_loss: 0.1251\n",
      "Epoch 3/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1255 - val_loss: 0.1163\n",
      "Epoch 4/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1146 - val_loss: 0.1079\n",
      "Epoch 5/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1097 - val_loss: 0.1003\n",
      "Epoch 6/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1043 - val_loss: 0.0985\n",
      "Epoch 7/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1024 - val_loss: 0.0962\n",
      "Epoch 8/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.1006 - val_loss: 0.0960\n",
      "Epoch 9/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0971 - val_loss: 0.0904\n",
      "Epoch 10/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0940 - val_loss: 0.0899\n",
      "Epoch 11/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0930 - val_loss: 0.0895\n",
      "Epoch 12/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0938 - val_loss: 0.0952\n",
      "Epoch 13/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0922 - val_loss: 0.0898\n",
      "Epoch 14/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0942 - val_loss: 0.0946\n",
      "Epoch 15/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0938 - val_loss: 0.0936\n",
      "Epoch 16/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0939 - val_loss: 0.0878\n",
      "Epoch 17/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0916 - val_loss: 0.0915\n",
      "Epoch 18/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0921 - val_loss: 0.0849\n",
      "Epoch 19/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0868 - val_loss: 0.0847\n",
      "Epoch 20/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0828\n",
      "Epoch 21/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0865 - val_loss: 0.0833\n",
      "Epoch 22/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0843 - val_loss: 0.0819\n",
      "Epoch 23/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0855 - val_loss: 0.0857\n",
      "Epoch 24/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0871 - val_loss: 0.0814\n",
      "Epoch 25/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0832 - val_loss: 0.0808\n",
      "Epoch 26/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0828 - val_loss: 0.0804\n",
      "Epoch 27/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0828 - val_loss: 0.0808\n",
      "Epoch 28/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0837 - val_loss: 0.0830\n",
      "Epoch 29/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0853 - val_loss: 0.0824\n",
      "Epoch 30/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0831 - val_loss: 0.0800\n",
      "Epoch 31/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0840 - val_loss: 0.0798\n",
      "Epoch 32/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0820 - val_loss: 0.0785\n",
      "Epoch 33/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0824 - val_loss: 0.0838\n",
      "Epoch 34/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0846 - val_loss: 0.0788\n",
      "Epoch 35/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0813 - val_loss: 0.0795\n",
      "Epoch 36/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0807 - val_loss: 0.0791\n",
      "Epoch 37/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0819 - val_loss: 0.0811\n",
      "Epoch 38/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0834 - val_loss: 0.0785\n",
      "Epoch 39/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0796 - val_loss: 0.0776\n",
      "Epoch 40/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0773\n",
      "Epoch 41/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0773\n",
      "Epoch 42/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0793 - val_loss: 0.0767\n",
      "Epoch 43/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0787 - val_loss: 0.0772\n",
      "Epoch 44/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0798 - val_loss: 0.0770\n",
      "Epoch 45/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0797 - val_loss: 0.0784\n",
      "Epoch 46/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0801 - val_loss: 0.0752\n",
      "Epoch 47/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0783 - val_loss: 0.0755\n",
      "Epoch 48/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0780 - val_loss: 0.0756\n",
      "Epoch 49/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0791 - val_loss: 0.0807\n",
      "Epoch 50/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0822 - val_loss: 0.0761\n",
      "Epoch 51/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0776 - val_loss: 0.0755\n",
      "Epoch 52/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0778 - val_loss: 0.0752\n",
      "Epoch 53/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0743\n",
      "Epoch 54/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0766 - val_loss: 0.0737\n",
      "Epoch 55/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0758 - val_loss: 0.0742\n",
      "Epoch 56/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0765 - val_loss: 0.0762\n",
      "Epoch 57/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0741\n",
      "Epoch 58/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0772 - val_loss: 0.0737\n",
      "Epoch 59/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0758\n",
      "Epoch 60/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0767 - val_loss: 0.0780\n",
      "Epoch 61/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0772 - val_loss: 0.0743\n",
      "Epoch 62/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0770 - val_loss: 0.0759\n",
      "Epoch 63/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0779 - val_loss: 0.0737\n",
      "Epoch 64/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0764 - val_loss: 0.0738\n",
      "Epoch 65/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0756 - val_loss: 0.0719\n",
      "Epoch 66/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0731\n",
      "Epoch 67/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0728\n",
      "Epoch 68/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0770\n",
      "Epoch 69/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0794 - val_loss: 0.0749\n",
      "Epoch 70/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0753 - val_loss: 0.0733\n",
      "Epoch 71/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0773 - val_loss: 0.0776\n",
      "Epoch 72/300\n",
      "1003/1003 [==============================] - 2s 2ms/step - loss: 0.0774 - val_loss: 0.0729\n",
      "Epoch 73/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0745 - val_loss: 0.0720\n",
      "Epoch 74/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0742 - val_loss: 0.0696\n",
      "Epoch 75/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0736 - val_loss: 0.0707\n",
      "Epoch 76/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0724 - val_loss: 0.0703\n",
      "Epoch 77/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0755 - val_loss: 0.0756\n",
      "Epoch 79/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0762 - val_loss: 0.0727\n",
      "Epoch 80/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0748 - val_loss: 0.0717\n",
      "Epoch 81/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0731 - val_loss: 0.0697\n",
      "Epoch 82/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0715 - val_loss: 0.0687\n",
      "Epoch 83/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0696\n",
      "Epoch 84/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0691\n",
      "Epoch 85/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0687\n",
      "Epoch 86/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0720 - val_loss: 0.0716\n",
      "Epoch 87/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0740 - val_loss: 0.0701\n",
      "Epoch 88/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0688\n",
      "Epoch 89/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0692\n",
      "Epoch 90/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0718 - val_loss: 0.0686\n",
      "Epoch 91/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 92/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0680\n",
      "Epoch 93/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0682\n",
      "Epoch 94/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0683\n",
      "Epoch 95/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0678\n",
      "Epoch 96/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0683\n",
      "Epoch 97/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0685\n",
      "Epoch 98/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0682\n",
      "Epoch 99/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0684\n",
      "Epoch 100/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0685\n",
      "Epoch 101/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0712 - val_loss: 0.0685\n",
      "Epoch 102/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0716 - val_loss: 0.0684\n",
      "Epoch 103/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0684\n",
      "Epoch 104/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0710 - val_loss: 0.0681\n",
      "Epoch 105/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0714 - val_loss: 0.0683\n",
      "Epoch 106/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0683\n",
      "Epoch 107/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0678\n",
      "Epoch 108/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0676\n",
      "Epoch 109/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0676\n",
      "Epoch 110/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0677\n",
      "Epoch 111/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0673\n",
      "Epoch 112/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0673\n",
      "Epoch 113/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0681\n",
      "Epoch 114/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0674\n",
      "Epoch 115/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0672\n",
      "Epoch 116/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 117/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0676\n",
      "Epoch 118/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0675\n",
      "Epoch 119/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0677\n",
      "Epoch 120/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0678\n",
      "Epoch 121/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0678\n",
      "Epoch 122/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0674\n",
      "Epoch 123/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0706 - val_loss: 0.0673\n",
      "Epoch 124/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0676\n",
      "Epoch 125/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0672\n",
      "Epoch 126/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0703 - val_loss: 0.0671\n",
      "Epoch 127/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0672\n",
      "Epoch 128/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0671\n",
      "Epoch 129/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0668\n",
      "Epoch 130/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0670\n",
      "Epoch 131/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0676\n",
      "Epoch 132/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0672\n",
      "Epoch 133/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0672\n",
      "Epoch 134/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0678\n",
      "Epoch 135/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0708 - val_loss: 0.0672\n",
      "Epoch 136/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0675\n",
      "Epoch 137/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0704 - val_loss: 0.0676\n",
      "Epoch 138/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0707 - val_loss: 0.0672\n",
      "Epoch 139/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0676\n",
      "Epoch 140/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0669\n",
      "Epoch 141/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0669\n",
      "Epoch 142/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0672\n",
      "Epoch 143/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0665\n",
      "Epoch 144/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0666\n",
      "Epoch 145/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0669\n",
      "Epoch 146/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0661\n",
      "Epoch 147/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0662\n",
      "Epoch 148/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0663\n",
      "Epoch 149/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0669\n",
      "Epoch 150/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0663\n",
      "Epoch 151/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0664\n",
      "Epoch 152/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0665\n",
      "Epoch 153/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0661\n",
      "Epoch 154/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0661\n",
      "Epoch 155/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0665\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0659\n",
      "Epoch 157/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0659\n",
      "Epoch 158/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0668\n",
      "Epoch 159/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0693 - val_loss: 0.0657\n",
      "Epoch 160/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0659\n",
      "Epoch 161/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0670\n",
      "Epoch 162/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0655\n",
      "Epoch 163/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0658\n",
      "Epoch 164/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0685 - val_loss: 0.0667\n",
      "Epoch 165/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0654\n",
      "Epoch 166/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0667\n",
      "Epoch 167/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0677\n",
      "Epoch 168/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0663\n",
      "Epoch 169/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0673\n",
      "Epoch 170/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0680\n",
      "Epoch 171/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0655\n",
      "Epoch 172/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0662\n",
      "Epoch 173/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0671\n",
      "Epoch 174/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0690 - val_loss: 0.0654\n",
      "Epoch 175/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0660\n",
      "Epoch 176/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0671\n",
      "Epoch 177/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0646\n",
      "Epoch 178/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0648\n",
      "Epoch 179/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0651\n",
      "Epoch 180/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0636\n",
      "Epoch 181/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0639\n",
      "Epoch 182/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0650\n",
      "Epoch 183/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0643\n",
      "Epoch 184/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0667 - val_loss: 0.0633\n",
      "Epoch 185/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0639\n",
      "Epoch 186/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0643\n",
      "Epoch 187/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0634\n",
      "Epoch 188/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0679 - val_loss: 0.0648\n",
      "Epoch 189/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0613\n",
      "Epoch 190/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0680 - val_loss: 0.0637\n",
      "Epoch 191/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0689 - val_loss: 0.0676\n",
      "Epoch 192/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0626\n",
      "Epoch 193/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0628\n",
      "Epoch 194/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0643\n",
      "Epoch 195/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0619\n",
      "Epoch 196/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0639\n",
      "Epoch 197/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0661\n",
      "Epoch 198/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0638\n",
      "Epoch 199/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0613\n",
      "Epoch 200/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0602\n",
      "Epoch 201/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0611\n",
      "Epoch 202/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0673 - val_loss: 0.0647\n",
      "Epoch 203/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0683 - val_loss: 0.0646\n",
      "Epoch 204/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0629\n",
      "Epoch 205/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0636\n",
      "Epoch 206/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0580\n",
      "Epoch 207/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0631 - val_loss: 0.0575\n",
      "Epoch 208/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0557\n",
      "Epoch 209/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0646 - val_loss: 0.0608\n",
      "Epoch 210/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0659 - val_loss: 0.0638\n",
      "Epoch 211/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0617\n",
      "Epoch 212/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0634 - val_loss: 0.0568\n",
      "Epoch 213/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0540\n",
      "Epoch 214/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0599 - val_loss: 0.0558\n",
      "Epoch 215/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0547\n",
      "Epoch 216/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0553\n",
      "Epoch 217/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0544\n",
      "Epoch 218/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0586 - val_loss: 0.0518\n",
      "Epoch 219/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0587 - val_loss: 0.0531\n",
      "Epoch 220/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0556\n",
      "Epoch 221/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0609 - val_loss: 0.0533\n",
      "Epoch 222/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0605 - val_loss: 0.0536\n",
      "Epoch 223/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0564\n",
      "Epoch 224/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0608 - val_loss: 0.0523\n",
      "Epoch 225/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0575 - val_loss: 0.0524\n",
      "Epoch 226/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0575 - val_loss: 0.0510\n",
      "Epoch 227/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0563 - val_loss: 0.0506\n",
      "Epoch 228/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0566 - val_loss: 0.0485\n",
      "Epoch 229/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0556 - val_loss: 0.0495\n",
      "Epoch 230/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0490\n",
      "Epoch 231/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0492\n",
      "Epoch 232/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0543 - val_loss: 0.0495\n",
      "Epoch 233/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0505\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0539 - val_loss: 0.0472\n",
      "Epoch 235/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0523 - val_loss: 0.0472\n",
      "Epoch 236/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0481\n",
      "Epoch 237/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0478\n",
      "Epoch 238/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0458\n",
      "Epoch 239/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0457\n",
      "Epoch 240/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0475\n",
      "Epoch 241/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0529 - val_loss: 0.0462\n",
      "Epoch 242/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0512 - val_loss: 0.0469\n",
      "Epoch 243/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0479\n",
      "Epoch 244/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0449\n",
      "Epoch 245/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
      "Epoch 246/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0467\n",
      "Epoch 247/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0533 - val_loss: 0.0464\n",
      "Epoch 248/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0472\n",
      "Epoch 249/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0477\n",
      "Epoch 250/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0551 - val_loss: 0.0490\n",
      "Epoch 251/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0471\n",
      "Epoch 252/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0468\n",
      "Epoch 253/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0446\n",
      "Epoch 254/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0481 - val_loss: 0.0447\n",
      "Epoch 255/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0500\n",
      "Epoch 256/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0476\n",
      "Epoch 257/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0450\n",
      "Epoch 258/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0441\n",
      "Epoch 259/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0433\n",
      "Epoch 260/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0435\n",
      "Epoch 261/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0427\n",
      "Epoch 262/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0443\n",
      "Epoch 263/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0441\n",
      "Epoch 264/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0525 - val_loss: 0.0461\n",
      "Epoch 265/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0456\n",
      "Epoch 266/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0586\n",
      "Epoch 267/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0537\n",
      "Epoch 268/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0543 - val_loss: 0.0456\n",
      "Epoch 269/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0429\n",
      "Epoch 270/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0470 - val_loss: 0.0416\n",
      "Epoch 271/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0458 - val_loss: 0.0417\n",
      "Epoch 272/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0464 - val_loss: 0.0410\n",
      "Epoch 273/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0468\n",
      "Epoch 274/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0523 - val_loss: 0.0482\n",
      "Epoch 275/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0531 - val_loss: 0.0466\n",
      "Epoch 276/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0455\n",
      "Epoch 277/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0475 - val_loss: 0.0434\n",
      "Epoch 278/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0465 - val_loss: 0.0420\n",
      "Epoch 279/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0414\n",
      "Epoch 280/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0411\n",
      "Epoch 281/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0460 - val_loss: 0.0431\n",
      "Epoch 282/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0445\n",
      "Epoch 283/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0458\n",
      "Epoch 284/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0493 - val_loss: 0.0442\n",
      "Epoch 285/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0438\n",
      "Epoch 286/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0483 - val_loss: 0.0447\n",
      "Epoch 287/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0473 - val_loss: 0.0415\n",
      "Epoch 288/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0410\n",
      "Epoch 289/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0455 - val_loss: 0.0417\n",
      "Epoch 290/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0462 - val_loss: 0.0425\n",
      "Epoch 291/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0474 - val_loss: 0.0419\n",
      "Epoch 292/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0456 - val_loss: 0.0406\n",
      "Epoch 293/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0438 - val_loss: 0.0399\n",
      "Epoch 294/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0392\n",
      "Epoch 295/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0434 - val_loss: 0.0396\n",
      "Epoch 296/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0444\n",
      "Epoch 297/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0465\n",
      "Epoch 298/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0483\n",
      "Epoch 299/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0435\n",
      "Epoch 300/300\n",
      "1003/1003 [==============================] - 1s 1ms/step - loss: 0.0464 - val_loss: 0.0416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold score (MSE):89.2072072072072\n",
      "Fold score (RMSE):9.444956707534832\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle = True, random_state = 42)\n",
    "oos_x = []\n",
    "oos_pred_x = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    fold+=1\n",
    "    print(f\"Unsupervised Fold #{fold}\")\n",
    "    \n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_train = Y[train]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # expand dimensions\n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "    print('X_train = ',X_train.shape) \n",
    "    print('X_test = ',X_test.shape)\n",
    "    \n",
    "    batch_size = round ((1/10)*1002)   #140860\n",
    "    print('batch_size = ', batch_size)\n",
    "    \n",
    "    #proposed architecture of LSTM model\n",
    "    # define model\n",
    "    encoder_decoder = Sequential()\n",
    "    encoder_decoder.add(LSTM(31, activation='elu', input_shape = X_train[1].shape, \\\n",
    "                         return_sequences=True)) #try units = 50\n",
    "    encoder_decoder.add(Dropout(0.3)) \n",
    "    encoder_decoder.add(LSTM(20, activation='elu', return_sequences=True))\n",
    "    encoder_decoder.add(Dropout(0.3)) \n",
    "\n",
    "    encoder_decoder.add(LSTM(10, activation='elu', return_sequences=False, name=\"bottleneck\"))\n",
    "    encoder_decoder.add(RepeatVector(31))\n",
    "    encoder_decoder.add(LSTM(10, activation='elu', return_sequences=True))\n",
    "\n",
    "    encoder_decoder.add(Dropout(0.3))\n",
    "    encoder_decoder.add(LSTM(20, activation='elu', return_sequences=True))\n",
    "    encoder_decoder.add(Dropout(0.3)) \n",
    "    encoder_decoder.add(LSTM(31, activation='elu', return_sequences=True))\n",
    "    encoder_decoder.add(TimeDistributed(Dense(1)))\n",
    "    #encoder_decoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    encoder_decoder.compile(loss='mse', optimizer='adam')\n",
    "   \n",
    "    history = encoder_decoder.fit(X_train, X_train, epochs = 300, batch_size = batch_size, \\\n",
    "                                shuffle = False, validation_data=[X_test, X_test])\n",
    "    rpt_vector_layer = Model(inputs=encoder_decoder.inputs, outputs=encoder_decoder.layers[2].output)\n",
    "    time_dist_layer = Model(inputs=encoder_decoder.inputs, outputs=encoder_decoder.layers[5].output)\n",
    "    encoder = Model(inputs=encoder_decoder.inputs,\\\n",
    "                    outputs=encoder_decoder.get_layer('bottleneck').output)\n",
    "    \n",
    "    model_name = get_model_name(fold)\n",
    "    encoder_decoder.save('D:/data/k_fold_unsupervised/mendaly_data/'+model_name,'h5')\n",
    "    \n",
    "    encoder_model_name = get_encoder_model_name(fold)\n",
    "    encoder.save('D:/data/k_fold_unsupervised/mendaly_data/'+encoder_model_name,'h5')\n",
    "    \n",
    "    plt.plot(history.history['loss'], label = 'loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    pred = encoder_decoder.predict(X_test)\n",
    "    oos_x.append(X_test)\n",
    "    #print(oos_x)\n",
    "    compare_X_test = np.argmax(X_test, axis = 1)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    oos_pred_x.append(pred)\n",
    "    #print(oos_pred_x)\n",
    "    \n",
    "    MSE_score = mean_squared_error(pred, compare_X_test)\n",
    "    print(f\"Fold score (MSE):{MSE_score}\")\n",
    "    RMSE_score = np.sqrt(mean_squared_error(pred, compare_X_test))\n",
    "    print(f\"Fold score (RMSE):{RMSE_score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE):15.466010685855903\n"
     ]
    }
   ],
   "source": [
    "#build the prediction list and calculate error\n",
    "oos_x = np.concatenate(oos_x)\n",
    "oos_pred_x = np.concatenate(oos_pred_x)\n",
    "oos_x_compare = np.argmax(oos_x, axis=1) #for accuracy calculation\n",
    "score = np.sqrt(mean_squared_error(oos_pred_x, oos_x_compare))\n",
    "print(f\"Final score (RMSE):{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
